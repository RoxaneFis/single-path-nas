{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import ast\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import seaborn as sns\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from progressbar import ProgressBar\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import Sequential, Model\n",
    "from random import randrange\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import time\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "from plot_figures import save_model\n",
    "\n",
    "pbar = ProgressBar()\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "max_blocks = 37 #(36 + 1 FC layer at the end)\n",
    "#max_blocks = 36\n",
    "\n",
    "nb_param =7\n",
    "#nb_param =13\n",
    "nb_hw_param = 6\n",
    "#nb_param =12\n",
    "\n",
    "inversed = True\n",
    "only_inversed = False\n",
    "\n",
    "BATCH_SIZE = 2048\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "\n",
    "DATASET_SIZE = 168308\n",
    "train_size = int(0.90 * DATASET_SIZE) #135 805\n",
    "test_size = int(0.10 * DATASET_SIZE) # 15 089\n",
    "\n",
    "nb_training_batches = train_size //BATCH_SIZE +1\n",
    "nb_test_batches = test_size //BATCH_SIZE +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def from_np_array(array_string):\n",
    "    array_string = ','.join(array_string.replace('[ ', '[').split())\n",
    "    return np.asarray(ast.literal_eval(array_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Proccessed Neural Networks (without HyperParameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_raw_val = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_val_all.csv'\n",
    "path_raw_train = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_train_all.csv'\n",
    "\n",
    "#path_processed_val_nn = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/val_13.csv'\n",
    "#path_processed_train_nn = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/train_13.csv'\n",
    "\n",
    "\n",
    "path_processed_val_nn = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/val_7.csv'\n",
    "path_processed_train_nn = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/train_7.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total time : 1.4375791333333332 min\n"
    }
   ],
   "source": [
    "#%pycache\n",
    "tin= time.clock()\n",
    "\n",
    "val = pd.read_csv(path_processed_val_nn,converters={'NN_dataframe': from_np_array})\n",
    "train = pd.read_csv(path_processed_train_nn,converters={'NN_dataframe': from_np_array})\n",
    "\n",
    "tfin= time.clock()\n",
    "print(f'Total time : {(tfin-tin)/60} min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete to zeros (max shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_zero_blocks(arr):\n",
    "    zero_blocks = np.zeros((max_blocks-arr.shape[0],arr.shape[1]))\n",
    "    return np.append(arr, zero_blocks, axis=0)\n",
    "\n",
    "val['NN_dataframe']= val['NN_dataframe'].apply(lambda x : add_zero_blocks(x))\n",
    "train['NN_dataframe']= train['NN_dataframe'].apply(lambda x : add_zero_blocks(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Get y_train, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To retrieve y_train / y_test\n",
    "\n",
    "train_hw = pd.read_csv(path_raw_train)\n",
    "val_hw = pd.read_csv(path_raw_val)\n",
    "\n",
    "y_train = np.array(train_hw[\"total_power\"].tolist())\n",
    "y_train=y_train.reshape(y_train.shape[0],-1)\n",
    "\n",
    "y_val = np.array(val_hw[\"total_power\"].tolist())\n",
    "y_val=y_val.reshape(y_val.shape[0],-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "# HW PARAM ALONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   mac_num  mac_array_num  data_bits  sram_size  max_filter_size  tot_mac\n0    118.0            2.0      256.0   179968.0           2048.0    236.0\n1     87.0            2.0      512.0    99968.0           2048.0    174.0\n2    124.0            2.0      512.0    99968.0           3072.0    248.0\n3     80.0            2.0     1024.0    99968.0           1024.0    160.0\n4     86.0            2.0      512.0    60000.0           1536.0    172.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mac_num</th>\n      <th>mac_array_num</th>\n      <th>data_bits</th>\n      <th>sram_size</th>\n      <th>max_filter_size</th>\n      <th>tot_mac</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>118.0</td>\n      <td>2.0</td>\n      <td>256.0</td>\n      <td>179968.0</td>\n      <td>2048.0</td>\n      <td>236.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>87.0</td>\n      <td>2.0</td>\n      <td>512.0</td>\n      <td>99968.0</td>\n      <td>2048.0</td>\n      <td>174.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>124.0</td>\n      <td>2.0</td>\n      <td>512.0</td>\n      <td>99968.0</td>\n      <td>3072.0</td>\n      <td>248.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>80.0</td>\n      <td>2.0</td>\n      <td>1024.0</td>\n      <td>99968.0</td>\n      <td>1024.0</td>\n      <td>160.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>86.0</td>\n      <td>2.0</td>\n      <td>512.0</td>\n      <td>60000.0</td>\n      <td>1536.0</td>\n      <td>172.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "X_train_hw_param  = train_hw[['mac_num', 'mac_array_num', 'data_bits', 'sram_size', 'max_filter_size']]\n",
    "X_train_hw_param['tot_mac'] = X_train_hw_param['mac_num']*X_train_hw_param['mac_array_num']\n",
    "\n",
    "X_val_hw_param  = val_hw[['mac_num', 'mac_array_num', 'data_bits', 'sram_size', 'max_filter_size']]\n",
    "X_val_hw_param['tot_mac'] = X_val_hw_param['mac_num']*X_val_hw_param['mac_array_num']\n",
    "\n",
    "X_train_hw_param.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 151622/151622 [00:00<00:00, 465526.49it/s]\n100%|██████████| 151622/151622 [00:00<00:00, 790847.27it/s]\n100%|██████████| 151622/151622 [00:00<00:00, 855383.78it/s]\n100%|██████████| 151622/151622 [00:00<00:00, 905762.83it/s]\n100%|██████████| 151622/151622 [00:00<00:00, 847703.37it/s]\n100%|██████████| 151622/151622 [00:00<00:00, 845610.20it/s]\n100%|██████████| 16686/16686 [00:00<00:00, 721960.79it/s]\n100%|██████████| 16686/16686 [00:00<00:00, 782615.31it/s]\n100%|██████████| 16686/16686 [00:00<00:00, 729060.44it/s]\n100%|██████████| 16686/16686 [00:00<00:00, 798609.65it/s]\n100%|██████████| 16686/16686 [00:00<00:00, 801316.21it/s]\n100%|██████████| 16686/16686 [00:00<00:00, 703958.60it/s]\n"
    }
   ],
   "source": [
    "def inv(x):\n",
    "    return 1/(1+x)\n",
    "\n",
    "\n",
    "if inversed : \n",
    "#nb_hw_param = 6\n",
    "    nb_hw_param = 12\n",
    "    X_train_hw_param['1/mac_num'] = X_train_hw_param['mac_num'].progress_apply(lambda x : inv(x))\n",
    "    X_train_hw_param['1/mac_array_num'] = X_train_hw_param['mac_array_num'].progress_apply(lambda x : inv(x))\n",
    "    X_train_hw_param['1/data_bits'] = X_train_hw_param['data_bits'].progress_apply(lambda x : inv(x))\n",
    "    X_train_hw_param['1/sram_size'] = X_train_hw_param['sram_size'].progress_apply(lambda x : inv(x))\n",
    "    X_train_hw_param['1/max_filter_size'] = X_train_hw_param['max_filter_size'].progress_apply(lambda x : inv(x))\n",
    "    X_train_hw_param['1/tot_mac'] = X_train_hw_param['tot_mac'].progress_apply(lambda x : inv(x))\n",
    "\n",
    "\n",
    "    X_val_hw_param['1/mac_num'] = X_val_hw_param['mac_num'].progress_apply(lambda x : inv(x))\n",
    "    X_val_hw_param['1/mac_array_num'] = X_val_hw_param['mac_array_num'].progress_apply(lambda x : inv(x))\n",
    "    X_val_hw_param['1/data_bits'] = X_val_hw_param['data_bits'].progress_apply(lambda x : inv(x))\n",
    "    X_val_hw_param['1/sram_size'] = X_val_hw_param['sram_size'].progress_apply(lambda x : inv(x))\n",
    "    X_val_hw_param['1/max_filter_size'] = X_val_hw_param['max_filter_size'].progress_apply(lambda x : inv(x))\n",
    "    X_val_hw_param['1/tot_mac'] = X_val_hw_param['tot_mac'].progress_apply(lambda x : inv(x))\n",
    "\n",
    "if only_inversed : \n",
    "    nb_hw_param = 6\n",
    "    inv = ['1/mac_num','1/mac_array_num','1/data_bits','1/sram_size','1/max_filter_size','1/tot_mac']\n",
    "    X_train_hw_param =X_train_hw_param.loc[:, inv]\n",
    "    X_val_hw_param =X_val_hw_param.loc[:, inv]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   mac_num  mac_array_num  data_bits  sram_size  max_filter_size  tot_mac  \\\n0     37.0            2.0      128.0   199936.0           4098.0     74.0   \n1     91.0            2.0      256.0   119936.0           2048.0    182.0   \n2     74.0            2.0      256.0   139904.0           1024.0    148.0   \n3     70.0            2.0      512.0    80000.0            512.0    140.0   \n4    103.0            2.0      256.0   199936.0           4098.0    206.0   \n\n   1/mac_num  1/mac_array_num  1/data_bits  1/sram_size  1/max_filter_size  \\\n0   0.026316         0.333333     0.007752     0.000005           0.000244   \n1   0.010870         0.333333     0.003891     0.000008           0.000488   \n2   0.013333         0.333333     0.003891     0.000007           0.000976   \n3   0.014085         0.333333     0.001949     0.000012           0.001949   \n4   0.009615         0.333333     0.003891     0.000005           0.000244   \n\n   1/tot_mac  \n0   0.013333  \n1   0.005464  \n2   0.006711  \n3   0.007092  \n4   0.004831  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mac_num</th>\n      <th>mac_array_num</th>\n      <th>data_bits</th>\n      <th>sram_size</th>\n      <th>max_filter_size</th>\n      <th>tot_mac</th>\n      <th>1/mac_num</th>\n      <th>1/mac_array_num</th>\n      <th>1/data_bits</th>\n      <th>1/sram_size</th>\n      <th>1/max_filter_size</th>\n      <th>1/tot_mac</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>37.0</td>\n      <td>2.0</td>\n      <td>128.0</td>\n      <td>199936.0</td>\n      <td>4098.0</td>\n      <td>74.0</td>\n      <td>0.026316</td>\n      <td>0.333333</td>\n      <td>0.007752</td>\n      <td>0.000005</td>\n      <td>0.000244</td>\n      <td>0.013333</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>91.0</td>\n      <td>2.0</td>\n      <td>256.0</td>\n      <td>119936.0</td>\n      <td>2048.0</td>\n      <td>182.0</td>\n      <td>0.010870</td>\n      <td>0.333333</td>\n      <td>0.003891</td>\n      <td>0.000008</td>\n      <td>0.000488</td>\n      <td>0.005464</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>74.0</td>\n      <td>2.0</td>\n      <td>256.0</td>\n      <td>139904.0</td>\n      <td>1024.0</td>\n      <td>148.0</td>\n      <td>0.013333</td>\n      <td>0.333333</td>\n      <td>0.003891</td>\n      <td>0.000007</td>\n      <td>0.000976</td>\n      <td>0.006711</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>70.0</td>\n      <td>2.0</td>\n      <td>512.0</td>\n      <td>80000.0</td>\n      <td>512.0</td>\n      <td>140.0</td>\n      <td>0.014085</td>\n      <td>0.333333</td>\n      <td>0.001949</td>\n      <td>0.000012</td>\n      <td>0.001949</td>\n      <td>0.007092</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>103.0</td>\n      <td>2.0</td>\n      <td>256.0</td>\n      <td>199936.0</td>\n      <td>4098.0</td>\n      <td>206.0</td>\n      <td>0.009615</td>\n      <td>0.333333</td>\n      <td>0.003891</td>\n      <td>0.000005</td>\n      <td>0.000244</td>\n      <td>0.004831</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "X_val_hw_param.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "\n",
    "#%pycache\n",
    "# Process\n",
    "scaler = preprocessing.StandardScaler().fit(X_train_hw_param)\n",
    "X_train_hw_param_norm= scaler.transform(X_train_hw_param)\n",
    "X_val_hw_param_norm = scaler.transform(X_val_hw_param )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets for HW param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_hw_norm = np.concatenate((X_train_hw_param_norm, X_val_hw_param_norm))\n",
    "X_hw = np.concatenate((X_train_hw_param, X_val_hw_param))\n",
    "y = np.concatenate((y_train, y_val))\n",
    "\n",
    "# Mix train/test\n",
    "#NORMED\n",
    "dataset_hw_norm = tf.data.Dataset.from_tensor_slices((X_hw_norm, y))\n",
    "dataset_hw_norm= dataset_hw_norm.shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "#UNORMED\n",
    "dataset_hw = tf.data.Dataset.from_tensor_slices((X_hw, y))\n",
    "dataset_hw= dataset_hw.shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "\n",
    "# Split them\n",
    "#NORMED\n",
    "train_dataset_hw_norm =  dataset_hw_norm.take(train_size).batch(BATCH_SIZE)\n",
    "test_dataset_hw_norm = dataset_hw_norm.skip(train_size).batch(BATCH_SIZE)\n",
    "\n",
    "#UNORMODED\n",
    "train_dataset_hw =  dataset_hw.take(train_size).batch(BATCH_SIZE)\n",
    "test_dataset_hw = dataset_hw.skip(train_size).batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "# NN TREATEMENT ALONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train_nn =np.array(train['NN_dataframe'].tolist())\n",
    "X_val_nn = np.array(val['NN_dataframe'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divde columns by standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "means = []\n",
    "std = []\n",
    "X_train_nn_norm=X_train_nn\n",
    "X_val_nn_norm = X_val_nn\n",
    "for i in range(nb_param):\n",
    "    #means.append(np.mean(X_train_nn[:,:,i]))\n",
    "    #X_train_nn[:,:,i]=-means[i]\n",
    "    std.append(np.std(X_train_nn[:,:,i]))\n",
    "    X_train_nn[:,:,i]/= std[i]\n",
    "    X_val_nn[:,:,i]/= std[i]  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bad normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "UsageError: Line magic function `%pycache` not found.\n"
    }
   ],
   "source": [
    "%pycache\n",
    "# #Reshape\n",
    "train_reshape= X_train_nn.reshape(X_train_nn.shape[0], -1)\n",
    "val_reshape= X_val_nn.reshape(X_val_nn.shape[0], -1)\n",
    "\n",
    "# # Process\n",
    "scaler = preprocessing.StandardScaler().fit(train_reshape)\n",
    "train_scaled= scaler.transform(train_reshape)\n",
    "val_scaled = scaler.transform(val_reshape)\n",
    "\n",
    "\n",
    "#Re-reshape\n",
    "X_train_nn_norm= train_scaled.reshape(X_train_nn.shape)\n",
    "X_val_nn_norm= val_scaled.reshape(X_val_nn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[290269479.2486268,\n 502976.69976542174,\n 134091.3240227188,\n 135896.62164816633,\n 313.5131629286966,\n 12.21604009918021,\n 0.39038205807298065]"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          0         1         2         3         4         5    6\n0  0.021002  0.000501  1.122578  0.830749  0.009569  0.736736  0.0\n1  0.007001  0.000179  0.841934  0.830749  0.028707  0.736736  0.0\n2  0.006223  0.000159  0.841934  0.738444  0.028707  0.081860  0.0\n3  0.192912  0.004499  0.748385  2.861469  0.025517  0.736736  0.0\n4  0.868103  0.020544  2.899994  3.784524  0.395518  0.736736  0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.021002</td>\n      <td>0.000501</td>\n      <td>1.122578</td>\n      <td>0.830749</td>\n      <td>0.009569</td>\n      <td>0.736736</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.007001</td>\n      <td>0.000179</td>\n      <td>0.841934</td>\n      <td>0.830749</td>\n      <td>0.028707</td>\n      <td>0.736736</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.006223</td>\n      <td>0.000159</td>\n      <td>0.841934</td>\n      <td>0.738444</td>\n      <td>0.028707</td>\n      <td>0.081860</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.192912</td>\n      <td>0.004499</td>\n      <td>0.748385</td>\n      <td>2.861469</td>\n      <td>0.025517</td>\n      <td>0.736736</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.868103</td>\n      <td>0.020544</td>\n      <td>2.899994</td>\n      <td>3.784524</td>\n      <td>0.395518</td>\n      <td>0.736736</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "pd.DataFrame(X_train_nn_norm[0]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets for NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_nn_norm = np.concatenate((X_train_nn_norm, X_val_nn_norm))\n",
    "X_nn = np.concatenate((X_train_nn, X_val_nn))\n",
    "y = np.concatenate((y_train, y_val))\n",
    "\n",
    "# Mix test/train \n",
    "#NORMED\n",
    "dataset_nn_norm = tf.data.Dataset.from_tensor_slices((X_nn_norm, y))\n",
    "dataset_nn_norm= dataset_nn_norm.shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "\n",
    "#UNNORMED\n",
    "dataset_nn = tf.data.Dataset.from_tensor_slices((X_nn, y))\n",
    "dataset_nn.shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "\n",
    "\n",
    "# Split them\n",
    "#NORMED\n",
    "test_dataset_nn_norm = dataset_nn_norm.take(test_size).batch(BATCH_SIZE)\n",
    "train_dataset_nn_norm = dataset_nn_norm.skip(test_size).batch(BATCH_SIZE)\n",
    "\n",
    "#UNORMED\n",
    "test_dataset_nn= dataset_nn.take(test_size).batch(BATCH_SIZE)\n",
    "train_dataset_nn = dataset_nn.skip(test_size).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Dataset (HW_params + NN arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NORMED\n",
    "train_dataset_norm = tf.data.Dataset.from_tensor_slices(((X_train_nn_norm, X_train_hw_param_norm), y_train))\n",
    "test_dataset_norm = tf.data.Dataset.from_tensor_slices(((X_val_nn_norm, X_val_hw_param_norm), y_val))\n",
    "\n",
    "#UNORMED\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(((np.array(X_train_nn), np.array(X_train_hw_param)), y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(((np.array(X_val_nn), np.array(X_val_hw_param)), y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle train/test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pycache\n",
    "# Mix between train/test (mix networks)\n",
    "#NORMED\n",
    "full_dataset_norm = train_dataset_norm.concatenate(test_dataset_norm)\n",
    "full_dataset_norm = full_dataset_norm.shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "\n",
    "test_dataset_norm = full_dataset_norm.take(test_size)\n",
    "train_dataset_norm = full_dataset_norm.skip(test_size)\n",
    "\n",
    "train_dataset_norm = train_dataset_norm.batch(BATCH_SIZE)\n",
    "test_dataset_norm = test_dataset_norm.batch(BATCH_SIZE)\n",
    "\n",
    "\n",
    "#UNORMED\n",
    "full_dataset = train_dataset.concatenate(test_dataset_norm)\n",
    "full_dataset = full_dataset.shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "\n",
    "test_dataset= full_dataset.take(test_size)\n",
    "train_dataset = full_dataset.skip(test_size)\n",
    "\n",
    "train_dataset = train_dataset_norm.batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset_norm.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pycache\n",
    "mini_batches = 2\n",
    "\n",
    "train_dataset_small =train_dataset.take(mini_batches).batch(BATCH_SIZE)\n",
    "test_dataset_small =test_dataset.take(mini_batches).batch(BATCH_SIZE)\n",
    "\n",
    "train_dataset_small_norm =train_dataset_norm.take(mini_batches)\n",
    "test_dataset_small_norm =test_dataset_norm.take(mini_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get loss/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_test = 'model_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(target_power, predicted_power):\n",
    "  return tf.math.abs((target_power - predicted_power)/target_power)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=5e-2,\n",
    "    decay_steps=2,\n",
    "    #decay_steps=nb_training_batches,\n",
    "    decay_rate=0.95)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "PARAMS : 9553\n"
    }
   ],
   "source": [
    "\n",
    " model_nn= tf.keras.Sequential([\n",
    "       layers.GRU(16, return_sequences=True,input_shape=(max_blocks, nb_param)),\n",
    "       #layers.LSTM(16, return_sequences=True),\n",
    "       #layers.LSTM(32),\n",
    "       layers.Conv1D(128, (3), activation='relu', padding=\"same\"),\n",
    "       #layers.Dense(32, activation='relu'),\n",
    "       #layers.Dense(32, activation='relu'),\n",
    "      #layers.Flatten()\n",
    " ])\n",
    "\n",
    "\n",
    "model_hw = tf.keras.Sequential([\n",
    "     layers.Dense(32, activation='relu', input_shape=(nb_hw_param,)),\n",
    "     #layers.Dropout(0.1),\n",
    "     #layers.Dense(32, activation='relu'),\n",
    "     #layers.Dense(16, activation='relu'),\n",
    "     #layers.Dense(16, activation='relu'),\n",
    "     #layers.Dropout(0.1),\n",
    "     layers.Dense(32, activation='linear')\n",
    " ])\n",
    "\n",
    "#concat = tf.keras.layers.Concatenate()([model_nn.output, model_hw.output])\n",
    "concat = tf.keras.layers.multiply([model_nn.output, model_nn.output])\n",
    "\n",
    "output = tf.keras.layers.Dense(units=16, activation='relu')(concat)\n",
    "#output = tf.keras.layers.Dense(units=16, activation='relu')(output)\n",
    "#output = tf.keras.layers.Dense(units=16, activation='relu')(output)\n",
    "output = tf.keras.layers.Dense(units=1, activation='relu')(output)\n",
    "full_model = tf.keras.Model(inputs=[model_nn.input, model_hw.input], outputs=[output])\n",
    "\n",
    "print(f'PARAMS : {full_model.count_params()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_14\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ngru (GRU)                    (None, 37, 16)            1200      \n_________________________________________________________________\nconv1d_5 (Conv1D)            (None, 37, 128)           6272      \n=================================================================\nTotal params: 7,472\nTrainable params: 7,472\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model_nn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "PARAMS : 9553\nEpoch 1/300\n2/2 [==============================] - 9s 4s/step - loss: 0.9988 - val_loss: 0.0000e+00\nEpoch 2/300\n2/2 [==============================] - 2s 1s/step - loss: 0.9380 - val_loss: 0.9501\nEpoch 3/300\n2/2 [==============================] - 2s 1s/step - loss: 1.0905 - val_loss: 0.8720\nEpoch 4/300\n2/2 [==============================] - 2s 1s/step - loss: 0.8051 - val_loss: 0.8531\nEpoch 5/300\n2/2 [==============================] - 3s 1s/step - loss: 0.7576 - val_loss: 0.6886\nEpoch 6/300\n2/2 [==============================] - 2s 1s/step - loss: 0.6372 - val_loss: 0.7432\nEpoch 7/300\n2/2 [==============================] - 3s 1s/step - loss: 0.6744 - val_loss: 0.6522\nEpoch 8/300\n2/2 [==============================] - 2s 1s/step - loss: 0.5924 - val_loss: 0.6503\nEpoch 9/300\n2/2 [==============================] - 2s 928ms/step - loss: 0.5925 - val_loss: 0.6347\nEpoch 10/300\n2/2 [==============================] - 2s 910ms/step - loss: 0.5538 - val_loss: 0.6955\nEpoch 11/300\n2/2 [==============================] - 2s 908ms/step - loss: 0.5475 - val_loss: 0.7068\nEpoch 12/300\n2/2 [==============================] - 2s 908ms/step - loss: 0.5272 - val_loss: 0.6644\nEpoch 13/300\n2/2 [==============================] - 2s 905ms/step - loss: 0.5265 - val_loss: 0.6583\nEpoch 14/300\n2/2 [==============================] - 2s 901ms/step - loss: 0.5276 - val_loss: 0.6801\nEpoch 15/300\n2/2 [==============================] - 2s 952ms/step - loss: 0.5060 - val_loss: 0.7015\nEpoch 16/300\n2/2 [==============================] - 2s 1s/step - loss: 0.5007 - val_loss: 0.6655\nEpoch 17/300\n2/2 [==============================] - 2s 987ms/step - loss: 0.4910 - val_loss: 0.6371\nEpoch 18/300\n2/2 [==============================] - 2s 984ms/step - loss: 0.4928 - val_loss: 0.6411\nEpoch 19/300\n2/2 [==============================] - 2s 974ms/step - loss: 0.4812 - val_loss: 0.6581\nEpoch 20/300\n2/2 [==============================] - 2s 996ms/step - loss: 0.4742 - val_loss: 0.6527\nEpoch 21/300\n2/2 [==============================] - 2s 986ms/step - loss: 0.4628 - val_loss: 0.6303\nEpoch 22/300\n2/2 [==============================] - 2s 1s/step - loss: 0.4544 - val_loss: 0.6295\nEpoch 23/300\n2/2 [==============================] - 2s 878ms/step - loss: 0.4404 - val_loss: 0.6442\nEpoch 24/300\n2/2 [==============================] - 2s 1s/step - loss: 0.4273 - val_loss: 0.6271\nEpoch 25/300\n2/2 [==============================] - 2s 966ms/step - loss: 0.4102 - val_loss: 0.6024\nEpoch 26/300\n2/2 [==============================] - 2s 941ms/step - loss: 0.3942 - val_loss: 0.6052\nEpoch 27/300\n2/2 [==============================] - 2s 1s/step - loss: 0.3802 - val_loss: 0.6043\nEpoch 28/300\n2/2 [==============================] - 2s 915ms/step - loss: 0.3734 - val_loss: 0.5826\nEpoch 29/300\n2/2 [==============================] - 2s 956ms/step - loss: 0.3618 - val_loss: 0.5872\nEpoch 30/300\n2/2 [==============================] - 3s 1s/step - loss: 0.3586 - val_loss: 0.5824\nEpoch 31/300\n2/2 [==============================] - 2s 1s/step - loss: 0.3564 - val_loss: 0.5648\nEpoch 32/300\n2/2 [==============================] - 2s 1s/step - loss: 0.3472 - val_loss: 0.5743\nEpoch 33/300\n2/2 [==============================] - 2s 1s/step - loss: 0.3416 - val_loss: 0.5673\nEpoch 34/300\n2/2 [==============================] - 2s 893ms/step - loss: 0.3317 - val_loss: 0.5788\nEpoch 35/300\n2/2 [==============================] - 2s 1s/step - loss: 0.3258 - val_loss: 0.5886\nEpoch 36/300\n2/2 [==============================] - 2s 1s/step - loss: 0.3214 - val_loss: 0.5802\nEpoch 37/300\n2/2 [==============================] - 2s 1s/step - loss: 0.3146 - val_loss: 0.5950\nEpoch 38/300\n2/2 [==============================] - 2s 969ms/step - loss: 0.3121 - val_loss: 0.5877\nEpoch 39/300\n2/2 [==============================] - 2s 927ms/step - loss: 0.3061 - val_loss: 0.5931\nEpoch 40/300\n2/2 [==============================] - 2s 1s/step - loss: 0.3036 - val_loss: 0.6015\nEpoch 41/300\n2/2 [==============================] - 2s 1s/step - loss: 0.3016 - val_loss: 0.6001\nEpoch 42/300\n2/2 [==============================] - 2s 998ms/step - loss: 0.2996 - val_loss: 0.6141\nEpoch 43/300\n2/2 [==============================] - 2s 1s/step - loss: 0.2989 - val_loss: 0.6066\nEpoch 44/300\n2/2 [==============================] - 2s 925ms/step - loss: 0.2959 - val_loss: 0.6148\nEpoch 45/300\n2/2 [==============================] - 2s 1s/step - loss: 0.2944 - val_loss: 0.6146\nEpoch 46/300\n2/2 [==============================] - 2s 909ms/step - loss: 0.2925 - val_loss: 0.6146\nEpoch 47/300\n2/2 [==============================] - 2s 908ms/step - loss: 0.2893 - val_loss: 0.6228\nEpoch 48/300\n2/2 [==============================] - 2s 1s/step - loss: 0.2878 - val_loss: 0.6221\nEpoch 49/300\n2/2 [==============================] - 2s 985ms/step - loss: 0.2863 - val_loss: 0.6245\nEpoch 50/300\n2/2 [==============================] - 2s 993ms/step - loss: 0.2854 - val_loss: 0.6310\nEpoch 51/300\n2/2 [==============================] - 2s 923ms/step - loss: 0.2858 - val_loss: 0.6291\nEpoch 52/300\n2/2 [==============================] - 2s 1s/step - loss: 0.2826 - val_loss: 0.6328\nEpoch 53/300\n2/2 [==============================] - 2s 977ms/step - loss: 0.2819 - val_loss: 0.6331\nEpoch 54/300\n2/2 [==============================] - 2s 930ms/step - loss: 0.2805 - val_loss: 0.6353\nEpoch 55/300\n2/2 [==============================] - 2s 1s/step - loss: 0.2807 - val_loss: 0.6385\nEpoch 56/300\n2/2 [==============================] - 2s 925ms/step - loss: 0.2810 - val_loss: 0.6387\nEpoch 57/300\n2/2 [==============================] - 2s 865ms/step - loss: 0.2797 - val_loss: 0.6375\nEpoch 58/300\n2/2 [==============================] - 2s 868ms/step - loss: 0.2803 - val_loss: 0.6407\nEpoch 59/300\n2/2 [==============================] - 2s 870ms/step - loss: 0.2783 - val_loss: 0.6394\nEpoch 60/300\n2/2 [==============================] - 2s 871ms/step - loss: 0.2776 - val_loss: 0.6393\nEpoch 61/300\n2/2 [==============================] - 2s 871ms/step - loss: 0.2771 - val_loss: 0.6413\nEpoch 62/300\n2/2 [==============================] - 2s 924ms/step - loss: 0.2769 - val_loss: 0.6438\nEpoch 63/300\n2/2 [==============================] - 2s 890ms/step - loss: 0.2765 - val_loss: 0.6426\nEpoch 64/300\n2/2 [==============================] - 2s 884ms/step - loss: 0.2763 - val_loss: 0.6432\nEpoch 65/300\n2/2 [==============================] - 2s 871ms/step - loss: 0.2756 - val_loss: 0.6453\nEpoch 66/300\n2/2 [==============================] - 2s 999ms/step - loss: 0.2753 - val_loss: 0.6453\nEpoch 67/300\n2/2 [==============================] - 2s 1s/step - loss: 0.2750 - val_loss: 0.6441\nEpoch 68/300\n2/2 [==============================] - 2s 1s/step - loss: 0.2751 - val_loss: 0.6439\nEpoch 69/300\n2/2 [==============================] - 2s 1s/step - loss: 0.2753 - val_loss: 0.6457\nEpoch 70/300\n2/2 [==============================] - 3s 1s/step - loss: 0.2747 - val_loss: 0.6454\nEpoch 71/300\n2/2 [==============================] - 3s 1s/step - loss: 0.2742 - val_loss: 0.6449\nEpoch 72/300\n2/2 [==============================] - 2s 1s/step - loss: 0.2743 - val_loss: 0.6448\nEpoch 73/300\n2/2 [==============================] - 4s 2s/step - loss: 0.2740 - val_loss: 0.6459\nEpoch 74/300\n2/2 [==============================] - 3s 2s/step - loss: 0.2747 - val_loss: 0.6443\nEpoch 75/300\n2/2 [==============================] - 3s 1s/step - loss: 0.2742 - val_loss: 0.6450\nEpoch 76/300\n2/2 [==============================] - 2s 1s/step - loss: 0.2738 - val_loss: 0.6444\nEpoch 77/300\n2/2 [==============================] - 4s 2s/step - loss: 0.2727 - val_loss: 0.6451\nEpoch 78/300\n2/2 [==============================] - 3s 1s/step - loss: 0.2739 - val_loss: 0.6460\nEpoch 79/300\n2/2 [==============================] - 2s 1s/step - loss: 0.2737 - val_loss: 0.6443\nEpoch 80/300\n2/2 [==============================] - 2s 998ms/step - loss: 0.2726 - val_loss: 0.6445\nEpoch 81/300\n2/2 [==============================] - 2s 1s/step - loss: 0.2727 - val_loss: 0.6450\nEpoch 82/300\n2/2 [==============================] - 2s 1s/step - loss: 0.2722 - val_loss: 0.6440\nEpoch 83/300\n2/2 [==============================] - 2s 982ms/step - loss: 0.2726 - val_loss: 0.6457\nEpoch 84/300\n2/2 [==============================] - 2s 978ms/step - loss: 0.2728 - val_loss: 0.6445\nEpoch 85/300\n2/2 [==============================] - 2s 1s/step - loss: 0.2718 - val_loss: 0.6452\nEpoch 86/300\n2/2 [==============================] - 2s 1s/step - loss: 0.2714 - val_loss: 0.6441\nEpoch 87/300\n2/2 [==============================] - 2s 968ms/step - loss: 0.2725 - val_loss: 0.6455\nEpoch 88/300\n2/2 [==============================] - 2s 1s/step - loss: 0.2715 - val_loss: 0.6451\nEpoch 89/300\n2/2 [==============================] - 3s 1s/step - loss: 0.2723 - val_loss: 0.6457\nEpoch 90/300\n2/2 [==============================] - 3s 1s/step - loss: 0.2711 - val_loss: 0.6458\nEpoch 91/300\n2/2 [==============================] - 2s 1s/step - loss: 0.2725 - val_loss: 0.6448\nEpoch 92/300\n2/2 [==============================] - 2s 1s/step - loss: 0.2718 - val_loss: 0.6446\nEpoch 93/300\n2/2 [==============================] - 4s 2s/step - loss: 0.2714 - val_loss: 0.6462\nEpoch 94/300\n2/2 [==============================] - 4s 2s/step - loss: 0.2712 - val_loss: 0.6456\nEpoch 95/300\n2/2 [==============================] - 2s 980ms/step - loss: 0.2723 - val_loss: 0.6453\nEpoch 96/300\n2/2 [==============================] - 2s 1s/step - loss: 0.2716 - val_loss: 0.6453\nEpoch 97/300\n2/2 [==============================] - 2s 930ms/step - loss: 0.2716 - val_loss: 0.6434\nEpoch 98/300\n2/2 [==============================] - 2s 1s/step - loss: 0.2719 - val_loss: 0.6451\nEpoch 99/300\n2/2 [==============================] - 2s 967ms/step - loss: 0.2711 - val_loss: 0.6450\nEpoch 100/300\n2/2 [==============================] - 2s 1s/step - loss: 0.2717 - val_loss: 0.6443\nEpoch 101/300\n2/2 [==============================] - 2s 909ms/step - loss: 0.2708 - val_loss: 0.6456\nEpoch 102/300\n2/2 [==============================] - 2s 1s/step - loss: 0.2698 - val_loss: 0.6455\nEpoch 103/300\n2/2 [==============================] - 2s 807ms/step - loss: 0.2846\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-430e29f4e2ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset_small_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m  )\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "full_epochs = 300\n",
    "\n",
    "print(f'PARAMS : {full_model.count_params()}')\n",
    "t4= time.clock()\n",
    "full_model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "\n",
    "history = full_model.fit(train_dataset_small_norm,\n",
    "        validation_data=(test_dataset_small_norm),\n",
    "        epochs=full_epochs,\n",
    "       verbose=1,\n",
    " )\n",
    "\n",
    "\n",
    "# history = full_model.fit(train_dataset_norm,\n",
    "#          validation_data=(test_dataset_norm),\n",
    "#         epochs=full_epochs,\n",
    "#          verbose=1,\n",
    "#  )\n",
    "\n",
    "t5= time.clock()\n",
    "\n",
    "print(f'Training Full Model for {full_epochs} epochs : {(t5-t4)/60} min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10,785 params:\n",
    "### 25 epochs : 56 min\n",
    "### 15 epochs : 34 min\n",
    "\n",
    "## 57,009 params\n",
    "### 20 epochs : 101 min\n",
    "\n",
    "## 143,345 params\n",
    "### 20 epochs : 276 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-87-d9b3ed997edd>, line 10)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-87-d9b3ed997edd>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    path = \"\"/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/results_best_models/multiply/only_inversed_hw\"model = full_model\u001b[0m\n\u001b[0m                                                                                                                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "nb_final_epochs_for_mean = 2\n",
    "print(f'PARAMS : {full_model.count_params()}')\n",
    "name = f'{name_test}_{full_model.count_params()}_param'\n",
    "save = True\n",
    "\n",
    "nb_predictions = 1000\n",
    "max_val_loss=53\n",
    "\n",
    "\n",
    "path = \"/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/results_best_models/RNN\"\n",
    "model = full_model\n",
    "X_val_list = [X_val_nn_norm, X_val_hw_param_norm]\n",
    "history = history\n",
    "\n",
    "#model = full_model\n",
    "#X_list = [X_val_hw_param_norm, X_val_nn_norm]\n",
    "\n",
    "s#ave_model(path=path, model= model, history=history, X_list=X_val_list, y=y_val, name=name, nb_predictions  b_predictions, max_val_loss=max_val_loss, nb_final_epochs_for_mean = nb_final_epochs_for_mean, save=save)\n",
    "\n",
    "\n",
    "t6= time.clock()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'model_4_62273_param'"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total time : 1.4952906166666666 min\n"
    }
   ],
   "source": [
    "print(f'Total time : {(t6-tin)/60} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "len(X_val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (16686,37,7) into shape (16686)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-9011ed2915ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mperm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPermutationImportance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0meli5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/eli5/sklearn/permutation_importance.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"prefit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (16686,37,7) into shape (16686)"
     ]
    }
   ],
   "source": [
    "\n",
    "#X=list(zip(X_val_nn_norm, X_val_hw_param_norm))\n",
    "X= X_val_list\n",
    "y = y_val\n",
    "\n",
    "\n",
    "def score(X_list,y):\n",
    "    losses=[]\n",
    "    inputs =[]\n",
    "    for i in range(len(X_list[0])):\n",
    "        for x in range(len(X_list)): # whether one or multiple inputs\n",
    "            input_x=np.array(X_list[x])[i]\n",
    "            input_x=input_x.reshape((1,*input_x.shape))\n",
    "            inputs.append(tf.convert_to_tensor(input_x))\n",
    "        pred = model.predict(inputs)\n",
    "        losses.append(loss(y[i],pred))\n",
    "    return losses\n",
    "\n",
    "perm = PermutationImportance(full_model, random_state=1, scoring=score).fit(X,y)\n",
    "eli5.show_weights(perm, feature_names = X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "index 10 is out of bounds for axis 0 with size 10",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-184eaa5627fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-184eaa5627fa>\u001b[0m in \u001b[0;36mscore\u001b[0;34m(X_list, y)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 10 is out of bounds for axis 0 with size 10"
     ]
    }
   ],
   "source": [
    "def score(X_list,y):\n",
    "    losses=[]\n",
    "    inputs =[]\n",
    "    for i in range(len(X_list[0])):\n",
    "        for x in range(len(X_list)): # whether one or multiple inputs\n",
    "            input_x=np.array(X_list[x])[i]\n",
    "            input_x=input_x.reshape((1,*input_x.shape))\n",
    "            inputs.append(tf.convert_to_tensor(input_x))\n",
    "        pred = model.predict(inputs)\n",
    "        losses.append(loss(y[i],pred))\n",
    "    return losses\n",
    "\n",
    "score(X_val_list[:10],y_val[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'get_score_importances' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-423608e255c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbase_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_decreases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_score_importances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_score_importances' is not defined"
     ]
    }
   ],
   "source": [
    "base_score, score_decreases = get_score_importances(score, X_val_list, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-6d90bcb39294>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mX_val_nn_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val_hw_param_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "(X_val_nn_norm, X_val_hw_param_norm).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (16686,37,7) into shape (16686)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-9af762860c43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_nn_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val_hw_param_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (16686,37,7) into shape (16686)"
     ]
    }
   ],
   "source": [
    "np.asarray((X_val_nn_norm, X_val_hw_param_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bithascondabd8f1537e5d34ba799ef15b8707e6526",
   "display_name": "Python 3.6.10 64-bit ('has': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}