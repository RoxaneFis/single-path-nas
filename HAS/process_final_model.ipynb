{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "from numpy import savetxt, loadtxt, asarray\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import ast\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import seaborn as sns\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from progressbar import ProgressBar\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import Sequential, Model\n",
    "from random import randrange\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras import Input\n",
    "import time\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "\n",
    "from plot_figures import save_model\n",
    "\n",
    "pbar = ProgressBar()\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "max_blocks = 37 #(36 + 1 FC layer at the end)\n",
    "nb_param =7\n",
    "nb_hw_param = 12\n",
    "\n",
    "inversed = True\n",
    "only_inversed = False\n",
    "\n",
    "if inversed and not only_inversed:\n",
    "    path_entire_model= \"/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/results_best_models/multiply/with_inversed_hw\"\n",
    "elif only_inversed:\n",
    "    path_entire_model= \"/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/results_best_models/multiply/only_inversed_hw\"\n",
    "else : \n",
    "    path_entire_model= \"/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/results_best_models/multiply/no_inversed_hw\"\n",
    "\n",
    "BATCH_SIZE = 2048\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "\n",
    "DATASET_SIZE = 168308\n",
    "train_size = int(0.90 * DATASET_SIZE) #135 805\n",
    "test_size = int(0.10 * DATASET_SIZE) # 15 089\n",
    "\n",
    "nb_training_batches = train_size //BATCH_SIZE +1\n",
    "nb_test_batches = test_size //BATCH_SIZE +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def from_np_array(array_string):\n",
    "    array_string = ','.join(array_string.replace('[ ', '[').split())\n",
    "    return np.asarray(ast.literal_eval(array_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Proccessed Neural Networks (without HyperParameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_raw_val = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/good_data/parsed_nondups_val_3.csv'\n",
    "path_processed_val_nn = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/good_data/val7_from1600.csv'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total time : 0.1831873 min\n"
    }
   ],
   "source": [
    "#%pycache\n",
    "tin= time.clock()   \n",
    "val = pd.read_csv(path_processed_val_nn,converters={'NN_dataframe': from_np_array})\n",
    "tfin= time.clock()\n",
    "print(f'Total time : {(tfin-tin)/60} min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete to zeros (max shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape(arr):\n",
    "    return arr.shape[0]\n",
    "\n",
    "def add_zero_blocks(arr):\n",
    "    zero_blocks = np.zeros((max_blocks-arr.shape[0],arr.shape[1]))\n",
    "    return np.append(arr, zero_blocks, axis=0)\n",
    "\n",
    "val[\"nb_blocks\"] = val[\"NN_dataframe\"].apply(lambda x : get_shape(x))\n",
    "val['NN_dataframe']= val['NN_dataframe'].apply(lambda x : add_zero_blocks(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Get y_train, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To retrieve y_train / y_test\n",
    "\n",
    "#train_hw = pd.read_csv(path_raw_train)\n",
    "val_hw = pd.read_csv(path_raw_val)\n",
    "\n",
    "#y_train = np.array(train_hw[\"total_power\"].tolist())\n",
    "#y_train=y_train.reshape(y_train.shape[0],-1)\n",
    "\n",
    "y_val = np.array(val_hw[\"total_power\"].tolist())\n",
    "y_val=y_val.reshape(y_val.shape[0],-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "# HW PARAM ALONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_hw_param  = train_hw[['mac_num', 'mac_array_num', 'data_bits', 'sram_size', 'max_filter_size']]\n",
    "#X_train_hw_param['tot_mac'] = X_train_hw_param['mac_num']*X_train_hw_param['mac_array_num']\n",
    "\n",
    "X_val_hw_param  = val_hw[['mac_num', 'mac_array_num', 'data_bits', 'sram_size', 'max_filter_size']]\n",
    "X_val_hw_param['tot_mac'] = X_val_hw_param['mac_num']*X_val_hw_param['mac_array_num']\n",
    "\n",
    "#X_train_hw_param.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapes of the blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_shape = np.array(train[\"nb_blocks\"])\n",
    "X_val_shape = np.array(val[\"nb_blocks\"])\n",
    "\n",
    "#X_val_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 24274/24274 [00:00<00:00, 305918.82it/s]\n100%|██████████| 24274/24274 [00:00<00:00, 435617.56it/s]\n100%|██████████| 24274/24274 [00:00<00:00, 448580.56it/s]\n100%|██████████| 24274/24274 [00:00<00:00, 444858.48it/s]\n100%|██████████| 24274/24274 [00:00<00:00, 416377.13it/s]\n100%|██████████| 24274/24274 [00:00<00:00, 402739.46it/s]\n"
    }
   ],
   "source": [
    "def inv(x):\n",
    "    return 1/(1+x)\n",
    "\n",
    "\n",
    "if inversed : \n",
    "#nb_hw_param = 6\n",
    "    nb_hw_param = 12\n",
    "\n",
    "    X_val_hw_param['1/mac_num'] = X_val_hw_param['mac_num'].progress_apply(lambda x : inv(x))\n",
    "    X_val_hw_param['1/mac_array_num'] = X_val_hw_param['mac_array_num'].progress_apply(lambda x : inv(x))\n",
    "    X_val_hw_param['1/data_bits'] = X_val_hw_param['data_bits'].progress_apply(lambda x : inv(x))\n",
    "    X_val_hw_param['1/sram_size'] = X_val_hw_param['sram_size'].progress_apply(lambda x : inv(x))\n",
    "    X_val_hw_param['1/max_filter_size'] = X_val_hw_param['max_filter_size'].progress_apply(lambda x : inv(x))\n",
    "    X_val_hw_param['1/tot_mac'] = X_val_hw_param['tot_mac'].progress_apply(lambda x : inv(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   mac_num  mac_array_num  data_bits  sram_size  max_filter_size  tot_mac  \\\n0     37.0            2.0      128.0   199936.0           4098.0     74.0   \n1     91.0            2.0      256.0   119936.0           2048.0    182.0   \n2     74.0            2.0      256.0   139904.0           1024.0    148.0   \n3     70.0            2.0      512.0    80000.0            512.0    140.0   \n4    103.0            2.0      256.0   199936.0           4098.0    206.0   \n\n   1/mac_num  1/mac_array_num  1/data_bits  1/sram_size  1/max_filter_size  \\\n0   0.026316         0.333333     0.007752     0.000005           0.000244   \n1   0.010870         0.333333     0.003891     0.000008           0.000488   \n2   0.013333         0.333333     0.003891     0.000007           0.000976   \n3   0.014085         0.333333     0.001949     0.000012           0.001949   \n4   0.009615         0.333333     0.003891     0.000005           0.000244   \n\n   1/tot_mac  \n0   0.013333  \n1   0.005464  \n2   0.006711  \n3   0.007092  \n4   0.004831  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mac_num</th>\n      <th>mac_array_num</th>\n      <th>data_bits</th>\n      <th>sram_size</th>\n      <th>max_filter_size</th>\n      <th>tot_mac</th>\n      <th>1/mac_num</th>\n      <th>1/mac_array_num</th>\n      <th>1/data_bits</th>\n      <th>1/sram_size</th>\n      <th>1/max_filter_size</th>\n      <th>1/tot_mac</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>37.0</td>\n      <td>2.0</td>\n      <td>128.0</td>\n      <td>199936.0</td>\n      <td>4098.0</td>\n      <td>74.0</td>\n      <td>0.026316</td>\n      <td>0.333333</td>\n      <td>0.007752</td>\n      <td>0.000005</td>\n      <td>0.000244</td>\n      <td>0.013333</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>91.0</td>\n      <td>2.0</td>\n      <td>256.0</td>\n      <td>119936.0</td>\n      <td>2048.0</td>\n      <td>182.0</td>\n      <td>0.010870</td>\n      <td>0.333333</td>\n      <td>0.003891</td>\n      <td>0.000008</td>\n      <td>0.000488</td>\n      <td>0.005464</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>74.0</td>\n      <td>2.0</td>\n      <td>256.0</td>\n      <td>139904.0</td>\n      <td>1024.0</td>\n      <td>148.0</td>\n      <td>0.013333</td>\n      <td>0.333333</td>\n      <td>0.003891</td>\n      <td>0.000007</td>\n      <td>0.000976</td>\n      <td>0.006711</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>70.0</td>\n      <td>2.0</td>\n      <td>512.0</td>\n      <td>80000.0</td>\n      <td>512.0</td>\n      <td>140.0</td>\n      <td>0.014085</td>\n      <td>0.333333</td>\n      <td>0.001949</td>\n      <td>0.000012</td>\n      <td>0.001949</td>\n      <td>0.007092</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>103.0</td>\n      <td>2.0</td>\n      <td>256.0</td>\n      <td>199936.0</td>\n      <td>4098.0</td>\n      <td>206.0</td>\n      <td>0.009615</td>\n      <td>0.333333</td>\n      <td>0.003891</td>\n      <td>0.000005</td>\n      <td>0.000244</td>\n      <td>0.004831</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "X_val_hw_param.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = joblib.load('/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/params/hw_scaler.pkl') \n",
    "X_val_hw_param_norm = scaler.transform(X_val_hw_param )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          0         1         2         3         4         5         6  \\\n0 -0.595863 -0.489793 -0.841296  0.754353  2.061669 -0.412974 -0.169928   \n1  0.371807 -0.489793 -0.647015 -0.147927  0.332994 -0.297455 -0.595003   \n2  0.067170 -0.489793 -0.647015  0.077282 -0.530500 -0.333822 -0.527201   \n3 -0.004509 -0.489793 -0.258452 -0.598345 -0.962247 -0.342379 -0.506529   \n4  0.586844 -0.489793 -0.647015  0.754353  2.061669 -0.271784 -0.629517   \n\n          7         8         9        10        11  \n0  0.706748  1.441544 -1.095801 -1.155747  0.067051  \n1  0.706748  0.103602 -0.409372 -0.778893 -0.427118  \n2  0.706748  0.103602 -0.654222 -0.026105 -0.348810  \n3  0.706748 -0.569281  0.447012  1.477272 -0.324896  \n4  0.706748  0.103602 -1.095801 -1.155747 -0.466906  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.595863</td>\n      <td>-0.489793</td>\n      <td>-0.841296</td>\n      <td>0.754353</td>\n      <td>2.061669</td>\n      <td>-0.412974</td>\n      <td>-0.169928</td>\n      <td>0.706748</td>\n      <td>1.441544</td>\n      <td>-1.095801</td>\n      <td>-1.155747</td>\n      <td>0.067051</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.371807</td>\n      <td>-0.489793</td>\n      <td>-0.647015</td>\n      <td>-0.147927</td>\n      <td>0.332994</td>\n      <td>-0.297455</td>\n      <td>-0.595003</td>\n      <td>0.706748</td>\n      <td>0.103602</td>\n      <td>-0.409372</td>\n      <td>-0.778893</td>\n      <td>-0.427118</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.067170</td>\n      <td>-0.489793</td>\n      <td>-0.647015</td>\n      <td>0.077282</td>\n      <td>-0.530500</td>\n      <td>-0.333822</td>\n      <td>-0.527201</td>\n      <td>0.706748</td>\n      <td>0.103602</td>\n      <td>-0.654222</td>\n      <td>-0.026105</td>\n      <td>-0.348810</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.004509</td>\n      <td>-0.489793</td>\n      <td>-0.258452</td>\n      <td>-0.598345</td>\n      <td>-0.962247</td>\n      <td>-0.342379</td>\n      <td>-0.506529</td>\n      <td>0.706748</td>\n      <td>-0.569281</td>\n      <td>0.447012</td>\n      <td>1.477272</td>\n      <td>-0.324896</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.586844</td>\n      <td>-0.489793</td>\n      <td>-0.647015</td>\n      <td>0.754353</td>\n      <td>2.061669</td>\n      <td>-0.271784</td>\n      <td>-0.629517</td>\n      <td>0.706748</td>\n      <td>0.103602</td>\n      <td>-1.095801</td>\n      <td>-1.155747</td>\n      <td>-0.466906</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "pd.DataFrame(X_val_hw_param_norm).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "# NN TREATEMENT ALONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#X_train_nn =np.array(train['NN_dataframe'].tolist())\n",
    "X_val_nn = np.array(val['NN_dataframe'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divde columns by standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "means = []\n",
    "std = np.loadtxt('/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/params/std.csv', delimiter=',')\n",
    "\n",
    "#X_train_nn_norm=X_train_nn.copy()\n",
    "X_val_nn_norm = X_val_nn.copy()\n",
    "for i in range(nb_param):\n",
    "    #means.append(np.mean(X_train_nn[:,:,i]))\n",
    "    #X_train_nn[:,:,i]=-means[i]\n",
    "    #std.append(np.std(X_train_nn[:,:,i]))\n",
    "    if std[i]!=0:\n",
    "        #X_train_nn_norm[:,:,i]/= std[i]\n",
    "        X_val_nn_norm[:,:,i]/= std[i]  \n",
    "\n",
    "#savetxt('std.csv', std, delimiter=',')\n",
    "#data = loadtxt('std.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([2.82669167e+08, 4.74753544e+05, 1.35528508e+05, 1.37473533e+05,\n       3.10471238e+02, 1.21999774e+01, 3.94031395e-01])"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add blocks with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_val_blocks = []\n",
    "for sha in X_val_shape:\n",
    "    ones = np.ones((sha, 1))\n",
    "    zeros = np.zeros((37-sha,1))\n",
    "    X_val_blocks.append(np.concatenate((ones,zeros)))\n",
    "X_val_blocks = np.array(X_val_blocks)# Full Dataset (HW_params + NN arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Dataset (HW_params + NN arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NORMED\n",
    "#train_dataset_norm = tf.data.Dataset.from_tensor_slices(((X_train_nn_norm, X_train_hw_param_norm), y_train))\n",
    "test_dataset_norm = tf.data.Dataset.from_tensor_slices(((X_val_nn_norm, X_val_hw_param_norm), y_val))\n",
    "\n",
    "#train_dataset_norm = tf.data.Dataset.from_tensor_slices(( (X_train_blocks,X_train_nn_norm, X_train_hw_param_norm), y_train) )\n",
    "#test_dataset_norm = tf.data.Dataset.from_tensor_slices(( (X_val_blocks,X_val_nn_norm, X_val_hw_param_norm), y_val) )\n",
    "\n",
    "#train_dataset_norm = train_dataset_norm.shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "test_dataset_norm = test_dataset_norm.shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "\n",
    "#train_dataset_norm = train_dataset_norm.batch(BATCH_SIZE)\n",
    "test_dataset_norm = test_dataset_norm.batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get loss/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "PARAMS : 117729\n"
    }
   ],
   "source": [
    "last_layer = 128\n",
    "\n",
    "input_blocks = Input(shape=(max_blocks, 1),dtype='float32', name='blocks')\n",
    "input_nn = Input(shape=(max_blocks, nb_param), dtype='float32', name='input_nn')\n",
    "\n",
    "\n",
    "\n",
    "output_nn = layers.LSTM(128, return_sequences=True)(input_nn)\n",
    "output_nn=layers.Dense(last_layer,  activation='relu')(output_nn)\n",
    "#output_nn = tf.keras.layers.multiply([output_nn, input_blocks])\n",
    "output_nn =tf.keras.layers.Lambda( lambda x: K.sum(x, axis=1))(output_nn)\n",
    "\n",
    "\n",
    "model_hw = tf.keras.Sequential([\n",
    "     layers.Dense(128, activation='relu', input_shape=(nb_hw_param,)),\n",
    "     layers.Dense(last_layer , activation='linear')\n",
    " ])\n",
    "\n",
    "\n",
    "concat = tf.keras.layers.multiply([output_nn, model_hw.output])\n",
    "concat = tf.keras.layers.Concatenate()([concat,output_nn, model_hw.output])\n",
    "\n",
    "output = tf.keras.layers.Dense(units=32, activation='relu')(concat)\n",
    "output = tf.keras.layers.Dense(units=32, activation='relu')(output)\n",
    "output = tf.keras.layers.Dense(units=1, activation='relu')(output)\n",
    "full_model = tf.keras.Model(inputs=[input_nn, model_hw.input], outputs=[output])\n",
    "#full_model = tf.keras.Model(inputs=[input_blocks, input_nn, model_hw.input], outputs=[output])\n",
    "\n",
    "\n",
    "\n",
    "print(f'PARAMS : {full_model.count_params()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x12b234ba8>"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "checkpoint_path = '/Users/roxanefischer/Desktop/LSTM_3mult_32_117729_param_0.141_error/LSTM_3mult_32_117729_param'\n",
    "full_model.load_weights(checkpoint_path)\n",
    "#results = full_model.evaluate(test_dataset_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(target_power, predicted_power):\n",
    "  return tf.math.abs((target_power - predicted_power)/target_power)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=nb_training_batches,\n",
    "    decay_rate=0.95)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x1a363459d8> and will run it as-is.\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\nCause: Bad argument number for Name: 4, expecting 3\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\nWARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x1a363459d8> and will run it as-is.\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\nCause: Bad argument number for Name: 4, expecting 3\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n12/12 [==============================] - 4s 358ms/step - loss: 0.1409\n"
    }
   ],
   "source": [
    "#%pycache\n",
    "\n",
    "\n",
    "full_model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "full_model.evaluate((test_dataset_norm))\n",
    "\n",
    "t5= time.clock()\n",
    "\n",
    "\n",
    "#print(f'Eval Full Model : {(t5-t4)/60} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "759/759 [==============================] - 13s 18ms/step - loss: 0.1409\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.14092466235160828"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "full_model.evaluate((X_val_nn_norm, X_val_hw_param_norm), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_centers = loadtxt('/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/params/hw_centroids.csv', delimiter=',')\n",
    "hw_centers_unscale = scaler.inverse_transform(hw_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      mac_num  mac_array_num    data_bits      sram_size  max_filter_size  \\\n0   75.964785       2.486868   833.547106   93668.176140       649.951653   \n1  117.008541       3.264456  1456.113216   84107.293832      2240.018941   \n2   60.880135       2.490219   195.103228   96333.481311      1411.857139   \n3   86.742132       3.225397   982.058957  274859.966984      1883.697506   \n4   20.773761      18.059963  1050.057114  133104.908250      2013.275122   \n5    7.690948       2.447323   545.758813  115240.581936      1580.626232   \n6   57.662028       2.640210   372.444101   96072.130567      3540.588412   \n7  160.470151      26.022932   921.348064  181151.430322      2037.905301   \n8   91.468883      17.594773   916.100438  274721.784205      2106.914422   \n9   51.294797       2.228711   158.466006  108974.387647       512.059000   \n\n       tot_mac  1/mac_num  1/mac_array_num  1/data_bits  1/sram_size  \\\n0   185.341827   0.019902         0.305932     0.001698     0.000012   \n1   379.168287   0.012062         0.275778     0.000913     0.000013   \n2   156.285856   0.023805         0.308794     0.006110     0.000012   \n3   262.708980   0.020185         0.267869     0.001942     0.000004   \n4   397.087634   0.077908         0.066835     0.001899     0.000010   \n5    18.294372   0.120950         0.304974     0.004008     0.000011   \n6   153.255594   0.026937         0.300399     0.004419     0.000012   \n7  4079.854238   0.006711         0.039559     0.002542     0.000008   \n8  1397.397085   0.016733         0.064086     0.002380     0.000004   \n9   113.409224   0.027574         0.318951     0.006840     0.000011   \n\n   1/max_filter_size  1/tot_mac  \n0           0.001693   0.008893  \n1           0.000554   0.004806  \n2           0.000764   0.010976  \n3           0.000740   0.007445  \n4           0.000708   0.006738  \n5           0.001033   0.057184  \n6           0.000295   0.011918  \n7           0.000669   0.000269  \n8           0.000657   0.001044  \n9           0.001949   0.013119  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mac_num</th>\n      <th>mac_array_num</th>\n      <th>data_bits</th>\n      <th>sram_size</th>\n      <th>max_filter_size</th>\n      <th>tot_mac</th>\n      <th>1/mac_num</th>\n      <th>1/mac_array_num</th>\n      <th>1/data_bits</th>\n      <th>1/sram_size</th>\n      <th>1/max_filter_size</th>\n      <th>1/tot_mac</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>75.964785</td>\n      <td>2.486868</td>\n      <td>833.547106</td>\n      <td>93668.176140</td>\n      <td>649.951653</td>\n      <td>185.341827</td>\n      <td>0.019902</td>\n      <td>0.305932</td>\n      <td>0.001698</td>\n      <td>0.000012</td>\n      <td>0.001693</td>\n      <td>0.008893</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>117.008541</td>\n      <td>3.264456</td>\n      <td>1456.113216</td>\n      <td>84107.293832</td>\n      <td>2240.018941</td>\n      <td>379.168287</td>\n      <td>0.012062</td>\n      <td>0.275778</td>\n      <td>0.000913</td>\n      <td>0.000013</td>\n      <td>0.000554</td>\n      <td>0.004806</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>60.880135</td>\n      <td>2.490219</td>\n      <td>195.103228</td>\n      <td>96333.481311</td>\n      <td>1411.857139</td>\n      <td>156.285856</td>\n      <td>0.023805</td>\n      <td>0.308794</td>\n      <td>0.006110</td>\n      <td>0.000012</td>\n      <td>0.000764</td>\n      <td>0.010976</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>86.742132</td>\n      <td>3.225397</td>\n      <td>982.058957</td>\n      <td>274859.966984</td>\n      <td>1883.697506</td>\n      <td>262.708980</td>\n      <td>0.020185</td>\n      <td>0.267869</td>\n      <td>0.001942</td>\n      <td>0.000004</td>\n      <td>0.000740</td>\n      <td>0.007445</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20.773761</td>\n      <td>18.059963</td>\n      <td>1050.057114</td>\n      <td>133104.908250</td>\n      <td>2013.275122</td>\n      <td>397.087634</td>\n      <td>0.077908</td>\n      <td>0.066835</td>\n      <td>0.001899</td>\n      <td>0.000010</td>\n      <td>0.000708</td>\n      <td>0.006738</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>7.690948</td>\n      <td>2.447323</td>\n      <td>545.758813</td>\n      <td>115240.581936</td>\n      <td>1580.626232</td>\n      <td>18.294372</td>\n      <td>0.120950</td>\n      <td>0.304974</td>\n      <td>0.004008</td>\n      <td>0.000011</td>\n      <td>0.001033</td>\n      <td>0.057184</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>57.662028</td>\n      <td>2.640210</td>\n      <td>372.444101</td>\n      <td>96072.130567</td>\n      <td>3540.588412</td>\n      <td>153.255594</td>\n      <td>0.026937</td>\n      <td>0.300399</td>\n      <td>0.004419</td>\n      <td>0.000012</td>\n      <td>0.000295</td>\n      <td>0.011918</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>160.470151</td>\n      <td>26.022932</td>\n      <td>921.348064</td>\n      <td>181151.430322</td>\n      <td>2037.905301</td>\n      <td>4079.854238</td>\n      <td>0.006711</td>\n      <td>0.039559</td>\n      <td>0.002542</td>\n      <td>0.000008</td>\n      <td>0.000669</td>\n      <td>0.000269</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>91.468883</td>\n      <td>17.594773</td>\n      <td>916.100438</td>\n      <td>274721.784205</td>\n      <td>2106.914422</td>\n      <td>1397.397085</td>\n      <td>0.016733</td>\n      <td>0.064086</td>\n      <td>0.002380</td>\n      <td>0.000004</td>\n      <td>0.000657</td>\n      <td>0.001044</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>51.294797</td>\n      <td>2.228711</td>\n      <td>158.466006</td>\n      <td>108974.387647</td>\n      <td>512.059000</td>\n      <td>113.409224</td>\n      <td>0.027574</td>\n      <td>0.318951</td>\n      <td>0.006840</td>\n      <td>0.000011</td>\n      <td>0.001949</td>\n      <td>0.013119</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "# data_boths : puissance de 2\n",
    "columns = ['mac_num', 'mac_array_num', 'data_bits', 'sram_size', 'max_filter_size', 'tot_mac', '1/mac_num', '1/mac_array_num', '1/data_bits', '1/sram_size', '1/max_filter_size', '1/tot_mac']\n",
    "pd.DataFrame(hw_centers_unscale, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nindex : 0\nhw_center :[ 0.10237858 -0.42623102  0.2295995  -0.44418862 -0.84591852 -0.2938803\n -0.34642427  0.45720505 -0.65637991  0.38035292  1.08133546 -0.21178732]\n759/759 [==============================] - 14s 18ms/step - loss: 0.2937\n"
    }
   ],
   "source": [
    "ii=0\n",
    "for ii in range(len(hw_centers)):\n",
    "    print()\n",
    "    print(f'index : {ii}')\n",
    "    print(f'hw_center :{hw_centers[ii]}')\n",
    "   # print(f'hw_center_unscale :{hw_centers_unscale[ii]}')\n",
    "    hw_param_array = np.array([hw_centers[ii],]*X_val_hw_param_norm.shape[0])\n",
    "    full_model.evaluate((X_val_nn_norm, hw_param_array), y_val)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('has': conda)",
   "language": "python",
   "name": "python361064bithascondabd8f1537e5d34ba799ef15b8707e6526"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}