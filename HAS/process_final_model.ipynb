{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "from numpy import savetxt, loadtxt, asarray\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import ast\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import seaborn as sns\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from progressbar import ProgressBar\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import Sequential, Model\n",
    "from random import randrange\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras import Input\n",
    "import time\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "\n",
    "from plot_figures import save_model\n",
    "\n",
    "pbar = ProgressBar()\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "max_blocks = 37 #(36 + 1 FC layer at the end)\n",
    "nb_param =7\n",
    "nb_hw_param = 12\n",
    "\n",
    "inversed = True\n",
    "only_inversed = False\n",
    "\n",
    "if inversed and not only_inversed:\n",
    "    path_entire_model= \"/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/results_best_models/multiply/with_inversed_hw\"\n",
    "elif only_inversed:\n",
    "    path_entire_model= \"/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/results_best_models/multiply/only_inversed_hw\"\n",
    "else : \n",
    "    path_entire_model= \"/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/results_best_models/multiply/no_inversed_hw\"\n",
    "\n",
    "BATCH_SIZE = 2048\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "\n",
    "DATASET_SIZE = 168308\n",
    "train_size = int(0.90 * DATASET_SIZE) #135 805\n",
    "test_size = int(0.10 * DATASET_SIZE) # 15 089\n",
    "\n",
    "nb_training_batches = train_size //BATCH_SIZE +1\n",
    "nb_test_batches = test_size //BATCH_SIZE +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def from_np_array(array_string):\n",
    "    array_string = ','.join(array_string.replace('[ ', '[').split())\n",
    "    return np.asarray(ast.literal_eval(array_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Proccessed Neural Networks (without HyperParameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_raw_val = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/good_data/parsed_nondups_val_3.csv'\n",
    "path_processed_val_nn = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/good_data/val7_from1600.csv'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total time : 0.15731295000000003 min\n"
    }
   ],
   "source": [
    "#%pycache\n",
    "tin= time.clock()   \n",
    "val = pd.read_csv(path_processed_val_nn,converters={'NN_dataframe': from_np_array})\n",
    "tfin= time.clock()\n",
    "print(f'Total time : {(tfin-tin)/60} min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete to zeros (max shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape(arr):\n",
    "    return arr.shape[0]\n",
    "\n",
    "def add_zero_blocks(arr):\n",
    "    zero_blocks = np.zeros((max_blocks-arr.shape[0],arr.shape[1]))\n",
    "    return np.append(arr, zero_blocks, axis=0)\n",
    "\n",
    "val[\"nb_blocks\"] = val[\"NN_dataframe\"].apply(lambda x : get_shape(x))\n",
    "val['NN_dataframe']= val['NN_dataframe'].apply(lambda x : add_zero_blocks(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Get y_train, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To retrieve y_train / y_test\n",
    "\n",
    "#train_hw = pd.read_csv(path_raw_train)\n",
    "val_hw = pd.read_csv(path_raw_val)\n",
    "\n",
    "#y_train = np.array(train_hw[\"total_power\"].tolist())\n",
    "#y_train=y_train.reshape(y_train.shape[0],-1)\n",
    "\n",
    "y_val = np.array(val_hw[\"total_power\"].tolist())\n",
    "y_val=y_val.reshape(y_val.shape[0],-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "# HW PARAM ALONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_hw_param  = train_hw[['mac_num', 'mac_array_num', 'data_bits', 'sram_size', 'max_filter_size']]\n",
    "#X_train_hw_param['tot_mac'] = X_train_hw_param['mac_num']*X_train_hw_param['mac_array_num']\n",
    "\n",
    "X_val_hw_param  = val_hw[['mac_num', 'mac_array_num', 'data_bits', 'sram_size', 'max_filter_size']]\n",
    "X_val_hw_param['tot_mac'] = X_val_hw_param['mac_num']*X_val_hw_param['mac_array_num']\n",
    "\n",
    "#X_train_hw_param.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapes of the blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_shape = np.array(train[\"nb_blocks\"])\n",
    "X_val_shape = np.array(val[\"nb_blocks\"])\n",
    "\n",
    "#X_val_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 24274/24274 [00:00<00:00, 497041.72it/s]\n100%|██████████| 24274/24274 [00:00<00:00, 511494.83it/s]\n100%|██████████| 24274/24274 [00:00<00:00, 493533.64it/s]\n100%|██████████| 24274/24274 [00:00<00:00, 515657.94it/s]\n100%|██████████| 24274/24274 [00:00<00:00, 481073.80it/s]\n100%|██████████| 24274/24274 [00:00<00:00, 386300.30it/s]\n"
    }
   ],
   "source": [
    "def inv(x):\n",
    "    return 1/(1+x)\n",
    "\n",
    "\n",
    "if inversed : \n",
    "#nb_hw_param = 6\n",
    "    nb_hw_param = 12\n",
    "\n",
    "    X_val_hw_param['1/mac_num'] = X_val_hw_param['mac_num'].progress_apply(lambda x : inv(x))\n",
    "    X_val_hw_param['1/mac_array_num'] = X_val_hw_param['mac_array_num'].progress_apply(lambda x : inv(x))\n",
    "    X_val_hw_param['1/data_bits'] = X_val_hw_param['data_bits'].progress_apply(lambda x : inv(x))\n",
    "    X_val_hw_param['1/sram_size'] = X_val_hw_param['sram_size'].progress_apply(lambda x : inv(x))\n",
    "    X_val_hw_param['1/max_filter_size'] = X_val_hw_param['max_filter_size'].progress_apply(lambda x : inv(x))\n",
    "    X_val_hw_param['1/tot_mac'] = X_val_hw_param['tot_mac'].progress_apply(lambda x : inv(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   mac_num  mac_array_num  data_bits  sram_size  max_filter_size  tot_mac  \\\n0     37.0            2.0      128.0   199936.0           4098.0     74.0   \n1     91.0            2.0      256.0   119936.0           2048.0    182.0   \n2     74.0            2.0      256.0   139904.0           1024.0    148.0   \n3     70.0            2.0      512.0    80000.0            512.0    140.0   \n4    103.0            2.0      256.0   199936.0           4098.0    206.0   \n\n   1/mac_num  1/mac_array_num  1/data_bits  1/sram_size  1/max_filter_size  \\\n0   0.026316         0.333333     0.007752     0.000005           0.000244   \n1   0.010870         0.333333     0.003891     0.000008           0.000488   \n2   0.013333         0.333333     0.003891     0.000007           0.000976   \n3   0.014085         0.333333     0.001949     0.000012           0.001949   \n4   0.009615         0.333333     0.003891     0.000005           0.000244   \n\n   1/tot_mac  \n0   0.013333  \n1   0.005464  \n2   0.006711  \n3   0.007092  \n4   0.004831  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mac_num</th>\n      <th>mac_array_num</th>\n      <th>data_bits</th>\n      <th>sram_size</th>\n      <th>max_filter_size</th>\n      <th>tot_mac</th>\n      <th>1/mac_num</th>\n      <th>1/mac_array_num</th>\n      <th>1/data_bits</th>\n      <th>1/sram_size</th>\n      <th>1/max_filter_size</th>\n      <th>1/tot_mac</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>37.0</td>\n      <td>2.0</td>\n      <td>128.0</td>\n      <td>199936.0</td>\n      <td>4098.0</td>\n      <td>74.0</td>\n      <td>0.026316</td>\n      <td>0.333333</td>\n      <td>0.007752</td>\n      <td>0.000005</td>\n      <td>0.000244</td>\n      <td>0.013333</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>91.0</td>\n      <td>2.0</td>\n      <td>256.0</td>\n      <td>119936.0</td>\n      <td>2048.0</td>\n      <td>182.0</td>\n      <td>0.010870</td>\n      <td>0.333333</td>\n      <td>0.003891</td>\n      <td>0.000008</td>\n      <td>0.000488</td>\n      <td>0.005464</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>74.0</td>\n      <td>2.0</td>\n      <td>256.0</td>\n      <td>139904.0</td>\n      <td>1024.0</td>\n      <td>148.0</td>\n      <td>0.013333</td>\n      <td>0.333333</td>\n      <td>0.003891</td>\n      <td>0.000007</td>\n      <td>0.000976</td>\n      <td>0.006711</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>70.0</td>\n      <td>2.0</td>\n      <td>512.0</td>\n      <td>80000.0</td>\n      <td>512.0</td>\n      <td>140.0</td>\n      <td>0.014085</td>\n      <td>0.333333</td>\n      <td>0.001949</td>\n      <td>0.000012</td>\n      <td>0.001949</td>\n      <td>0.007092</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>103.0</td>\n      <td>2.0</td>\n      <td>256.0</td>\n      <td>199936.0</td>\n      <td>4098.0</td>\n      <td>206.0</td>\n      <td>0.009615</td>\n      <td>0.333333</td>\n      <td>0.003891</td>\n      <td>0.000005</td>\n      <td>0.000244</td>\n      <td>0.004831</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "X_val_hw_param.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = joblib.load('/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/params/hw_scaler.pkl') \n",
    "X_val_hw_param_norm = scaler.transform(X_val_hw_param )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "    hw_array_test = np.array([1.023785822261557565e-01,-4.262310244296395600e-01,2.295995016604397698e-01,-4.441886177106757483e-01,-8.459185226109141587e-01,-2.938802963497538223e-01,-3.464242712811745339e-01,4.572050514380619490e-01,-6.563799113750447001e-01,3.803529224492657179e-01,1.081335456679819673e+00,-2.117873165907936950e-01])\n",
    "    hw_array_test = hw_array_test.reshape((1, *hw_array_test.shape))\n",
    "    hw_array_test = tf.convert_to_tensor(hw_array_test, dtype=tf.float32)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[7.5964783e+01, 2.4868679e+00, 8.3354712e+02, 9.3668180e+04,\n        6.4995160e+02, 1.8534184e+02, 1.9902330e-02, 3.0593166e-01,\n        1.6979771e-03, 1.2175874e-05, 1.6928774e-03, 8.8932756e-03]],\n      dtype=float32)"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "scaler.inverse_transform(hw_array_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          0         1         2         3         4         5         6  \\\n0 -0.595863 -0.489793 -0.841296  0.754353  2.061669 -0.412974 -0.169928   \n1  0.371807 -0.489793 -0.647015 -0.147927  0.332994 -0.297455 -0.595003   \n2  0.067170 -0.489793 -0.647015  0.077282 -0.530500 -0.333822 -0.527201   \n3 -0.004509 -0.489793 -0.258452 -0.598345 -0.962247 -0.342379 -0.506529   \n4  0.586844 -0.489793 -0.647015  0.754353  2.061669 -0.271784 -0.629517   \n\n          7         8         9        10        11  \n0  0.706748  1.441544 -1.095801 -1.155747  0.067051  \n1  0.706748  0.103602 -0.409372 -0.778893 -0.427118  \n2  0.706748  0.103602 -0.654222 -0.026105 -0.348810  \n3  0.706748 -0.569281  0.447012  1.477272 -0.324896  \n4  0.706748  0.103602 -1.095801 -1.155747 -0.466906  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.595863</td>\n      <td>-0.489793</td>\n      <td>-0.841296</td>\n      <td>0.754353</td>\n      <td>2.061669</td>\n      <td>-0.412974</td>\n      <td>-0.169928</td>\n      <td>0.706748</td>\n      <td>1.441544</td>\n      <td>-1.095801</td>\n      <td>-1.155747</td>\n      <td>0.067051</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.371807</td>\n      <td>-0.489793</td>\n      <td>-0.647015</td>\n      <td>-0.147927</td>\n      <td>0.332994</td>\n      <td>-0.297455</td>\n      <td>-0.595003</td>\n      <td>0.706748</td>\n      <td>0.103602</td>\n      <td>-0.409372</td>\n      <td>-0.778893</td>\n      <td>-0.427118</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.067170</td>\n      <td>-0.489793</td>\n      <td>-0.647015</td>\n      <td>0.077282</td>\n      <td>-0.530500</td>\n      <td>-0.333822</td>\n      <td>-0.527201</td>\n      <td>0.706748</td>\n      <td>0.103602</td>\n      <td>-0.654222</td>\n      <td>-0.026105</td>\n      <td>-0.348810</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.004509</td>\n      <td>-0.489793</td>\n      <td>-0.258452</td>\n      <td>-0.598345</td>\n      <td>-0.962247</td>\n      <td>-0.342379</td>\n      <td>-0.506529</td>\n      <td>0.706748</td>\n      <td>-0.569281</td>\n      <td>0.447012</td>\n      <td>1.477272</td>\n      <td>-0.324896</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.586844</td>\n      <td>-0.489793</td>\n      <td>-0.647015</td>\n      <td>0.754353</td>\n      <td>2.061669</td>\n      <td>-0.271784</td>\n      <td>-0.629517</td>\n      <td>0.706748</td>\n      <td>0.103602</td>\n      <td>-1.095801</td>\n      <td>-1.155747</td>\n      <td>-0.466906</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "pd.DataFrame(X_val_hw_param_norm).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "# NN TREATEMENT ALONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#X_train_nn =np.array(train['NN_dataframe'].tolist())\n",
    "X_val_nn = np.array(val['NN_dataframe'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divde columns by standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "means = []\n",
    "std = np.loadtxt('/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/params/std.csv', delimiter=',')\n",
    "\n",
    "#X_train_nn_norm=X_train_nn.copy()\n",
    "X_val_nn_norm = X_val_nn.copy()\n",
    "for i in range(nb_param):\n",
    "    #means.append(np.mean(X_train_nn[:,:,i]))\n",
    "    #X_train_nn[:,:,i]=-means[i]\n",
    "    #std.append(np.std(X_train_nn[:,:,i]))\n",
    "    if std[i]!=0:\n",
    "        #X_train_nn_norm[:,:,i]/= std[i]\n",
    "        X_val_nn_norm[:,:,i]/= std[i]  \n",
    "\n",
    "#savetxt('std.csv', std, delimiter=',')\n",
    "#data = loadtxt('std.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "amir_test = np.array([[2.1676032e+07, 8.6400000e+02, 1.5052800e+05, 4.0140800e+05,\n",
    "        3.0000000e+00, 9.0000000e+00, 0.0000000e+00],\n",
    "       [4.5760512e+07, 8.0000000e+02, 4.0140800e+05, 2.0070400e+05,\n",
    "        3.2000000e+01, 9.0000000e+00, 0.0000000e+00],\n",
    "       [6.8038656e+07, 6.2400000e+03, 2.0070400e+05, 7.5264000e+04,\n",
    "        9.6000000e+01, 2.5000000e+01, 0.0000000e+00],\n",
    "       [6.6006528e+07, 1.0512000e+04, 7.5264000e+04, 7.5264000e+04,\n",
    "        1.4400000e+02, 2.5000000e+01, 1.0000000e+00],\n",
    "       [6.6006528e+07, 1.0512000e+04, 7.5264000e+04, 7.5264000e+04,\n",
    "        1.4400000e+02, 2.5000000e+01, 1.0000000e+00],\n",
    "       [6.6006528e+07, 1.0512000e+04, 7.5264000e+04, 7.5264000e+04,\n",
    "        1.4400000e+02, 2.5000000e+01, 1.0000000e+00],\n",
    "       [3.6352512e+07, 1.2816000e+04, 7.5264000e+04, 3.1360000e+04,\n",
    "        1.4400000e+02, 2.5000000e+01, 0.0000000e+00],\n",
    "       [3.9544960e+07, 2.5200000e+04, 3.1360000e+04, 3.1360000e+04,\n",
    "        2.4000000e+02, 2.5000000e+01, 1.0000000e+00],\n",
    "       [3.9544960e+07, 2.5200000e+04, 3.1360000e+04, 3.1360000e+04,\n",
    "        2.4000000e+02, 2.5000000e+01, 1.0000000e+00],\n",
    "       [3.9544960e+07, 2.5200000e+04, 3.1360000e+04, 3.1360000e+04,\n",
    "        2.4000000e+02, 2.5000000e+01, 1.0000000e+00],\n",
    "       [2.4931200e+07, 3.4800000e+04, 3.1360000e+04, 1.5680000e+04,\n",
    "        2.4000000e+02, 2.5000000e+01, 0.0000000e+00],\n",
    "       [3.4825280e+07, 8.8800000e+04, 1.5680000e+04, 1.5680000e+04,\n",
    "        4.8000000e+02, 2.5000000e+01, 1.0000000e+00],\n",
    "       [3.4825280e+07, 8.8800000e+04, 1.5680000e+04, 1.5680000e+04,\n",
    "        4.8000000e+02, 2.5000000e+01, 1.0000000e+00],\n",
    "       [3.4825280e+07, 8.8800000e+04, 1.5680000e+04, 1.5680000e+04,\n",
    "        4.8000000e+02, 2.5000000e+01, 1.0000000e+00],\n",
    "       [3.7820160e+07, 9.6480000e+04, 1.5680000e+04, 1.8816000e+04,\n",
    "        4.8000000e+02, 2.5000000e+01, 0.0000000e+00],\n",
    "       [4.9015680e+07, 1.2499200e+05, 1.8816000e+04, 1.8816000e+04,\n",
    "        5.7600000e+02, 2.5000000e+01, 1.0000000e+00],\n",
    "       [4.9015680e+07, 1.2499200e+05, 1.8816000e+04, 1.8816000e+04,\n",
    "        5.7600000e+02, 2.5000000e+01, 1.0000000e+00],\n",
    "       [4.9015680e+07, 1.2499200e+05, 1.8816000e+04, 1.8816000e+04,\n",
    "        5.7600000e+02, 2.5000000e+01, 1.0000000e+00],\n",
    "       [3.3925248e+07, 1.8028800e+05, 1.8816000e+04, 9.4080000e+03,\n",
    "        5.7600000e+02, 2.5000000e+01, 0.0000000e+00],\n",
    "       [4.6183872e+07, 4.7116800e+05, 9.4080000e+03, 9.4080000e+03,\n",
    "        1.1520000e+03, 2.5000000e+01, 1.0000000e+00],\n",
    "       [4.6183872e+07, 4.7116800e+05, 9.4080000e+03, 9.4080000e+03,\n",
    "        1.1520000e+03, 2.5000000e+01, 1.0000000e+00],\n",
    "       [4.6183872e+07, 4.7116800e+05, 9.4080000e+03, 9.4080000e+03,\n",
    "        1.1520000e+03, 2.5000000e+01, 1.0000000e+00],\n",
    "       [5.8818816e+07, 6.0019200e+05, 9.4080000e+03, 1.5680000e+04,\n",
    "        1.1520000e+03, 9.0000000e+00, 0.0000000e+00],\n",
    "       [4.0140800e+07, 4.0960000e+05, 1.5680000e+04, 6.2720000e+04,\n",
    "        3.2000000e+02, 1.0000000e+00, 0.0000000e+00],\n",
    "       [1.6056320e+08, 1.6396800e+06, 6.2720000e+04, 6.2720000e+04,\n",
    "        1.2800000e+03, 1.0000000e+00, 0.0000000e+00],\n",
    "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
    "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
    "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
    "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
    "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
    "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
    "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
    "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
    "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
    "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
    "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
    "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
    "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
    "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
    "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
    "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
    "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
    "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
    "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
    "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
    "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
    "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
    "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
    "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([2.77884803e+08, 4.61103797e+05, 1.36894478e+05, 1.38975805e+05,\n       3.11840030e+02, 1.21890588e+01, 3.94164309e-01])"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nb_param):\n",
    "    #means.append(np.mean(X_train_nn[:,:,i]))\n",
    "    #X_train_nn[:,:,i]=-means[i]\n",
    "    #std.append(np.std(X_train_nn[:,:,i]))\n",
    "    if std[i]!=0:\n",
    "        #X_train_nn_norm[:,:,i]/= std[i]\n",
    "       amir_test[:,i]/= std[i]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[7.80036612e-02, 1.87376466e-03, 1.09959146e+00, 2.88833009e+00,\n        9.62031719e-03, 7.38367098e-01, 0.00000000e+00],\n       [1.64674396e-01, 1.73496728e-03, 2.93224390e+00, 1.44416505e+00,\n        1.02616717e-01, 7.38367098e-01, 0.00000000e+00],\n       [2.44844826e-01, 1.35327448e-02, 1.46612195e+00, 5.41561892e-01,\n        3.07850150e-01, 2.05101972e+00, 0.00000000e+00],\n       [2.37531982e-01, 2.27974700e-02, 5.49795732e-01, 5.41561892e-01,\n        4.61775225e-01, 2.05101972e+00, 2.53701306e+00],\n       [2.37531982e-01, 2.27974700e-02, 5.49795732e-01, 5.41561892e-01,\n        4.61775225e-01, 2.05101972e+00, 2.53701306e+00],\n       [2.37531982e-01, 2.27974700e-02, 5.49795732e-01, 5.41561892e-01,\n        4.61775225e-01, 2.05101972e+00, 2.53701306e+00],\n       [1.30818640e-01, 2.77941758e-02, 5.49795732e-01, 2.25650788e-01,\n        4.61775225e-01, 2.05101972e+00, 0.00000000e+00],\n       [1.42307027e-01, 5.46514693e-02, 2.29081555e-01, 2.25650788e-01,\n        7.69625375e-01, 2.05101972e+00, 2.53701306e+00],\n       [1.42307027e-01, 5.46514693e-02, 2.29081555e-01, 2.25650788e-01,\n        7.69625375e-01, 2.05101972e+00, 2.53701306e+00],\n       [1.42307027e-01, 5.46514693e-02, 2.29081555e-01, 2.25650788e-01,\n        7.69625375e-01, 2.05101972e+00, 2.53701306e+00],\n       [8.97177527e-02, 7.54710766e-02, 2.29081555e-01, 1.12825394e-01,\n        7.69625375e-01, 2.05101972e+00, 0.00000000e+00],\n       [1.25322723e-01, 1.92581368e-01, 1.14540778e-01, 1.12825394e-01,\n        1.53925075e+00, 2.05101972e+00, 2.53701306e+00],\n       [1.25322723e-01, 1.92581368e-01, 1.14540778e-01, 1.12825394e-01,\n        1.53925075e+00, 2.05101972e+00, 2.53701306e+00],\n       [1.25322723e-01, 1.92581368e-01, 1.14540778e-01, 1.12825394e-01,\n        1.53925075e+00, 2.05101972e+00, 2.53701306e+00],\n       [1.36100138e-01, 2.09237054e-01, 1.14540778e-01, 1.35390473e-01,\n        1.53925075e+00, 2.05101972e+00, 0.00000000e+00],\n       [1.76388487e-01, 2.71071288e-01, 1.37448933e-01, 1.35390473e-01,\n        1.84710090e+00, 2.05101972e+00, 2.53701306e+00],\n       [1.76388487e-01, 2.71071288e-01, 1.37448933e-01, 1.35390473e-01,\n        1.84710090e+00, 2.05101972e+00, 2.53701306e+00],\n       [1.76388487e-01, 2.71071288e-01, 1.37448933e-01, 1.35390473e-01,\n        1.84710090e+00, 2.05101972e+00, 2.53701306e+00],\n       [1.22083855e-01, 3.90992226e-01, 1.37448933e-01, 6.76952365e-02,\n        1.84710090e+00, 2.05101972e+00, 0.00000000e+00],\n       [1.66197905e-01, 1.02182633e+00, 6.87244665e-02, 6.76952365e-02,\n        3.69420180e+00, 2.05101972e+00, 2.53701306e+00],\n       [1.66197905e-01, 1.02182633e+00, 6.87244665e-02, 6.76952365e-02,\n        3.69420180e+00, 2.05101972e+00, 2.53701306e+00],\n       [1.66197905e-01, 1.02182633e+00, 6.87244665e-02, 6.76952365e-02,\n        3.69420180e+00, 2.05101972e+00, 2.53701306e+00],\n       [2.11666185e-01, 1.30164185e+00, 6.87244665e-02, 1.12825394e-01,\n        3.69420180e+00, 7.38367098e-01, 0.00000000e+00],\n       [1.44451224e-01, 8.88303246e-01, 1.14540778e-01, 4.51301577e-01,\n        1.02616717e+00, 8.20407887e-02, 0.00000000e+00],\n       [5.77804898e-01, 3.55598893e+00, 4.58163110e-01, 4.51301577e-01,\n        4.10466867e+00, 8.20407887e-02, 0.00000000e+00],\n       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "amir_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add blocks with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_val_blocks = []\n",
    "for sha in X_val_shape:\n",
    "    ones = np.ones((sha, 1))\n",
    "    zeros = np.zeros((37-sha,1))\n",
    "    X_val_blocks.append(np.concatenate((ones,zeros)))\n",
    "X_val_blocks = np.array(X_val_blocks)# Full Dataset (HW_params + NN arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = ((X_val_nn_norm, X_val_hw_param_norm), y_val)\n",
    "index = []\n",
    "#X_small = [(),()]\n",
    "for Y in X[1] :\n",
    "    for i in range(len(Y)):\n",
    "        #print(Y[i])\n",
    "        if Y[i] > 40 and Y[i] < 65 :\n",
    "            index.append(i)\n",
    "X_restrained = ((X_val_nn_norm[index], X_val_hw_param_norm[index]), y_val[index])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "24274"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "len(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4208"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "len(X_restrained[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Dataset (HW_params + NN arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NORMED\n",
    "#train_dataset_norm = tf.data.Dataset.from_tensor_slices(((X_train_nn_norm, X_train_hw_param_norm), y_train))\n",
    "#test_dataset_norm = tf.data.Dataset.from_tensor_slices(((X_val_nn_norm, X_val_hw_param_norm), y_val))\n",
    "test_dataset_norm = tf.data.Dataset.from_tensor_slices((X_restrained))\n",
    "\n",
    "#train_dataset_norm = tf.data.Dataset.from_tensor_slices(( (X_train_blocks,X_train_nn_norm, X_train_hw_param_norm), y_train) )\n",
    "#test_dataset_norm = tf.data.Dataset.from_tensor_slices(( (X_val_blocks,X_val_nn_norm, X_val_hw_param_norm), y_val) )\n",
    "\n",
    "#train_dataset_norm = train_dataset_norm.shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "SHUFFLE_BUFFER_SIZE = 4\n",
    "BATCH_SIZE = 128\n",
    "test_dataset_norm = test_dataset_norm.shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "\n",
    "#train_dataset_norm = train_dataset_norm.batch(BATCH_SIZE)\n",
    "test_dataset_norm = test_dataset_norm.batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get loss/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_1(target_power, predicted_power):\n",
    "  return tf.math.abs((target_power - predicted_power)/target_power)\n",
    "\n",
    "def loss_2(target_power, predicted_power):\n",
    "  return tf.math.abs((target_power[:,0] - predicted_power[:,0])/target_power[:,0]) +tf.math.abs((target_power[:,1] - predicted_power[:,1])/target_power[:,1])\n",
    "\n",
    "#def loss(target_power, predicted_power):\n",
    " # return tf.math.abs((target_power - predicted_power)/target_power)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=nb_training_batches,\n",
    "    decay_rate=0.95)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "PARAMS : 117762\n"
    }
   ],
   "source": [
    "last_layer = 128\n",
    "\n",
    "multiple_power = True\n",
    "\n",
    "if multiple_power ==True :\n",
    "\n",
    "    checkpoint_path = '/Users/roxanefischer/Desktop/a_images/two_power/all_0.279_error/all'\n",
    "    output_shape = 2\n",
    "    #train_dataset = train_dataset_mult\n",
    "    #test_dataset = test_dataset_mult\n",
    "    loss = loss_2\n",
    "else :\n",
    "    checkpoint_path = '/Users/roxanefischer/Desktop/LSTM_3mult_32_117729_param_0.141_error/LSTM_3mult_32_117729_param'\n",
    "    output_shape = 1\n",
    "    #train_dataset = train_dataset_norm\n",
    "    #test_dataset = test_dataset_norm\n",
    "    loss = loss_1\n",
    "\n",
    "#input_blocks = Input(shape=(max_blocks, 1),dtype='float32', name='blocks')\n",
    "input_nn = Input(shape=(max_blocks, nb_param), dtype='float32', name='input_nn')\n",
    "output_nn = layers.LSTM(128, return_sequences=True)(input_nn)\n",
    "output_nn=layers.Dense(last_layer,  activation='relu')(output_nn)\n",
    "#output_nn = tf.keras.layers.multiply([output_nn, input_blocks])\n",
    "output_nn =tf.keras.layers.Lambda( lambda x: K.sum(x, axis=1))(output_nn)\n",
    "\n",
    "\n",
    "model_hw = tf.keras.Sequential([\n",
    "     layers.Dense(128, activation='relu', input_shape=(nb_hw_param,)),\n",
    "     layers.Dense(last_layer , activation='linear')\n",
    " ])\n",
    "\n",
    "concat = tf.keras.layers.multiply([output_nn, model_hw.output])\n",
    "concat = tf.keras.layers.Concatenate()([concat,output_nn, model_hw.output])\n",
    "\n",
    "output = tf.keras.layers.Dense(units=32, activation='relu')(concat)\n",
    "output = tf.keras.layers.Dense(units=32, activation='relu')(output)\n",
    "output = tf.keras.layers.Dense(units=output_shape, activation='relu')(output)\n",
    "full_model = tf.keras.Model(inputs=[input_nn, model_hw.input], outputs=[output])\n",
    "\n",
    "\n",
    "\n",
    "output_mult =tf.keras.layers.Lambda( lambda x: K.sum(x, axis=1))(output)\n",
    "full_model_mult = tf.keras.Model(inputs=[input_nn, model_hw.input], outputs=[output_mult])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Wsave = full_model.get_weights()\n",
    "print(f'PARAMS : {full_model.count_params()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1a3b700ac8>"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "\n",
    "full_model.load_weights(checkpoint_path)\n",
    "#results = full_model.evaluate(test_dataset_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if output_shape == 2:\n",
    "\n",
    "    full_model_mult.compile(optimizer=optimizer, loss=[loss_1])\n",
    "    def updateTargetModel(model, targetModel):\n",
    "      modelWeights       = model.trainable_weights\n",
    "      targetModelWeights = targetModel.trainable_weights\n",
    "\n",
    "      for i in range(len(targetModelWeights)):\n",
    "        targetModelWeights[i].assign(modelWeights[i])\n",
    "    updateTargetModel(full_model, full_model_mult)\n",
    "\n",
    "   # full_model_mult.evaluate((X_val_nn_norm, X_val_hw_param_norm), y_val_core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_9\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_nn (InputLayer)           [(None, 37, 7)]      0                                            \n__________________________________________________________________________________________________\nlstm_4 (LSTM)                   (None, 37, 128)      69632       input_nn[0][0]                   \n__________________________________________________________________________________________________\ndense_25_input (InputLayer)     [(None, 12)]         0                                            \n__________________________________________________________________________________________________\ndense_24 (Dense)                (None, 37, 128)      16512       lstm_4[0][0]                     \n__________________________________________________________________________________________________\ndense_25 (Dense)                (None, 128)          1664        dense_25_input[0][0]             \n__________________________________________________________________________________________________\nlambda_8 (Lambda)               (None, 128)          0           dense_24[0][0]                   \n__________________________________________________________________________________________________\ndense_26 (Dense)                (None, 128)          16512       dense_25[0][0]                   \n__________________________________________________________________________________________________\nmultiply_4 (Multiply)           (None, 128)          0           lambda_8[0][0]                   \n                                                                 dense_26[0][0]                   \n__________________________________________________________________________________________________\nconcatenate_4 (Concatenate)     (None, 384)          0           multiply_4[0][0]                 \n                                                                 lambda_8[0][0]                   \n                                                                 dense_26[0][0]                   \n__________________________________________________________________________________________________\ndense_27 (Dense)                (None, 32)           12320       concatenate_4[0][0]              \n__________________________________________________________________________________________________\ndense_28 (Dense)                (None, 32)           1056        dense_27[0][0]                   \n__________________________________________________________________________________________________\ndense_29 (Dense)                (None, 2)            66          dense_28[0][0]                   \n__________________________________________________________________________________________________\nlambda_9 (Lambda)               (None,)              0           dense_29[0][0]                   \n==================================================================================================\nTotal params: 117,762\nTrainable params: 117,762\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "full_model_mult.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'y_core' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-3ded3660c3c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfull_model_mult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_nn_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val_hw_param_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_core\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_core' is not defined"
     ]
    }
   ],
   "source": [
    "    full_model_mult.evaluate((X_val_nn_norm, X_val_hw_param_norm), y_core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x1a40e4a730> and will run it as-is.\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\nCause: Bad argument number for Name: 4, expecting 3\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\nWARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x1a40e4a730> and will run it as-is.\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\nCause: Bad argument number for Name: 4, expecting 3\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n33/33 [==============================] - 1s 35ms/step - loss: 0.1292\n"
    }
   ],
   "source": [
    "#%pycache\n",
    "\n",
    "\n",
    "full_model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "full_model.evaluate((test_dataset_norm))\n",
    "\n",
    "t5= time.clock()\n",
    "\n",
    "\n",
    "#print(f'Eval Full Model : {(t5-t4)/60} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "759/759 [==============================] - 13s 17ms/step - loss: 0.1409\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.14092466235160828"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "full_model.evaluate((X_val_nn_norm, X_val_hw_param_norm), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_centers = loadtxt('/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/params/hw_centroids.csv', delimiter=',')\n",
    "hw_centers_unscale = scaler.inverse_transform(hw_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_boths : puissance de 2\n",
    "columns = ['mac_num', 'mac_array_num', 'data_bits', 'sram_size', 'max_filter_size', 'tot_mac', '1/mac_num', '1/mac_array_num', '1/data_bits', '1/sram_size', '1/max_filter_size', '1/tot_mac']\n",
    "pd.DataFrame(hw_centers_unscale, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ii=0\n",
    "for ii in range(len(hw_centers)):\n",
    "    print()\n",
    "    print(f'index : {ii}')\n",
    "    print(f'hw_center :{hw_centers[ii]}')\n",
    "   # print(f'hw_center_unscale :{hw_centers_unscale[ii]}')\n",
    "    hw_param_array = np.array([hw_centers[ii],]*X_val_hw_param_norm.shape[0])\n",
    "    full_model.evaluate((X_val_nn_norm, hw_param_array), y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nindex : 0\n[[49.722855]]\n\nindex : 1\n[[57.656647]]\n\nindex : 2\n[[60.51816]]\n\nindex : 3\n[[66.16458]]\n\nindex : 4\n[[39.812965]]\n\nindex : 5\n[[37.970947]]\n\nindex : 6\n[[66.056206]]\n\nindex : 7\n[[84.150375]]\n\nindex : 8\n[[40.023857]]\n\nindex : 9\n[[60.4999]]\n"
    }
   ],
   "source": [
    "ii=0\n",
    "for ii in range(len(hw_centers)):\n",
    "    print()\n",
    "    print(f'index : {ii}')\n",
    "    #print(f'hw_center :{hw_centers[ii]}')\n",
    "   # print(f'hw_center_unscale :{hw_centers_unscale[ii]}')\n",
    "    print(full_model.predict([nn_array_test, hw_centers[ii].reshape(1,12)], steps=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    nn_array_test= np.array([[7.66833971e-02, 1.81989163e-03, 1.11067407e+00, 2.91989295e+00,\n",
    "          9.66273081e-03, 7.37706287e-01, 0.00000000e+00],\n",
    "        [1.61887172e-01, 1.68508484e-03, 2.96179752e+00, 1.45994647e+00,\n",
    "          1.03069129e-01, 7.37706287e-01, 0.00000000e+00],\n",
    "        [2.41410695e-01, 1.31436618e-02, 1.48089876e+00, 5.47479928e-01,\n",
    "          3.09207386e-01, 2.04918413e+00, 2.53786884e+00],\n",
    "        [2.33511595e-01, 2.21420148e-02, 5.55337035e-01, 5.47479928e-01,\n",
    "          4.63811079e-01, 2.04918413e+00, 2.53786884e+00],\n",
    "        [2.33511595e-01, 2.21420148e-02, 5.55337035e-01, 5.47479928e-01,\n",
    "          4.63811079e-01, 2.04918413e+00, 2.53786884e+00],\n",
    "        [2.33511595e-01, 2.21420148e-02, 5.55337035e-01, 5.47479928e-01,\n",
    "          4.63811079e-01, 2.04918413e+00, 2.53786884e+00],\n",
    "        [1.28870709e-01, 2.69950592e-02, 5.55337035e-01, 2.28116637e-01,\n",
    "          4.63811079e-01, 2.04918413e+00, 2.53786884e+00],\n",
    "        [1.39898385e-01, 5.30801725e-02, 2.31390431e-01, 2.28116637e-01,\n",
    "          7.73018465e-01, 2.04918413e+00, 2.53786884e+00],\n",
    "        [1.39898385e-01, 5.30801725e-02, 2.31390431e-01, 2.28116637e-01,\n",
    "          7.73018465e-01, 2.04918413e+00, 2.53786884e+00],\n",
    "        [1.39898385e-01, 5.30801725e-02, 2.31390431e-01, 2.28116637e-01,\n",
    "          7.73018465e-01, 2.04918413e+00, 2.53786884e+00],\n",
    "        [8.83101622e-02, 7.33011906e-02, 2.31390431e-01, 1.14058318e-01,\n",
    "          7.73018465e-01, 2.04918413e+00, 2.53786884e+00],\n",
    "        [1.23201552e-01, 1.87044417e-01, 1.15695216e-01, 1.14058318e-01,\n",
    "          1.54603693e+00, 2.04918413e+00, 2.53786884e+00],\n",
    "        [1.23201552e-01, 1.87044417e-01, 1.15695216e-01, 1.14058318e-01,\n",
    "          1.54603693e+00, 2.04918413e+00, 2.53786884e+00],\n",
    "        [1.23201552e-01, 1.87044417e-01, 1.15695216e-01, 1.14058318e-01,\n",
    "          1.54603693e+00, 2.04918413e+00, 2.53786884e+00],\n",
    "        [1.33852023e-01, 2.03221232e-01, 1.15695216e-01, 1.36869982e-01,\n",
    "          1.54603693e+00, 2.04918413e+00, 2.53786884e+00],\n",
    "        [1.73402994e-01, 2.63277656e-01, 1.38834259e-01, 1.36869982e-01,\n",
    "          1.85524432e+00, 2.04918413e+00, 2.53786884e+00],\n",
    "        [1.73402994e-01, 2.63277656e-01, 1.38834259e-01, 1.36869982e-01,\n",
    "          1.85524432e+00, 2.04918413e+00, 2.53786884e+00],\n",
    "        [1.73402994e-01, 2.63277656e-01, 1.38834259e-01, 1.36869982e-01,\n",
    "          1.85524432e+00, 2.04918413e+00, 2.53786884e+00],\n",
    "        [1.20084070e-01, 3.79750720e-01, 1.38834259e-01, 6.84349910e-02,\n",
    "          1.85524432e+00, 2.04918413e+00, 2.53786884e+00],\n",
    "        [1.63384894e-01, 9.92447569e-01, 6.94171294e-02, 6.84349910e-02,\n",
    "          3.71048863e+00, 2.04918413e+00, 2.53786884e+00],\n",
    "        [1.63384894e-01, 9.92447569e-01, 6.94171294e-02, 6.84349910e-02,\n",
    "          3.71048863e+00, 2.04918413e+00, 2.53786884e+00],\n",
    "        [1.63384894e-01, 9.92447569e-01, 6.94171294e-02, 6.84349910e-02,\n",
    "          3.71048863e+00, 2.04918413e+00, 2.53786884e+00],\n",
    "        [2.08083593e-01, 1.26421805e+00, 6.94171294e-02, 1.14058318e-01,\n",
    "          3.71048863e+00, 7.37706287e-01, 0.00000000e+00],\n",
    "        [1.42006291e-01, 8.62763439e-01, 1.15695216e-01, 4.56233273e-01,\n",
    "          1.03069129e+00, 8.19673652e-02, 0.00000000e+00],\n",
    "        [8.87539318e-02, 5.39648421e-01, 4.62780863e-01, 7.12864490e-02,\n",
    "          4.12276514e+00, 8.19673652e-02, 0.00000000e+00],\n",
    "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
    "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
    "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
    "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
    "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
    "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
    "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
    "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
    "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
    "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
    "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
    "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])\n",
    "    nn_array_test = nn_array_test.reshape((1, *nn_array_test.shape))\n",
    "    nn_array_test = tf.convert_to_tensor(nn_array_test, dtype=tf.float32)\n",
    "\n",
    "    hw_array_test = np.array([1.023785822261557565e-01,-4.262310244296395600e-01,2.295995016604397698e-01,-4.441886177106757483e-01,-8.459185226109141587e-01,-2.938802963497538223e-01,-3.464242712811745339e-01,4.572050514380619490e-01,-6.563799113750447001e-01,3.803529224492657179e-01,1.081335456679819673e+00,-2.117873165907936950e-01])\n",
    "    hw_array_test = hw_array_test.reshape((1, *hw_array_test.shape))\n",
    "    hw_array_test = tf.convert_to_tensor(hw_array_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('has': conda)",
   "language": "python",
   "name": "python361064bithascondabd8f1537e5d34ba799ef15b8707e6526"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}