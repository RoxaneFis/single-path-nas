{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import glob, os\n",
    "from numpy import savetxt, loadtxt, asarray\n",
    "\n",
    "\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nets = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/DataForHASpredictor2/all_nets.json'\n",
    "more_nets = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/DataForHASpredictor2'\n",
    "\n",
    "# parsed_nondups_val1 = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_val1_fix.txt'\n",
    "# parsed_nondups_train1 = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_train1_fix.txt'\n",
    "\n",
    "# parsed_nondups_val1_csv = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_val1.csv'\n",
    "# parsed_nondups_train1_csv = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_train1.csv'\n",
    "\n",
    "# parsed_nondups_val2 = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_val2.txt'\n",
    "# parsed_nondups_train2 = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_train2.txt'\n",
    "\n",
    "\n",
    "#ALL\n",
    "parsed_nondups_val_csv = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/DataForHASpredictor2/new_parsed_val.csv'\n",
    "parsed_nondups_train_csv = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/DataForHASpredictor2/new_parsed_train.csv'\n",
    "\n",
    "# parsed_nondups_val_csv = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_val_2.csv'\n",
    "# parsed_nondups_train_csv = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_train_2.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "UsageError: Line magic function `%pycache` not found.\n"
    }
   ],
   "source": [
    "%pycache\n",
    "number = 2\n",
    "\n",
    "with open(parsed_nondups_val2, 'r') as in_file:\n",
    "    stripped = (line.strip() for line in in_file)\n",
    "    lines = (line.split(\",\") for line in stripped if line)\n",
    "    with open(f'parsed_nondups_val{number}.csv', 'w') as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        writer.writerows(lines)\n",
    "\n",
    "with open(parsed_nondups_train2, 'r') as in_file:\n",
    "    stripped = (line.strip() for line in in_file)\n",
    "    lines = (line.split(\",\") for line in stripped if line)\n",
    "    with open(f'parsed_nondups_train{number}.csv', 'w') as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        writer.writerows(lines)\n",
    "\n",
    "# train_hw = pd.read_csv(parsed_nondups_train1_csv)\n",
    "# val_hw = pd.read_csv(parsed_nondups_val1_csv)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "train_00001600-00001649.txt\ntrain_00001850-00001899.txt\ntrain_00002000-00002049.txt\ntrain_00002300-00002349.txt\ntrain_00002200-00002249.txt\ntrain_00001950-00001999.txt\ntrain_00002100-00002149.txt\ntrain_00001700-00001749.txt\ntrain_00001750-00001799.txt\ntrain_00002250-00002299.txt\ntrain_00002150-00002199.txt\ntrain_00001900-00001949.txt\ntrain_00002050-00002099.txt\ntrain_00001800-00001849.txt\ntrain_00002350-00002399.txt\ntrain_00001650-00001699.txt\n"
    }
   ],
   "source": [
    "#%pycache\n",
    "os.chdir(more_nets)\n",
    "add_train = glob.glob(\"train*.txt\")\n",
    "add_val =  glob.glob(\"val*.txt\")\n",
    "\n",
    "with open(f'new_parsed_train.csv', 'w') as out_file:\n",
    "    c=0\n",
    "    writer = csv.writer(out_file)\n",
    "    for train in add_train:\n",
    "        print(train)\n",
    "        with open(more_nets +'/'+ train, 'r') as in_file:\n",
    "            # for line in in_file:\n",
    "            #     print(line[0])\n",
    "            stripped = (line.strip() for line in in_file)\n",
    "            #print(list(stripped))\n",
    "            #print(\"-----------\")\n",
    "            lines = (line.split(\",\") for line in stripped if line)\n",
    "            #print(list(lines))\n",
    "           # print(\"---------\")\n",
    "            # if list(lines)[0]=='C':\n",
    "            #     print(list(lines))\n",
    "           # writer = csv.writer(out_file)\n",
    "            writer.writerows(lines)\n",
    "\n",
    "\n",
    "with open(f'new_parsed_val.csv', 'w') as out_file:\n",
    "    c=0\n",
    "    for val in add_val:\n",
    "        with open(more_nets +'/'+ val, 'r') as in_file:\n",
    "            stripped = (line.strip() for line in in_file  )\n",
    "            lines = (line.split(\",\") for line in stripped if line)\n",
    "            writer = csv.writer(out_file)\n",
    "            writer.writerows(lines)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hw = pd.read_csv(parsed_nondups_train_csv)\n",
    "val_hw = pd.read_csv(parsed_nondups_val_csv)\n",
    "\n",
    "\n",
    "train_hw = train_hw[train_hw.C != 'C']\n",
    "val_hw = val_hw[val_hw.C != 'C']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "              C          B      name                   G  \\\n2531   748323.0  2679043.0  00001619   8141295.936344964   \n2532  6129302.0  7236639.0  00001619  1698060.5572549982   \n2533  6015364.0  7236639.0  00001619  1757963.4398911092   \n\n                          J mac_num max_filter_size mac_array_num  \\\n2531  9.865678969799997e-05    65.0          4098.0           7.0   \n2532  8.896639770600013e-05    28.0           512.0           2.0   \n2533  8.506332450000004e-05    41.0           512.0           2.0   \n\n             total_power   bw_power          core_power data_bits sram_size  \n2531  14.662443587919999  10.716172  3.9462715879199988    2048.0  379904.0  \n2532   32.50521190824001  28.946556  3.5586559082400053     128.0   80000.0  \n2533  32.349088980000005  28.946556  3.4025329800000015     128.0   80000.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>C</th>\n      <th>B</th>\n      <th>name</th>\n      <th>G</th>\n      <th>J</th>\n      <th>mac_num</th>\n      <th>max_filter_size</th>\n      <th>mac_array_num</th>\n      <th>total_power</th>\n      <th>bw_power</th>\n      <th>core_power</th>\n      <th>data_bits</th>\n      <th>sram_size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2531</th>\n      <td>748323.0</td>\n      <td>2679043.0</td>\n      <td>00001619</td>\n      <td>8141295.936344964</td>\n      <td>9.865678969799997e-05</td>\n      <td>65.0</td>\n      <td>4098.0</td>\n      <td>7.0</td>\n      <td>14.662443587919999</td>\n      <td>10.716172</td>\n      <td>3.9462715879199988</td>\n      <td>2048.0</td>\n      <td>379904.0</td>\n    </tr>\n    <tr>\n      <th>2532</th>\n      <td>6129302.0</td>\n      <td>7236639.0</td>\n      <td>00001619</td>\n      <td>1698060.5572549982</td>\n      <td>8.896639770600013e-05</td>\n      <td>28.0</td>\n      <td>512.0</td>\n      <td>2.0</td>\n      <td>32.50521190824001</td>\n      <td>28.946556</td>\n      <td>3.5586559082400053</td>\n      <td>128.0</td>\n      <td>80000.0</td>\n    </tr>\n    <tr>\n      <th>2533</th>\n      <td>6015364.0</td>\n      <td>7236639.0</td>\n      <td>00001619</td>\n      <td>1757963.4398911092</td>\n      <td>8.506332450000004e-05</td>\n      <td>41.0</td>\n      <td>512.0</td>\n      <td>2.0</td>\n      <td>32.349088980000005</td>\n      <td>28.946556</td>\n      <td>3.4025329800000015</td>\n      <td>128.0</td>\n      <td>80000.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "train_hw[2531:2534]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter 70% size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "UsageError: Line magic function `%pycache` not found.\n"
    }
   ],
   "source": [
    "%pycache\n",
    "val_hw[\"total_power\"]=pd.to_numeric(val_hw[\"total_power\"], errors='coerce')\n",
    "train_hw[\"total_power\"]=pd.to_numeric(train_hw[\"total_power\"], errors='coerce')\n",
    "\n",
    "\n",
    "train_hw = train_hw[(train_hw.total_power) < 200]\n",
    "val_hw = val_hw[(val_hw.total_power) < 200 ]\n",
    "\n",
    "\n",
    "train_hw.to_csv( \"parsed_nondups_train_lower_power.csv\", index=False, encoding='utf-8-sig')\n",
    "val_hw.to_csv( \"parsed_nondups_val_lower_power.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks Dictionnary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open(all_nets, 'r') as f:\n",
    "    nets_dict = json.load(f)\n",
    "\n",
    "\n",
    "os.chdir(more_nets)\n",
    "all_filenames = glob.glob(\"*.json\")\n",
    "for file in all_filenames:\n",
    "    with open(more_nets +'/'+ file, 'r') as f:\n",
    "        file_dict = json.load(f)\n",
    "        nets_dict.update(file_dict)\n",
    "len(nets_dict.keys())\n",
    "\n",
    "def number_zeros(k):\n",
    "    nb = len(k)\n",
    "    return \"0\"*(8-nb)\n",
    "\n",
    "\n",
    "def f(mydict):\n",
    "    return dict((number_zeros(k)+k,f(v) if hasattr(v,'keys') else v) for k,v in mydict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nets_dict = f(nets_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max block size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_blocks = 0\n",
    "for k,nn in nets_dict.items():\n",
    "    if len(nn)>max_blocks:\n",
    "        max_blocks=len(nn)\n",
    "\n",
    "max_blocks = max_blocks +1 # add fc layer at the end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "37"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "max_blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General information \n",
    "\n",
    "nets_dict_keys :0000 to 00531 (532)\n",
    "\n",
    "Train : 453 different NN\n",
    "\n",
    "Val : 50 different NN\n",
    "\n",
    "\n",
    "# Size dataset\n",
    "\n",
    "#### Train 1: 137,090\n",
    "#### Val 1: 13,804\n",
    "#### Train 2: 14,532\n",
    "#### Val 2: 2,882"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_NN_name(x):\n",
    "    x=int(x)\n",
    "    x=str(x)\n",
    "    while len(str(x))<8 :\n",
    "        x = '0'+str(x)\n",
    "    return x\n",
    "\n",
    "train_hw['name']=train_hw['name'].apply(lambda x : convert_NN_name(x))\n",
    "val_hw['name']=val_hw['name'].apply(lambda x : convert_NN_name(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            C          B      name                   G  \\\n0  11944703.0  3771067.0  00001642   1658074.656352509   \n1   8433638.0  4002079.0  00001642  1570522.2101876577   \n2  10753855.0  4002079.0  00001642  1411966.0827421746   \n3   1110008.0  3708652.0  00001642  10185009.221130842   \n4  11869528.0  4002079.0  00001642  1374615.4980233472   \n\n                        J mac_num max_filter_size mac_array_num  \\\n0  0.00016476742908900027    20.0           512.0           2.0   \n1  0.00015681514086299977    21.0           512.0           3.0   \n2  0.00014640667743900034    30.0           512.0           2.0   \n3  0.00010648946978700016   189.0          1536.0          14.0   \n4  0.00017413813578299998    20.0          1024.0           2.0   \n\n          total_power   bw_power          core_power data_bits sram_size  \n0   21.67496516356001  15.084268  6.5906971635600105     128.0   80000.0  \n1   22.28092163451999  16.008316   6.272605634519991     128.0   60000.0  \n2  21.864583097560015  16.008316   5.856267097560014     128.0   60000.0  \n3  19.094186791480006  14.834608   4.259578791480006     512.0   99968.0  \n4      22.97384143132  16.008316   6.965525431319999     128.0   60000.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>C</th>\n      <th>B</th>\n      <th>name</th>\n      <th>G</th>\n      <th>J</th>\n      <th>mac_num</th>\n      <th>max_filter_size</th>\n      <th>mac_array_num</th>\n      <th>total_power</th>\n      <th>bw_power</th>\n      <th>core_power</th>\n      <th>data_bits</th>\n      <th>sram_size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11944703.0</td>\n      <td>3771067.0</td>\n      <td>00001642</td>\n      <td>1658074.656352509</td>\n      <td>0.00016476742908900027</td>\n      <td>20.0</td>\n      <td>512.0</td>\n      <td>2.0</td>\n      <td>21.67496516356001</td>\n      <td>15.084268</td>\n      <td>6.5906971635600105</td>\n      <td>128.0</td>\n      <td>80000.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8433638.0</td>\n      <td>4002079.0</td>\n      <td>00001642</td>\n      <td>1570522.2101876577</td>\n      <td>0.00015681514086299977</td>\n      <td>21.0</td>\n      <td>512.0</td>\n      <td>3.0</td>\n      <td>22.28092163451999</td>\n      <td>16.008316</td>\n      <td>6.272605634519991</td>\n      <td>128.0</td>\n      <td>60000.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10753855.0</td>\n      <td>4002079.0</td>\n      <td>00001642</td>\n      <td>1411966.0827421746</td>\n      <td>0.00014640667743900034</td>\n      <td>30.0</td>\n      <td>512.0</td>\n      <td>2.0</td>\n      <td>21.864583097560015</td>\n      <td>16.008316</td>\n      <td>5.856267097560014</td>\n      <td>128.0</td>\n      <td>60000.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1110008.0</td>\n      <td>3708652.0</td>\n      <td>00001642</td>\n      <td>10185009.221130842</td>\n      <td>0.00010648946978700016</td>\n      <td>189.0</td>\n      <td>1536.0</td>\n      <td>14.0</td>\n      <td>19.094186791480006</td>\n      <td>14.834608</td>\n      <td>4.259578791480006</td>\n      <td>512.0</td>\n      <td>99968.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11869528.0</td>\n      <td>4002079.0</td>\n      <td>00001642</td>\n      <td>1374615.4980233472</td>\n      <td>0.00017413813578299998</td>\n      <td>20.0</td>\n      <td>1024.0</td>\n      <td>2.0</td>\n      <td>22.97384143132</td>\n      <td>16.008316</td>\n      <td>6.965525431319999</td>\n      <td>128.0</td>\n      <td>60000.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "train_hw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                C           B      name                   G  \\\n35423  51108099.0  39678749.0  00001695  2166257.3203038117   \n\n                          J mac_num max_filter_size mac_array_num  \\\n35423  0.002254929273794983    57.0          1536.0           2.0   \n\n              total_power    bw_power         core_power data_bits sram_size  \n35423  248.91216695179932  158.714996  90.19717095179931     512.0   99968.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>C</th>\n      <th>B</th>\n      <th>name</th>\n      <th>G</th>\n      <th>J</th>\n      <th>mac_num</th>\n      <th>max_filter_size</th>\n      <th>mac_array_num</th>\n      <th>total_power</th>\n      <th>bw_power</th>\n      <th>core_power</th>\n      <th>data_bits</th>\n      <th>sram_size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>35423</th>\n      <td>51108099.0</td>\n      <td>39678749.0</td>\n      <td>00001695</td>\n      <td>2166257.3203038117</td>\n      <td>0.002254929273794983</td>\n      <td>57.0</td>\n      <td>1536.0</td>\n      <td>2.0</td>\n      <td>248.91216695179932</td>\n      <td>158.714996</td>\n      <td>90.19717095179931</td>\n      <td>512.0</td>\n      <td>99968.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "train_hw[-2:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add neural network to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hw[\"NN\"]=train_hw['name'].map(nets_dict)\n",
    "val_hw[\"NN\"]=val_hw['name'].map(nets_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            C          B      name                   G  \\\n0  11944703.0  3771067.0  00001642   1658074.656352509   \n1   8433638.0  4002079.0  00001642  1570522.2101876577   \n2  10753855.0  4002079.0  00001642  1411966.0827421746   \n3   1110008.0  3708652.0  00001642  10185009.221130842   \n4  11869528.0  4002079.0  00001642  1374615.4980233472   \n\n                        J mac_num max_filter_size mac_array_num  \\\n0  0.00016476742908900027    20.0           512.0           2.0   \n1  0.00015681514086299977    21.0           512.0           3.0   \n2  0.00014640667743900034    30.0           512.0           2.0   \n3  0.00010648946978700016   189.0          1536.0          14.0   \n4  0.00017413813578299998    20.0          1024.0           2.0   \n\n          total_power   bw_power          core_power data_bits sram_size  \\\n0   21.67496516356001  15.084268  6.5906971635600105     128.0   80000.0   \n1   22.28092163451999  16.008316   6.272605634519991     128.0   60000.0   \n2  21.864583097560015  16.008316   5.856267097560014     128.0   60000.0   \n3  19.094186791480006  14.834608   4.259578791480006     512.0   99968.0   \n4      22.97384143132  16.008316   6.965525431319999     128.0   60000.0   \n\n                                                  NN  \n0  [[1, 31, 2, 3, 0, conv], [1, 31, 1, 3, 0, dw],...  \n1  [[1, 31, 2, 3, 0, conv], [1, 31, 1, 3, 0, dw],...  \n2  [[1, 31, 2, 3, 0, conv], [1, 31, 1, 3, 0, dw],...  \n3  [[1, 31, 2, 3, 0, conv], [1, 31, 1, 3, 0, dw],...  \n4  [[1, 31, 2, 3, 0, conv], [1, 31, 1, 3, 0, dw],...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>C</th>\n      <th>B</th>\n      <th>name</th>\n      <th>G</th>\n      <th>J</th>\n      <th>mac_num</th>\n      <th>max_filter_size</th>\n      <th>mac_array_num</th>\n      <th>total_power</th>\n      <th>bw_power</th>\n      <th>core_power</th>\n      <th>data_bits</th>\n      <th>sram_size</th>\n      <th>NN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11944703.0</td>\n      <td>3771067.0</td>\n      <td>00001642</td>\n      <td>1658074.656352509</td>\n      <td>0.00016476742908900027</td>\n      <td>20.0</td>\n      <td>512.0</td>\n      <td>2.0</td>\n      <td>21.67496516356001</td>\n      <td>15.084268</td>\n      <td>6.5906971635600105</td>\n      <td>128.0</td>\n      <td>80000.0</td>\n      <td>[[1, 31, 2, 3, 0, conv], [1, 31, 1, 3, 0, dw],...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8433638.0</td>\n      <td>4002079.0</td>\n      <td>00001642</td>\n      <td>1570522.2101876577</td>\n      <td>0.00015681514086299977</td>\n      <td>21.0</td>\n      <td>512.0</td>\n      <td>3.0</td>\n      <td>22.28092163451999</td>\n      <td>16.008316</td>\n      <td>6.272605634519991</td>\n      <td>128.0</td>\n      <td>60000.0</td>\n      <td>[[1, 31, 2, 3, 0, conv], [1, 31, 1, 3, 0, dw],...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10753855.0</td>\n      <td>4002079.0</td>\n      <td>00001642</td>\n      <td>1411966.0827421746</td>\n      <td>0.00014640667743900034</td>\n      <td>30.0</td>\n      <td>512.0</td>\n      <td>2.0</td>\n      <td>21.864583097560015</td>\n      <td>16.008316</td>\n      <td>5.856267097560014</td>\n      <td>128.0</td>\n      <td>60000.0</td>\n      <td>[[1, 31, 2, 3, 0, conv], [1, 31, 1, 3, 0, dw],...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1110008.0</td>\n      <td>3708652.0</td>\n      <td>00001642</td>\n      <td>10185009.221130842</td>\n      <td>0.00010648946978700016</td>\n      <td>189.0</td>\n      <td>1536.0</td>\n      <td>14.0</td>\n      <td>19.094186791480006</td>\n      <td>14.834608</td>\n      <td>4.259578791480006</td>\n      <td>512.0</td>\n      <td>99968.0</td>\n      <td>[[1, 31, 2, 3, 0, conv], [1, 31, 1, 3, 0, dw],...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11869528.0</td>\n      <td>4002079.0</td>\n      <td>00001642</td>\n      <td>1374615.4980233472</td>\n      <td>0.00017413813578299998</td>\n      <td>20.0</td>\n      <td>1024.0</td>\n      <td>2.0</td>\n      <td>22.97384143132</td>\n      <td>16.008316</td>\n      <td>6.965525431319999</td>\n      <td>128.0</td>\n      <td>60000.0</td>\n      <td>[[1, 31, 2, 3, 0, conv], [1, 31, 1, 3, 0, dw],...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "train_hw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treat NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME DIDNT COUNT ACTIVATION\n",
    "\n",
    "def conv_flops(hout,cin,cout,k,tensor_in,skip=0):\n",
    "    flops = 2*k*k*cin*hout*hout*cout\n",
    "    if skip ==1:\n",
    "        flops += tensor_in\n",
    "    return flops\n",
    "\n",
    "def dw_flops(hout,c,k,tensor_in,skip=0, mult=1):\n",
    "    flops = 2*k*k*c*hout*hout\n",
    "    if skip == 1:\n",
    "        flops +=tensor_in\n",
    "    return flops\n",
    "\n",
    "def fcc_flops(i, j):\n",
    "    return (2*i-1)*j\n",
    "\n",
    "def calculate_flop(convtype,hin,hout,cin,cout,k,exp,tensor_in, skip=0, mult=1,skip_op=False):\n",
    "    if skip_op==True:\n",
    "        return 0\n",
    "    else:\n",
    "        if convtype=='conv':\n",
    "            return conv_flops(hout,cin,cout,k, tensor_in, skip)\n",
    "        elif convtype=='dw':\n",
    "            return dw_flops(hout,cin,k,tensor_in,skip)\n",
    "        elif convtype=='inv':\n",
    "            hout_pointwise = hin\n",
    "            return conv_flops(hout=hout_pointwise, cin=cin,cout=cin*exp,k=1, tensor_in=tensor_in, skip=skip) + \\\n",
    "        dw_flops(hout=hout,c=cin*exp,k=k,tensor_in=0,skip=0) + \\\n",
    "        conv_flops(hout=hout,cin=cin*exp,cout=cout,k=1, tensor_in=0, skip=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Calculate weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_weights(cin,cout,k):\n",
    "    return (k*k*cin+1)*cout\n",
    "\n",
    "def dw_weights(cin,k,mult=1):\n",
    "    #dw = equi cin=1 and multiply by cout\n",
    "    #return conv_flops(hout,1,cin,k)*mult\n",
    "    return (k*k+1)*cin\n",
    "\n",
    "def fcc_weight(i, j):\n",
    "    return\n",
    "    #return (2*i-1)*j\n",
    "\n",
    "def calculate_weights(convtype,cin,cout,k,exp,mult=1):\n",
    "    if convtype=='conv':\n",
    "        return conv_weights(cin,cout,k)\n",
    "    elif convtype=='dw':\n",
    "        return dw_weights(cin,k)\n",
    "    elif convtype=='inv':\n",
    "        return conv_weights(cin, cin*exp, 1)+ dw_weights(cin*exp,k,mult) + conv_weights(cin*exp,cout,1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distinguish columns between convtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def distinct_contypes(NN_frame, columns_names, conv_types):\n",
    "    columns_names_augmented = [ f'{name}_{conv_type}' for conv_type in conv_types for name in columns_names]\n",
    "    NN_frame_processed= pd.DataFrame(None, index=np.arange(len(NN)+1), columns=columns_names_augmented)\n",
    "\n",
    "    ### Len(NN)+1  beceause +1 FC layer at the end\n",
    "    for conv_type in conv_types:\n",
    "        columns_conv_type = [f'{columns_name}_{conv_type}' for columns_name in columns_names]\n",
    "        NN_frame_processed[columns_conv_type] = NN_frame.loc[NN_frame['convtype']==conv_type, columns_names]\n",
    "    return NN_frame_processed.fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treat the neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nb_classes= 1000\n",
    "separate_types = False\n",
    "\n",
    "# def no_relu(NN_frame):  \n",
    "#     NN_frame['convtype']= NN_frame['convtype'].apply(lambda x : 'conv' if x=='conv_norelu' else x)\n",
    "\n",
    "def treat_NN(NN_frame, values_to_keep, separate_types):\n",
    "    fc_block = {'exp':1, 'c_out':1000, 's':1, 'k':1, 'skip':0,'convtype':'conv'}\n",
    "    NN_frame=NN_frame.append(fc_block, ignore_index=True)\n",
    "    import pdb\n",
    "   # pdb.set_trace()\n",
    "\n",
    "    #no_relu\n",
    "    NN_frame['convtype']= NN_frame['convtype'].apply(lambda x : 'conv' if x=='conv_norelu' else x)\n",
    "\n",
    "    NN_frame['c_in'] = np.roll(NN_frame['c_out'], 1)\n",
    "    NN_frame['c_in'][0]=3 # RGB channels\n",
    "\n",
    "    NN_frame['k2']=NN_frame['k'].apply(lambda x : x*x)\n",
    "    NN_frame['hidden_dim']=NN_frame['exp']*NN_frame['c_in']\n",
    "\n",
    "    NN_frame['h_in'] = np.nan\n",
    "    NN_frame['h_in'][0]=224 # Size imagenet - hardcoded\n",
    "    for i in range(1, len(NN_frame)):\n",
    "        if NN_frame.loc[i-1, 's']==1:\n",
    "            NN_frame.loc[i, 'h_in']=NN_frame.loc[i-1, 'h_in']\n",
    "        elif NN_frame.loc[i-1, 's']==2:\n",
    "            NN_frame.loc[i, 'h_in']=NN_frame.loc[i-1, 'h_in']/2\n",
    "        else : \n",
    "            raise NameError('Dont know the paddind')\n",
    "\n",
    "\n",
    "    NN_frame['h_out'] = np.roll(NN_frame['h_in'], -1)\n",
    "    NN_frame['h_out'][NN_frame.last_valid_index()]=NN_frame['h_in'][NN_frame.last_valid_index()]/NN_frame.loc[NN_frame.last_valid_index(), 's']\n",
    "\n",
    "    NN_frame['tensor_in']=NN_frame['c_in']*NN_frame['h_in']*NN_frame['h_in']\n",
    "    NN_frame['tensor_out']=NN_frame['c_out']*NN_frame['h_out']*NN_frame['h_out']\n",
    "\n",
    "    NN_frame['weights']=NN_frame.apply(lambda x : calculate_weights(x.convtype,x.c_in,x.c_out,x.k,x.exp), axis=1)\n",
    "    NN_frame['FLOPS']= NN_frame.apply(lambda x : calculate_flop(x.convtype,x.h_in,x.h_out,x.c_in,x.c_out,x.k,x.exp, x.tensor_in,x.skip), axis=1)\n",
    "    #return  NN_frame\n",
    "    if separate_types:\n",
    "        NN_frame=NN_frame.loc[:, values_to_keep + ['convtype']]\n",
    "        NN_frame =distinct_contypes(NN_frame, values_to_keep, conv_types)\n",
    "        #values_to_keep = [f'{value}_{type}' for type in conv_types for value in values_to_keep]\n",
    "    else:\n",
    "        NN_frame =NN_frame.loc[:, values_to_keep]\n",
    "    return  NN_frame\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example NN_treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          FLOPS  weights  tensor_in  tensor_out  hidden_dim  k2  skip\n0    23708160.0      980   150528.0    439040.0           3   9     0\n1     7902720.0      350   439040.0    439040.0          35   9     0\n2    29854720.0     1224   439040.0    426496.0          35   1     0\n3   181260800.0    11909   426496.0     28224.0         170  25     0\n4     7620480.0     1314    28224.0     28224.0          45   9     0\n5     3951360.0     1406    28224.0      8624.0          45   9     0\n6     2673440.0     1826     8624.0      8624.0          55   9     0\n7     2121504.0     3379     8624.0      2548.0          66  25     0\n8     2293200.0     6019     2548.0      2548.0          78  49     0\n9     2293200.0     6019     2548.0      2548.0          78  49     0\n10    1070160.0     2899     2548.0      2548.0          78   9     0\n11     347802.0     2136     2548.0      1470.0          39   9     0\n12     610050.0     6420     1470.0      1470.0          90   9     1\n13     599760.0     6329     1470.0      1421.0          90   9     0\n14    3066518.0    32370     1421.0     52871.0          29   1     0\n15  105742000.0  1080000    52871.0     49000.0        1079   1     0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FLOPS</th>\n      <th>weights</th>\n      <th>tensor_in</th>\n      <th>tensor_out</th>\n      <th>hidden_dim</th>\n      <th>k2</th>\n      <th>skip</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>23708160.0</td>\n      <td>980</td>\n      <td>150528.0</td>\n      <td>439040.0</td>\n      <td>3</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7902720.0</td>\n      <td>350</td>\n      <td>439040.0</td>\n      <td>439040.0</td>\n      <td>35</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>29854720.0</td>\n      <td>1224</td>\n      <td>439040.0</td>\n      <td>426496.0</td>\n      <td>35</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>181260800.0</td>\n      <td>11909</td>\n      <td>426496.0</td>\n      <td>28224.0</td>\n      <td>170</td>\n      <td>25</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7620480.0</td>\n      <td>1314</td>\n      <td>28224.0</td>\n      <td>28224.0</td>\n      <td>45</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3951360.0</td>\n      <td>1406</td>\n      <td>28224.0</td>\n      <td>8624.0</td>\n      <td>45</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2673440.0</td>\n      <td>1826</td>\n      <td>8624.0</td>\n      <td>8624.0</td>\n      <td>55</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2121504.0</td>\n      <td>3379</td>\n      <td>8624.0</td>\n      <td>2548.0</td>\n      <td>66</td>\n      <td>25</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2293200.0</td>\n      <td>6019</td>\n      <td>2548.0</td>\n      <td>2548.0</td>\n      <td>78</td>\n      <td>49</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2293200.0</td>\n      <td>6019</td>\n      <td>2548.0</td>\n      <td>2548.0</td>\n      <td>78</td>\n      <td>49</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1070160.0</td>\n      <td>2899</td>\n      <td>2548.0</td>\n      <td>2548.0</td>\n      <td>78</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>347802.0</td>\n      <td>2136</td>\n      <td>2548.0</td>\n      <td>1470.0</td>\n      <td>39</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>610050.0</td>\n      <td>6420</td>\n      <td>1470.0</td>\n      <td>1470.0</td>\n      <td>90</td>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>599760.0</td>\n      <td>6329</td>\n      <td>1470.0</td>\n      <td>1421.0</td>\n      <td>90</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>3066518.0</td>\n      <td>32370</td>\n      <td>1421.0</td>\n      <td>52871.0</td>\n      <td>29</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>105742000.0</td>\n      <td>1080000</td>\n      <td>52871.0</td>\n      <td>49000.0</td>\n      <td>1079</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "conv_types = ['conv', 'dw', 'inv']\n",
    "columns_names = ['exp','c_out','s','k','skip']\n",
    "values_to_keep = ['FLOPS','weights','tensor_in','tensor_out','hidden_dim','k2', 'skip']\n",
    "#values_to_keep_plus_type = ['FLOPS','weights','tensor_in','tensor_out','hidden_dim','k2', 'skip', 'convtype']\n",
    "\n",
    "\n",
    "\n",
    "NN = nets_dict['00000001']\n",
    "NN_frame = pd.DataFrame(NN, columns = columns_names+ ['convtype',])\n",
    "\n",
    "#distinct =distinct_contypes(NN_frame, columns_names, conv_types)\n",
    "NN_00001 = treat_NN(NN_frame, values_to_keep, False)\n",
    "NN_00001\n",
    "#distinct.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify properperly calculate number of weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Initialize one NN : nets_dict[00001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\nModel: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 224, 224, 3)       0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 112, 112, 35)      980       \n_________________________________________________________________\ndepthwise_conv2d_1 (Depthwis (None, 112, 112, 35)      350       \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 112, 112, 34)      1224      \n_________________________________________________________________\nactivation_1 (Activation)    (None, 112, 112, 34)      0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 112, 112, 170)     5950      \n_________________________________________________________________\ndepthwise_conv2d_2 (Depthwis (None, 56, 56, 170)       4420      \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 56, 56, 9)         1539      \n_________________________________________________________________\nactivation_2 (Activation)    (None, 56, 56, 9)         0         \n_________________________________________________________________\nactivation_3 (Activation)    (None, 56, 56, 9)         0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 56, 56, 45)        450       \n_________________________________________________________________\ndepthwise_conv2d_3 (Depthwis (None, 56, 56, 45)        450       \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 56, 56, 9)         414       \n_________________________________________________________________\nactivation_4 (Activation)    (None, 56, 56, 9)         0         \n_________________________________________________________________\nactivation_5 (Activation)    (None, 56, 56, 9)         0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 56, 56, 45)        450       \n_________________________________________________________________\ndepthwise_conv2d_4 (Depthwis (None, 28, 28, 45)        450       \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 28, 28, 11)        506       \n_________________________________________________________________\nactivation_6 (Activation)    (None, 28, 28, 11)        0         \n_________________________________________________________________\nactivation_7 (Activation)    (None, 28, 28, 11)        0         \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 28, 28, 55)        660       \n_________________________________________________________________\ndepthwise_conv2d_5 (Depthwis (None, 28, 28, 55)        550       \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 28, 28, 11)        616       \n_________________________________________________________________\nactivation_8 (Activation)    (None, 28, 28, 11)        0         \n_________________________________________________________________\nactivation_9 (Activation)    (None, 28, 28, 11)        0         \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 28, 28, 66)        792       \n_________________________________________________________________\ndepthwise_conv2d_6 (Depthwis (None, 14, 14, 66)        1716      \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, 14, 14, 13)        871       \n_________________________________________________________________\nactivation_10 (Activation)   (None, 14, 14, 13)        0         \n_________________________________________________________________\nactivation_11 (Activation)   (None, 14, 14, 13)        0         \n_________________________________________________________________\nconv2d_13 (Conv2D)           (None, 14, 14, 78)        1092      \n_________________________________________________________________\ndepthwise_conv2d_7 (Depthwis (None, 14, 14, 78)        3900      \n_________________________________________________________________\nconv2d_14 (Conv2D)           (None, 14, 14, 13)        1027      \n_________________________________________________________________\nactivation_12 (Activation)   (None, 14, 14, 13)        0         \n_________________________________________________________________\nactivation_13 (Activation)   (None, 14, 14, 13)        0         \n_________________________________________________________________\nconv2d_15 (Conv2D)           (None, 14, 14, 78)        1092      \n_________________________________________________________________\ndepthwise_conv2d_8 (Depthwis (None, 14, 14, 78)        3900      \n_________________________________________________________________\nconv2d_16 (Conv2D)           (None, 14, 14, 13)        1027      \n_________________________________________________________________\nactivation_14 (Activation)   (None, 14, 14, 13)        0         \n_________________________________________________________________\nactivation_15 (Activation)   (None, 14, 14, 13)        0         \n_________________________________________________________________\nconv2d_17 (Conv2D)           (None, 14, 14, 78)        1092      \n_________________________________________________________________\ndepthwise_conv2d_9 (Depthwis (None, 14, 14, 78)        780       \n_________________________________________________________________\nconv2d_18 (Conv2D)           (None, 14, 14, 13)        1027      \n_________________________________________________________________\nactivation_16 (Activation)   (None, 14, 14, 13)        0         \n_________________________________________________________________\nactivation_17 (Activation)   (None, 14, 14, 13)        0         \n_________________________________________________________________\nconv2d_19 (Conv2D)           (None, 14, 14, 39)        546       \n_________________________________________________________________\ndepthwise_conv2d_10 (Depthwi (None, 7, 7, 39)          390       \n_________________________________________________________________\nconv2d_20 (Conv2D)           (None, 7, 7, 30)          1200      \n_________________________________________________________________\nactivation_18 (Activation)   (None, 7, 7, 30)          0         \n_________________________________________________________________\nactivation_19 (Activation)   (None, 7, 7, 30)          0         \n_________________________________________________________________\nconv2d_21 (Conv2D)           (None, 7, 7, 90)          2790      \n_________________________________________________________________\ndepthwise_conv2d_11 (Depthwi (None, 7, 7, 90)          900       \n_________________________________________________________________\nconv2d_22 (Conv2D)           (None, 7, 7, 30)          2730      \n_________________________________________________________________\nactivation_20 (Activation)   (None, 7, 7, 30)          0         \n_________________________________________________________________\nactivation_21 (Activation)   (None, 7, 7, 30)          0         \n_________________________________________________________________\nconv2d_23 (Conv2D)           (None, 7, 7, 90)          2790      \n_________________________________________________________________\ndepthwise_conv2d_12 (Depthwi (None, 7, 7, 90)          900       \n_________________________________________________________________\nconv2d_24 (Conv2D)           (None, 7, 7, 29)          2639      \n_________________________________________________________________\nactivation_22 (Activation)   (None, 7, 7, 29)          0         \n_________________________________________________________________\nconv2d_25 (Conv2D)           (None, 7, 7, 1079)        32370     \n_________________________________________________________________\nglobal_average_pooling2d_1 ( (None, 1079)              0         \n_________________________________________________________________\nreshape_1 (Reshape)          (None, 1, 1, 1079)        0         \n_________________________________________________________________\nDropout (Dropout)            (None, 1, 1, 1079)        0         \n_________________________________________________________________\nconv2d_26 (Conv2D)           (None, 1, 1, 1000)        1080000   \n_________________________________________________________________\nreshape_2 (Reshape)          (None, 1000)              0         \n=================================================================\nTotal params: 1,164,580\nTrainable params: 1,164,580\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dropout\n",
    "from keras.layers import Activation, BatchNormalization, Add, Reshape, DepthwiseConv2D\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from keras import backend as K\n",
    "def relu6(x):\n",
    "    return K.relu(x, max_value=6.0)\n",
    "\n",
    "def _conv_block(inputs, filters, kernel, strides):\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "    x = Conv2D(filters, kernel, padding='same', strides=strides)(inputs)\n",
    "    return x\n",
    "\n",
    "def _bottleneck(inputs, filters, kernel, t, alpha, s, r=False):\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "    tchannel = K.int_shape(inputs)[channel_axis] * t\n",
    "    cchannel = int(filters * alpha)\n",
    "    x = _conv_block(inputs, tchannel, (1, 1), (1, 1))\n",
    "    x = DepthwiseConv2D(kernel, strides=(s, s), depth_multiplier=1, padding='same')(x)\n",
    "    x = Conv2D(cchannel, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "    if r:\n",
    "        x = Add()([x, inputs])\n",
    "    return x\n",
    "\n",
    "def _inverted_residual_block(inputs, filters, kernel, t, alpha, strides, n):\n",
    "    x=Activation(relu6)(inputs)\n",
    "    x = _bottleneck(x, filters, kernel, t, alpha, strides)\n",
    "    for i in range(1, n):\n",
    "        x = _bottleneck(x, filters, kernel, t, alpha, 1, True)\n",
    "    x=Activation(relu6)(x)\n",
    "    return x\n",
    "\n",
    "def Net1(input_shape, k, alpha=1.0):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x= Conv2D(35, 3, padding='same', strides=(2,2))(inputs)\n",
    "    x = DepthwiseConv2D((3,3),  activation='relu', padding='same')(x)\n",
    "    x= Conv2D(34, 1, padding='same', strides=(1,1))(x)\n",
    "\n",
    "    x = _inverted_residual_block(x, 9, (5, 5), t=5, alpha=alpha, strides=2, n=1)\n",
    "    x = _inverted_residual_block(x, 9, (3, 3), t=5, alpha=alpha, strides=1, n=1)\n",
    "    x = _inverted_residual_block(x, 11, (3, 3), t=5, alpha=alpha, strides=2, n=1)\n",
    "    x = _inverted_residual_block(x, 11, (3, 3), t=5, alpha=alpha, strides=1, n=1)\n",
    "\n",
    "    x = _inverted_residual_block(x, 13, (5, 5), t=6, alpha=alpha, strides=2, n=1)\n",
    "    x = _inverted_residual_block(x, 13, (7, 7), t=6, alpha=alpha, strides=1, n=1)\n",
    "    x = _inverted_residual_block(x, 13, (7, 7), t=6, alpha=alpha, strides=1, n=1)\n",
    "    x = _inverted_residual_block(x, 13, (3, 3), t=6, alpha=alpha, strides=1, n=1)\n",
    "\n",
    "    x = _inverted_residual_block(x, 30, (3, 3), t=3, alpha=alpha, strides=2, n=1)\n",
    "    x = _inverted_residual_block(x, 30, (3, 3), t=3, alpha=alpha, strides=1, n=1)\n",
    "    x = _inverted_residual_block(x, 29, (3, 3), t=3, alpha=alpha, strides=1, n=1)\n",
    "    last_filters = 1079\n",
    "\n",
    "    x = _conv_block(x, last_filters, (1, 1), strides=(1, 1))\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    x = Reshape((1, 1, last_filters))(x)\n",
    "    x = Dropout(0.3, name='Dropout')(x)\n",
    "    #!!!!!!!!!\n",
    "    x = Conv2D(k, (1, 1), padding='same')(x)\n",
    "    #!!!!!!!!!\n",
    "    output = Reshape((k,))(x)\n",
    "    model = Model(inputs, output)\n",
    "    # plot_model(model, to_file='images/MobileNetv2.png', show_shapes=True)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model_1 = Net1((224, 224, 3), 1000, 1.0)\n",
    "    print(model_1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model total param = Total params: 1,164,580"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1164580"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "sum(NN_00001['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /Users/roxanefischer/miniconda3/envs/has/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nWARNING:tensorflow:From /Users/roxanefischer/miniconda3/envs/has/lib/python3.6/site-packages/tensorflow/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2321134"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    " \n",
    "##### FIXME!!!!!!!!!!!\n",
    "def get_flops():\n",
    "    session = tf.compat.v1.Session()\n",
    "    graph = tf.compat.v1.get_default_graph()\n",
    "\n",
    "    with graph.as_default():\n",
    "        with session.as_default():\n",
    "            model_2 = Net1((224, 224, 3), 1000, 1.0)\n",
    "            run_meta = tf.compat.v1.RunMetadata()\n",
    "            opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "            # Optional: save printed results to file\n",
    "            # flops_log_path = os.path.join(tempfile.gettempdir(), 'tf_flops_log.txt')\n",
    "            # opts['output'] = 'file:outfile={}'.format(flops_log_path)\n",
    "\n",
    "            # We use the Keras session graph in the call to the profiler.\n",
    "            flops = tf.compat.v1.profiler.profile(graph=graph,\n",
    "                                                  run_meta=run_meta, cmd='op', options=opts)\n",
    "\n",
    "            return flops.total_float_ops\n",
    "get_flops()\n",
    "\n",
    "#print(sum(NN_00001['FLOPS']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['exp', 'c_out', 's', 'k', 'skip']"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "columns_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['conv', 'dw', 'inv']"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "conv_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['FLOPS', 'weights', 'tensor_in', 'tensor_out', 'hidden_dim', 'k2', 'skip']"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "values_to_keep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the final representation of the NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          FLOPS  weights  tensor_in  tensor_out  hidden_dim  k2  skip\n0    23708160.0      980   150528.0    439040.0           3   9     0\n1     7902720.0      350   439040.0    439040.0          35   9     0\n2    29854720.0     1224   439040.0    426496.0          35   1     0\n3   181260800.0    11909   426496.0     28224.0         170  25     0\n4     7620480.0     1314    28224.0     28224.0          45   9     0\n5     3951360.0     1406    28224.0      8624.0          45   9     0\n6     2673440.0     1826     8624.0      8624.0          55   9     0\n7     2121504.0     3379     8624.0      2548.0          66  25     0\n8     2293200.0     6019     2548.0      2548.0          78  49     0\n9     2293200.0     6019     2548.0      2548.0          78  49     0\n10    1070160.0     2899     2548.0      2548.0          78   9     0\n11     347802.0     2136     2548.0      1470.0          39   9     0\n12     610050.0     6420     1470.0      1470.0          90   9     1\n13     599760.0     6329     1470.0      1421.0          90   9     0\n14    3066518.0    32370     1421.0     52871.0          29   1     0\n15  105742000.0  1080000    52871.0     49000.0        1079   1     0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FLOPS</th>\n      <th>weights</th>\n      <th>tensor_in</th>\n      <th>tensor_out</th>\n      <th>hidden_dim</th>\n      <th>k2</th>\n      <th>skip</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>23708160.0</td>\n      <td>980</td>\n      <td>150528.0</td>\n      <td>439040.0</td>\n      <td>3</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7902720.0</td>\n      <td>350</td>\n      <td>439040.0</td>\n      <td>439040.0</td>\n      <td>35</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>29854720.0</td>\n      <td>1224</td>\n      <td>439040.0</td>\n      <td>426496.0</td>\n      <td>35</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>181260800.0</td>\n      <td>11909</td>\n      <td>426496.0</td>\n      <td>28224.0</td>\n      <td>170</td>\n      <td>25</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7620480.0</td>\n      <td>1314</td>\n      <td>28224.0</td>\n      <td>28224.0</td>\n      <td>45</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3951360.0</td>\n      <td>1406</td>\n      <td>28224.0</td>\n      <td>8624.0</td>\n      <td>45</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2673440.0</td>\n      <td>1826</td>\n      <td>8624.0</td>\n      <td>8624.0</td>\n      <td>55</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2121504.0</td>\n      <td>3379</td>\n      <td>8624.0</td>\n      <td>2548.0</td>\n      <td>66</td>\n      <td>25</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2293200.0</td>\n      <td>6019</td>\n      <td>2548.0</td>\n      <td>2548.0</td>\n      <td>78</td>\n      <td>49</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2293200.0</td>\n      <td>6019</td>\n      <td>2548.0</td>\n      <td>2548.0</td>\n      <td>78</td>\n      <td>49</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1070160.0</td>\n      <td>2899</td>\n      <td>2548.0</td>\n      <td>2548.0</td>\n      <td>78</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>347802.0</td>\n      <td>2136</td>\n      <td>2548.0</td>\n      <td>1470.0</td>\n      <td>39</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>610050.0</td>\n      <td>6420</td>\n      <td>1470.0</td>\n      <td>1470.0</td>\n      <td>90</td>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>599760.0</td>\n      <td>6329</td>\n      <td>1470.0</td>\n      <td>1421.0</td>\n      <td>90</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>3066518.0</td>\n      <td>32370</td>\n      <td>1421.0</td>\n      <td>52871.0</td>\n      <td>29</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>105742000.0</td>\n      <td>1080000</td>\n      <td>52871.0</td>\n      <td>49000.0</td>\n      <td>1079</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "\n",
    "def no_relu(NN_frame):  \n",
    "    NN_frame['convtype']= NN_frame['convtype'].apply(lambda x : 'conv' if x=='conv_norelu' else x)\n",
    "\n",
    "\n",
    "def NN_to_dataframe(NN_list, columns_names, conv_types, values_to_keep,separate_types):\n",
    "    NN_frame = pd.DataFrame(NN_list, columns = columns_names+ ['convtype',])\n",
    "    no_relu(NN_frame)\n",
    "    return treat_NN(NN_frame, values_to_keep,separate_types)\n",
    "\n",
    "    #NN_distinct_contypes = distinct_contypes(NN_frame, columns_names, conv_types)\n",
    "    #return NN_frame\n",
    "    #return NN_distinct_contypes\n",
    "\n",
    "\n",
    "NN_df = NN_to_dataframe(NN, columns_names, conv_types,values_to_keep,separate_types)\n",
    "NN_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[[1, 35, 2, 3, 0, 'conv'],\n [1, 35, 1, 3, 0, 'dw'],\n [1, 34, 1, 1, 0, 'conv_norelu'],\n [5, 9, 2, 5, 0, 'inv'],\n [5, 9, 1, 3, 0, 'inv'],\n [5, 11, 2, 3, 0, 'inv'],\n [5, 11, 1, 3, 0, 'inv'],\n [6, 13, 2, 5, 0, 'inv'],\n [6, 13, 1, 7, 0, 'inv'],\n [6, 13, 1, 7, 0, 'inv'],\n [6, 13, 1, 3, 0, 'inv'],\n [3, 30, 2, 3, 0, 'inv'],\n [3, 30, 1, 3, 1, 'inv'],\n [3, 29, 1, 3, 0, 'inv'],\n [1, 1079, 1, 1, 0, 'conv']]"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add HW params to NN_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ['mac_num','mac_array_num','data_bits','sram_size','max_filter_size']\n",
    "\n",
    "def add_HW_param_column(df,mac_num, mac_array_num, data_bits, sram_size, max_filter_size):\n",
    "    df['mac_num']=mac_num\n",
    "    df['mac_array_num']=mac_array_num\n",
    "    df['total_macs']=  mac_num * mac_array_num\n",
    "    df['data_bits']=data_bits\n",
    "    df['sram_size']=sram_size\n",
    "    df['max_filter_size']=max_filter_size\n",
    "\n",
    "\n",
    "def add_HW_param_line(NN_frame, mac_num, mac_array_num, data_bits, sram_size, max_filter_size):\n",
    "    HW_param_line =pd.DataFrame([[mac_num]*(NN_frame.shape[1])], columns=NN_frame.columns)\n",
    "    HW_param_line = HW_param_line.append(pd.DataFrame([[mac_array_num]*(NN_frame.shape[1])], columns=NN_frame.columns))\n",
    "    HW_param_line = HW_param_line.append(pd.DataFrame([[mac_num*mac_array_num]*(NN_frame.shape[1])], columns=NN_frame.columns))\n",
    "    HW_param_line =HW_param_line.append(pd.DataFrame([[data_bits]*(NN_frame.shape[1])], columns=NN_frame.columns))\n",
    "    HW_param_line =HW_param_line.append(pd.DataFrame([[sram_size]*(NN_frame.shape[1])], columns=NN_frame.columns))\n",
    "    HW_param_line =HW_param_line.append(pd.DataFrame([[max_filter_size]*(NN_frame.shape[1])], columns=NN_frame.columns))\n",
    "    return HW_param_line.append(NN_frame)\n",
    "\n",
    "\n",
    "#not_used\n",
    "def extend_to_max_blocks(NN_frame, value):\n",
    "    for i in range (max_blocks-len(NN_frame)):\n",
    "        NN_frame=NN_frame.append(pd.DataFrame([[0]*(NN_frame.shape[1])], index=[i+len(NN_frame),] ,columns=NN_frame.columns))\n",
    "    return NN_frame\n",
    "\n",
    "#not_used\n",
    "def add_zero_blocks(arr):\n",
    "    zero_blocks = np.zeros(( max_blocks-arr.shape[0],arr.shape[1]))\n",
    "    return np.append(arr, zero_blocks, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "UsageError: Line magic function `%pycache` not found.\n"
    }
   ],
   "source": [
    "%pycache\n",
    "train_hw= train_hw[:3]\n",
    "val_hw = val_hw[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|| 35410/35410 [18:39<00:00, 31.62it/s]\n100%|| 35410/35410 [00:02<00:00, 14176.43it/s]\n100%|| 4451/4451 [02:21<00:00, 31.47it/s]\n100%|| 4451/4451 [00:00<00:00, 14492.38it/s]\n"
    }
   ],
   "source": [
    "#%pycache\n",
    "values_to_keep = ['FLOPS','weights','tensor_in','tensor_out','hidden_dim','k2', 'skip']\n",
    "separate_types = False\n",
    "# if separate_types:\n",
    "#     values_to_keep = [f'{value}_{type}' for type in conv_types for value in values_to_keep]\n",
    "\n",
    "name = 'from_1600'\n",
    "\n",
    "\n",
    "# Convert NN to dataframe with values of interest\n",
    "train_hw[\"NN_dataframe\"] = train_hw[\"NN\"].progress_apply(lambda x : NN_to_dataframe(x,columns_names, conv_types, values_to_keep,separate_types))\n",
    "#train_hw.progress_apply(lambda x : add_HW_param_column(x.NN_dataframe,x.mac_num,x.mac_array_num, x.data_bits, x.sram_size, x.max_filter_size), axis=1)\n",
    "train_hw['NN_dataframe']=train_hw['NN_dataframe'].progress_apply(lambda x : np.array(x))\n",
    "#complete to zero#complete to zero\n",
    "#train_hw['NN_dataframe']= train['NN_dataframe'].progress_apply(lambda x : add_zero_blocks(x))#complete to zero#complete to zero\n",
    "train_hw['NN_dataframe'].to_csv(f'train_{name}.csv')\n",
    "\n",
    "\n",
    "#####################################\n",
    "\n",
    "val_hw[\"NN_dataframe\"] = val_hw[\"NN\"].progress_apply(lambda x : NN_to_dataframe(x,columns_names, conv_types, values_to_keep,separate_types))\n",
    "#val_hw.progress_apply(lambda x : add_HW_param_column(x.NN_dataframe,x.mac_num,x.mac_array_num, x.data_bits, x.sram_size, x.max_filter_size), axis=1)\n",
    "val_hw['NN_dataframe']=val_hw['NN_dataframe'].progress_apply(lambda x : np.array(x))\n",
    "\n",
    "#complete to zero#complete to zero\n",
    "#val['NN_dataframe']= val['NN_dataframe'].progress_apply(lambda x : add_zero_blocks(x))#complete to zero#complete to zero\n",
    "val_hw.to_csv(f'val_{name}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   mac_num  mac_array_num  data_bits  sram_size  max_filter_size  \\\n0    118.0            2.0      256.0   179968.0           2048.0   \n1     87.0            2.0      512.0    99968.0           2048.0   \n2    124.0            2.0      512.0    99968.0           3072.0   \n\n              G           C           B         J   name   bw_power  \\\n0  3.636011e+06  18770712.0  19987780.0  0.000533  00000  79.951120   \n1  2.325259e+06  14362735.0  21849702.0  0.000570  00000  87.398808   \n2  2.533459e+06  12739050.0  21849702.0  0.000543  00000  87.398808   \n\n   core_power  total_power                                                 NN  \\\n0   21.330414   101.281534  [[1, 9, 2, 3, 0, conv], [1, 9, 1, 3, 0, dw], [...   \n1   22.816285   110.215093  [[1, 9, 2, 3, 0, conv], [1, 9, 1, 3, 0, dw], [...   \n2   21.716202   109.115010  [[1, 9, 2, 3, 0, conv], [1, 9, 1, 3, 0, dw], [...   \n\n                                        NN_dataframe  \n0  [[6096384.0, 252.0, 150528.0, 112896.0, 3.0, 9...  \n1  [[6096384.0, 252.0, 150528.0, 112896.0, 3.0, 9...  \n2  [[6096384.0, 252.0, 150528.0, 112896.0, 3.0, 9...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mac_num</th>\n      <th>mac_array_num</th>\n      <th>data_bits</th>\n      <th>sram_size</th>\n      <th>max_filter_size</th>\n      <th>G</th>\n      <th>C</th>\n      <th>B</th>\n      <th>J</th>\n      <th>name</th>\n      <th>bw_power</th>\n      <th>core_power</th>\n      <th>total_power</th>\n      <th>NN</th>\n      <th>NN_dataframe</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>118.0</td>\n      <td>2.0</td>\n      <td>256.0</td>\n      <td>179968.0</td>\n      <td>2048.0</td>\n      <td>3.636011e+06</td>\n      <td>18770712.0</td>\n      <td>19987780.0</td>\n      <td>0.000533</td>\n      <td>00000</td>\n      <td>79.951120</td>\n      <td>21.330414</td>\n      <td>101.281534</td>\n      <td>[[1, 9, 2, 3, 0, conv], [1, 9, 1, 3, 0, dw], [...</td>\n      <td>[[6096384.0, 252.0, 150528.0, 112896.0, 3.0, 9...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>87.0</td>\n      <td>2.0</td>\n      <td>512.0</td>\n      <td>99968.0</td>\n      <td>2048.0</td>\n      <td>2.325259e+06</td>\n      <td>14362735.0</td>\n      <td>21849702.0</td>\n      <td>0.000570</td>\n      <td>00000</td>\n      <td>87.398808</td>\n      <td>22.816285</td>\n      <td>110.215093</td>\n      <td>[[1, 9, 2, 3, 0, conv], [1, 9, 1, 3, 0, dw], [...</td>\n      <td>[[6096384.0, 252.0, 150528.0, 112896.0, 3.0, 9...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>124.0</td>\n      <td>2.0</td>\n      <td>512.0</td>\n      <td>99968.0</td>\n      <td>3072.0</td>\n      <td>2.533459e+06</td>\n      <td>12739050.0</td>\n      <td>21849702.0</td>\n      <td>0.000543</td>\n      <td>00000</td>\n      <td>87.398808</td>\n      <td>21.716202</td>\n      <td>109.115010</td>\n      <td>[[1, 9, 2, 3, 0, conv], [1, 9, 1, 3, 0, dw], [...</td>\n      <td>[[6096384.0, 252.0, 150528.0, 112896.0, 3.0, 9...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "train_hw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pycache\n",
    "import ast\n",
    "\n",
    "\n",
    "path_processed_val_nn=\"/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/DataForHASpredictor/val_low_power.csv\"\n",
    "\n",
    "def from_np_array(array_string):\n",
    "    array_string = ','.join(array_string.replace('[ ', '[').split())\n",
    "    return np.asarray(ast.literal_eval(array_string))\n",
    "\n",
    "val = pd.read_csv(path_processed_val_nn,converters={'NN_dataframe': from_np_array})\n",
    "\n",
    "X_train_nn =np.array(val['NN_dataframe'].tolist())\n",
    "#train = pd.read_csv(path_processed_train_nn,converters={'NN_dataframe': from_np_array})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "              0         1         2         3      4     5    6\n0    16257024.0     672.0  150528.0  301056.0    3.0   9.0  0.0\n1     5419008.0     240.0  301056.0  301056.0   24.0   9.0  0.0\n2    21676032.0     900.0  301056.0  451584.0   24.0   1.0  0.0\n3   158054400.0    9958.0  451584.0   68992.0  144.0   9.0  0.0\n4    29252608.0    4862.0   68992.0   68992.0   88.0   9.0  0.0\n5    94657024.0   15427.0   68992.0   84672.0  154.0  49.0  0.0\n6    80269056.0   13149.0   84672.0   84672.0  162.0  25.0  0.0\n7    42674688.0    7047.0   84672.0   84672.0  108.0   9.0  0.0\n8    53597376.0    8775.0   84672.0   84672.0  108.0  25.0  1.0\n9   104654592.0   17037.0   84672.0   84672.0  162.0  49.0  0.0\n10   21422016.0    3537.0   84672.0   84672.0   54.0   9.0  1.0\n11   40007520.0   14882.0   84672.0   25088.0  135.0  49.0  0.0\n12   25037824.0   16467.0   25088.0  391216.0   32.0   1.0  0.0\n13  782432000.0  500000.0  391216.0  784000.0  499.0   1.0  0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>16257024.0</td>\n      <td>672.0</td>\n      <td>150528.0</td>\n      <td>301056.0</td>\n      <td>3.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5419008.0</td>\n      <td>240.0</td>\n      <td>301056.0</td>\n      <td>301056.0</td>\n      <td>24.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21676032.0</td>\n      <td>900.0</td>\n      <td>301056.0</td>\n      <td>451584.0</td>\n      <td>24.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>158054400.0</td>\n      <td>9958.0</td>\n      <td>451584.0</td>\n      <td>68992.0</td>\n      <td>144.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>29252608.0</td>\n      <td>4862.0</td>\n      <td>68992.0</td>\n      <td>68992.0</td>\n      <td>88.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>94657024.0</td>\n      <td>15427.0</td>\n      <td>68992.0</td>\n      <td>84672.0</td>\n      <td>154.0</td>\n      <td>49.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>80269056.0</td>\n      <td>13149.0</td>\n      <td>84672.0</td>\n      <td>84672.0</td>\n      <td>162.0</td>\n      <td>25.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>42674688.0</td>\n      <td>7047.0</td>\n      <td>84672.0</td>\n      <td>84672.0</td>\n      <td>108.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>53597376.0</td>\n      <td>8775.0</td>\n      <td>84672.0</td>\n      <td>84672.0</td>\n      <td>108.0</td>\n      <td>25.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>104654592.0</td>\n      <td>17037.0</td>\n      <td>84672.0</td>\n      <td>84672.0</td>\n      <td>162.0</td>\n      <td>49.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>21422016.0</td>\n      <td>3537.0</td>\n      <td>84672.0</td>\n      <td>84672.0</td>\n      <td>54.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>40007520.0</td>\n      <td>14882.0</td>\n      <td>84672.0</td>\n      <td>25088.0</td>\n      <td>135.0</td>\n      <td>49.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>25037824.0</td>\n      <td>16467.0</td>\n      <td>25088.0</td>\n      <td>391216.0</td>\n      <td>32.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>782432000.0</td>\n      <td>500000.0</td>\n      <td>391216.0</td>\n      <td>784000.0</td>\n      <td>499.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "pd.DataFrame(val['NN_dataframe'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Must pass 2-d input",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-7cf355e0640b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_nn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    462\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[0;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;31m# by definition an array here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;31m# the dtypes will be coerced to a single dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mprep_ndarray\u001b[0;34m(values, copy)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Must pass 2-d input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Must pass 2-d input"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(X_train_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File /Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_train_all.csv does not exist: '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_train_all.csv'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-2b8861bd9c24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_hw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/DataForHASpredictor/new_train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_hw_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_train_all.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_train_new.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File /Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_train_all.csv does not exist: '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_train_all.csv'"
     ]
    }
   ],
   "source": [
    "train_hw = pd.read_csv('/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/DataForHASpredictor/new_train.csv')\n",
    "train_hw_old = pd.read_csv('/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_train_all.csv')\n",
    "train_all = pd.read_csv('/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_train_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                C           B    name             G         J  mac_num  \\\n0       7268254.0  17970336.0  1501.0  3.598255e+06  0.000879     76.0   \n1      14613399.0  19142521.0  1501.0  2.277913e+06  0.001274     58.0   \n2      22923332.0  18360833.0  1501.0  2.797106e+06  0.000662    118.0   \n3      25836964.0  20670026.0  1501.0  1.858189e+06  0.001977     29.0   \n4      22793145.0  18360833.0  1501.0  2.839804e+06  0.000660    134.0   \n...           ...         ...     ...           ...       ...      ...   \n28419   2463773.0   9007084.0  1569.0  2.096227e+07  0.000746    130.0   \n28420  25364967.0  31532640.0  1569.0  3.160583e+06  0.000921    200.0   \n28421   4062796.0   5803814.0  1569.0  8.571541e+06  0.000820    108.0   \n28422  26034959.0  24410683.0  1569.0  2.564763e+06  0.001388    135.0   \n28423  14851309.0  24410683.0  1569.0  2.918314e+06  0.001433    114.0   \n\n       max_filter_size  mac_array_num  total_power    bw_power  core_power  \\\n0                512.0            4.0   107.060580   71.881344   35.179236   \n1               2048.0            2.0   127.519998   76.570084   50.949914   \n2               4098.0            2.0    99.933890   73.443332   26.490558   \n3               3072.0            2.0   161.743410   82.680104   79.063306   \n4               2048.0            2.0    99.855414   73.443332   26.412082   \n...                ...            ...          ...         ...         ...   \n28419           2048.0           32.0    65.876460   36.028336   29.848124   \n28420           1024.0            2.0   162.960370  126.130560   36.829810   \n28421           1024.0            9.0    56.009309   23.215256   32.794053   \n28422           2048.0            2.0   153.152159   97.642732   55.509427   \n28423           1536.0            3.0   154.965067   97.642732   57.322335   \n\n       data_bits  sram_size  \n0         2048.0   139904.0  \n1         2048.0    99968.0  \n2          256.0   119936.0  \n3         2048.0    80000.0  \n4          256.0   119936.0  \n...          ...        ...  \n28419      512.0   379904.0  \n28420      256.0   119936.0  \n28421     1024.0   320000.0  \n28422      512.0    99968.0  \n28423     1024.0    99968.0  \n\n[28413 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>C</th>\n      <th>B</th>\n      <th>name</th>\n      <th>G</th>\n      <th>J</th>\n      <th>mac_num</th>\n      <th>max_filter_size</th>\n      <th>mac_array_num</th>\n      <th>total_power</th>\n      <th>bw_power</th>\n      <th>core_power</th>\n      <th>data_bits</th>\n      <th>sram_size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7268254.0</td>\n      <td>17970336.0</td>\n      <td>1501.0</td>\n      <td>3.598255e+06</td>\n      <td>0.000879</td>\n      <td>76.0</td>\n      <td>512.0</td>\n      <td>4.0</td>\n      <td>107.060580</td>\n      <td>71.881344</td>\n      <td>35.179236</td>\n      <td>2048.0</td>\n      <td>139904.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14613399.0</td>\n      <td>19142521.0</td>\n      <td>1501.0</td>\n      <td>2.277913e+06</td>\n      <td>0.001274</td>\n      <td>58.0</td>\n      <td>2048.0</td>\n      <td>2.0</td>\n      <td>127.519998</td>\n      <td>76.570084</td>\n      <td>50.949914</td>\n      <td>2048.0</td>\n      <td>99968.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22923332.0</td>\n      <td>18360833.0</td>\n      <td>1501.0</td>\n      <td>2.797106e+06</td>\n      <td>0.000662</td>\n      <td>118.0</td>\n      <td>4098.0</td>\n      <td>2.0</td>\n      <td>99.933890</td>\n      <td>73.443332</td>\n      <td>26.490558</td>\n      <td>256.0</td>\n      <td>119936.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>25836964.0</td>\n      <td>20670026.0</td>\n      <td>1501.0</td>\n      <td>1.858189e+06</td>\n      <td>0.001977</td>\n      <td>29.0</td>\n      <td>3072.0</td>\n      <td>2.0</td>\n      <td>161.743410</td>\n      <td>82.680104</td>\n      <td>79.063306</td>\n      <td>2048.0</td>\n      <td>80000.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>22793145.0</td>\n      <td>18360833.0</td>\n      <td>1501.0</td>\n      <td>2.839804e+06</td>\n      <td>0.000660</td>\n      <td>134.0</td>\n      <td>2048.0</td>\n      <td>2.0</td>\n      <td>99.855414</td>\n      <td>73.443332</td>\n      <td>26.412082</td>\n      <td>256.0</td>\n      <td>119936.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>28419</th>\n      <td>2463773.0</td>\n      <td>9007084.0</td>\n      <td>1569.0</td>\n      <td>2.096227e+07</td>\n      <td>0.000746</td>\n      <td>130.0</td>\n      <td>2048.0</td>\n      <td>32.0</td>\n      <td>65.876460</td>\n      <td>36.028336</td>\n      <td>29.848124</td>\n      <td>512.0</td>\n      <td>379904.0</td>\n    </tr>\n    <tr>\n      <th>28420</th>\n      <td>25364967.0</td>\n      <td>31532640.0</td>\n      <td>1569.0</td>\n      <td>3.160583e+06</td>\n      <td>0.000921</td>\n      <td>200.0</td>\n      <td>1024.0</td>\n      <td>2.0</td>\n      <td>162.960370</td>\n      <td>126.130560</td>\n      <td>36.829810</td>\n      <td>256.0</td>\n      <td>119936.0</td>\n    </tr>\n    <tr>\n      <th>28421</th>\n      <td>4062796.0</td>\n      <td>5803814.0</td>\n      <td>1569.0</td>\n      <td>8.571541e+06</td>\n      <td>0.000820</td>\n      <td>108.0</td>\n      <td>1024.0</td>\n      <td>9.0</td>\n      <td>56.009309</td>\n      <td>23.215256</td>\n      <td>32.794053</td>\n      <td>1024.0</td>\n      <td>320000.0</td>\n    </tr>\n    <tr>\n      <th>28422</th>\n      <td>26034959.0</td>\n      <td>24410683.0</td>\n      <td>1569.0</td>\n      <td>2.564763e+06</td>\n      <td>0.001388</td>\n      <td>135.0</td>\n      <td>2048.0</td>\n      <td>2.0</td>\n      <td>153.152159</td>\n      <td>97.642732</td>\n      <td>55.509427</td>\n      <td>512.0</td>\n      <td>99968.0</td>\n    </tr>\n    <tr>\n      <th>28423</th>\n      <td>14851309.0</td>\n      <td>24410683.0</td>\n      <td>1569.0</td>\n      <td>2.918314e+06</td>\n      <td>0.001433</td>\n      <td>114.0</td>\n      <td>1536.0</td>\n      <td>3.0</td>\n      <td>154.965067</td>\n      <td>97.642732</td>\n      <td>57.322335</td>\n      <td>1024.0</td>\n      <td>99968.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>28413 rows  13 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "train_hw = train_hw[train_hw.C != 'C']\n",
    "#al_hw = val_hw[val_hw.C != 'C']\n",
    "\n",
    "train_hw.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train_hw_old' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-ad7552efc5cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_hw_old\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_hw_old' is not defined"
     ]
    }
   ],
   "source": [
    "train_hw_old.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            C           B      name                   G  \\\n0   7268254.0  17970336.0  00001501  3598255.3109029434   \n1  14613399.0  19142521.0  00001501  2277912.6023773067   \n2  22923332.0  18360833.0  00001501   2797106.426879716   \n3  25836964.0  20670026.0  00001501   1858189.091508767   \n4  22793145.0  18360833.0  00001501   2839804.299988273   \n\n                       J mac_num max_filter_size mac_array_num  \\\n0   0.000879480903465003    76.0           512.0           4.0   \n1  0.0012737478559800043    58.0          2048.0           2.0   \n2  0.0006622639444620016   118.0          4098.0           2.0   \n3  0.0019765826388869756    29.0          3072.0           2.0   \n4  0.0006603020464379995   134.0          2048.0           2.0   \n\n          total_power   bw_power          core_power data_bits sram_size  \n0  107.06058013860012  71.881344   35.17923613860012    2048.0  139904.0  \n1  127.51999823920016  76.570084  50.949914239200176    2048.0   99968.0  \n2   99.93388977848007  73.443332  26.490557778480063     256.0  119936.0  \n3  161.74340955547902  82.680104   79.06330555547902    2048.0   80000.0  \n4   99.85541385751998  73.443332   26.41208185751998     256.0  119936.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>C</th>\n      <th>B</th>\n      <th>name</th>\n      <th>G</th>\n      <th>J</th>\n      <th>mac_num</th>\n      <th>max_filter_size</th>\n      <th>mac_array_num</th>\n      <th>total_power</th>\n      <th>bw_power</th>\n      <th>core_power</th>\n      <th>data_bits</th>\n      <th>sram_size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7268254.0</td>\n      <td>17970336.0</td>\n      <td>00001501</td>\n      <td>3598255.3109029434</td>\n      <td>0.000879480903465003</td>\n      <td>76.0</td>\n      <td>512.0</td>\n      <td>4.0</td>\n      <td>107.06058013860012</td>\n      <td>71.881344</td>\n      <td>35.17923613860012</td>\n      <td>2048.0</td>\n      <td>139904.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14613399.0</td>\n      <td>19142521.0</td>\n      <td>00001501</td>\n      <td>2277912.6023773067</td>\n      <td>0.0012737478559800043</td>\n      <td>58.0</td>\n      <td>2048.0</td>\n      <td>2.0</td>\n      <td>127.51999823920016</td>\n      <td>76.570084</td>\n      <td>50.949914239200176</td>\n      <td>2048.0</td>\n      <td>99968.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22923332.0</td>\n      <td>18360833.0</td>\n      <td>00001501</td>\n      <td>2797106.426879716</td>\n      <td>0.0006622639444620016</td>\n      <td>118.0</td>\n      <td>4098.0</td>\n      <td>2.0</td>\n      <td>99.93388977848007</td>\n      <td>73.443332</td>\n      <td>26.490557778480063</td>\n      <td>256.0</td>\n      <td>119936.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>25836964.0</td>\n      <td>20670026.0</td>\n      <td>00001501</td>\n      <td>1858189.091508767</td>\n      <td>0.0019765826388869756</td>\n      <td>29.0</td>\n      <td>3072.0</td>\n      <td>2.0</td>\n      <td>161.74340955547902</td>\n      <td>82.680104</td>\n      <td>79.06330555547902</td>\n      <td>2048.0</td>\n      <td>80000.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>22793145.0</td>\n      <td>18360833.0</td>\n      <td>00001501</td>\n      <td>2839804.299988273</td>\n      <td>0.0006603020464379995</td>\n      <td>134.0</td>\n      <td>2048.0</td>\n      <td>2.0</td>\n      <td>99.85541385751998</td>\n      <td>73.443332</td>\n      <td>26.41208185751998</td>\n      <td>256.0</td>\n      <td>119936.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "train_hw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'X_train_hw_param' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-5b7aa5afccad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_hw_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mac_num'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_hw_param' is not defined"
     ]
    }
   ],
   "source": [
    "type(X_train_hw_param['mac_num'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'X_train_hw_param' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-5f8ccb46310d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_hw_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_power'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_hw_param' is not defined"
     ]
    }
   ],
   "source": [
    "type(X_train_hw_param['total_power'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'str'>\n0\n"
    }
   ],
   "source": [
    "#train_hw['mac_num']*train_hw['mac_array_num']\n",
    "\n",
    "X_train_hw_param = train_hw\n",
    "\n",
    "for i in range(len(X_train_hw_param)):\n",
    "\n",
    "    if type(X_train_hw_param['mac_num'][i]) != float :\n",
    "        print (type(X_train_hw_param['mac_num'][i]))\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas\n",
    "import pandas as pd\n",
    "os.chdir(\"/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data\")\n",
    "extension = 'csv'\n",
    "\n",
    "trains = [\"/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/data_180035train/parsed_nondups_train_2.csv\", \"/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/DataForHASpredictor2/new_parsed_train.csv\"]\n",
    "\n",
    "vals = [\"/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/data_180035train/parsed_nondups_val_2.csv\", \"/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/DataForHASpredictor2/new_parsed_val.csv\"]\n",
    "#all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "\n",
    "\n",
    "#combine all files in the list\n",
    "#train_csv = pd.concat([pd.read_csv(f) for f in trains])\n",
    "#val_csv = pd.concat([pd.read_csv(f) for f in vals])\n",
    "\n",
    "train_l = []\n",
    "for f in trains:\n",
    "    panda = pd.read_csv(f)\n",
    "    panda = panda[panda.C != 'C']\n",
    "    panda = panda.astype(float)\n",
    "    train_l.append(panda)\n",
    "train_csv = pd.concat(train_l)\n",
    "\n",
    "\n",
    "\n",
    "val_l = []\n",
    "for f in vals:\n",
    "    panda = pd.read_csv(f)\n",
    "    panda = panda[panda.C != 'C']\n",
    "    panda = panda.astype(float)\n",
    "    val_l.append(panda)\n",
    "val_csv = pd.concat(val_l)\n",
    "\n",
    "\n",
    "\n",
    "#train_hw = train_hw[train_hw.C != 'C']\n",
    "#export to csv\n",
    "train_csv.to_csv( \"parsed_nondups_train_3.csv\", index=False, encoding='utf-8-sig')\n",
    "val_csv.to_csv( \"parsed_nondups_val_3.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "all_nets.json              train_7.csv\nparsed_nondups_train_1.csv train_7_new.csv\nparsed_nondups_train_2.csv \u001b[1m\u001b[36mtxt\u001b[m\u001b[m\nparsed_nondups_val_1.csv   val_13_all.csv\nparsed_nondups_val_2.csv   val_21_all.csv\ntrain_13_all.csv           val_7.csv\ntrain_21_all.csv           val_7_new.csv\n"
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File /Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_train_new.csv does not exist: '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_train_new.csv'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-e93b0e6cdab0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_hw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_train_new.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File /Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_train_new.csv does not exist: '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_train_new.csv'"
     ]
    }
   ],
   "source": [
    "train_hw = pd.read_csv('/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_train_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "28413"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "len(train_hw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "diter les Mta-Donnes",
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('has': conda)",
   "language": "python",
   "name": "python361064bithascondabd8f1537e5d34ba799ef15b8707e6526"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}