{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import glob, os\n",
    "from numpy import savetxt, loadtxt, asarray\n",
    "\n",
    "\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nets = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/DataForHASpredictor2/all_nets.json'\n",
    "more_nets = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/DataForHASpredictor2'\n",
    "\n",
    "# parsed_nondups_val1 = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_val1_fix.txt'\n",
    "# parsed_nondups_train1 = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_train1_fix.txt'\n",
    "\n",
    "# parsed_nondups_val1_csv = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_val1.csv'\n",
    "# parsed_nondups_train1_csv = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_train1.csv'\n",
    "\n",
    "# parsed_nondups_val2 = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_val2.txt'\n",
    "# parsed_nondups_train2 = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_train2.txt'\n",
    "\n",
    "\n",
    "# parsed_nondups_val_csv = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_val_2.csv'\n",
    "# parsed_nondups_train_csv = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_train_2.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (DONE) Convert txt to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "UsageError: Line magic function `%pycache` not found.\n"
    }
   ],
   "source": [
    "%pycache\n",
    "number = 2\n",
    "\n",
    "with open(parsed_nondups_val2, 'r') as in_file:\n",
    "    stripped = (line.strip() for line in in_file)\n",
    "    lines = (line.split(\",\") for line in stripped if line)\n",
    "    with open(f'parsed_nondups_val{number}.csv', 'w') as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        writer.writerows(lines)\n",
    "\n",
    "with open(parsed_nondups_train2, 'r') as in_file:\n",
    "    stripped = (line.strip() for line in in_file)\n",
    "    lines = (line.split(\",\") for line in stripped if line)\n",
    "    with open(f'parsed_nondups_train{number}.csv', 'w') as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        writer.writerows(lines)\n",
    "\n",
    "\n",
    "\n",
    "# parsed_nondups_val2 = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_val2.txt'\n",
    "# parsed_nondups_train2 = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_train2.txt'\n",
    "\n",
    "# train_hw = pd.read_csv(parsed_nondups_train1_csv)\n",
    "# val_hw = pd.read_csv(parsed_nondups_val1_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treat Additional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "train_00001600-00001649.txt\ntrain_00001850-00001899.txt\ntrain_00002000-00002049.txt\ntrain_00002300-00002349.txt\ntrain_00002200-00002249.txt\ntrain_00001950-00001999.txt\ntrain_00002100-00002149.txt\ntrain_00001700-00001749.txt\ntrain_00001750-00001799.txt\ntrain_00002250-00002299.txt\ntrain_00002150-00002199.txt\ntrain_00001900-00001949.txt\ntrain_00002050-00002099.txt\ntrain_00001800-00001849.txt\ntrain_00002350-00002399.txt\ntrain_00001650-00001699.txt\n"
    }
   ],
   "source": [
    "#%pycache\n",
    "os.chdir(more_nets)\n",
    "add_train = glob.glob(\"train*.txt\")\n",
    "add_val =  glob.glob(\"val*.txt\")\n",
    "\n",
    "with open(f'new_parsed_train.csv', 'w') as out_file:\n",
    "    c=0\n",
    "    writer = csv.writer(out_file)\n",
    "    for train in add_train:\n",
    "        print(train)\n",
    "        with open(more_nets +'/'+ train, 'r') as in_file:\n",
    "            stripped = (line.strip() for line in in_file)\n",
    "            lines = (line.split(\",\") for line in stripped if line)\n",
    "            writer.writerows(lines)\n",
    "\n",
    "\n",
    "with open(f'new_parsed_val.csv', 'w') as out_file:\n",
    "    c=0\n",
    "    for val in add_val:\n",
    "        with open(more_nets +'/'+ val, 'r') as in_file:\n",
    "            stripped = (line.strip() for line in in_file  )\n",
    "            lines = (line.split(\",\") for line in stripped if line)\n",
    "            writer = csv.writer(out_file)\n",
    "            writer.writerows(lines)\n",
    "\n",
    "#ALL\n",
    "parsed_nondups_val_csv = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/DataForHASpredictor2/new_parsed_val.csv'\n",
    "parsed_nondups_train_csv = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/DataForHASpredictor2/new_parsed_train.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hw = pd.read_csv(parsed_nondups_train_csv)\n",
    "val_hw = pd.read_csv(parsed_nondups_val_csv)\n",
    "\n",
    "\n",
    "train_hw = train_hw[train_hw.C != 'C']\n",
    "val_hw = val_hw[val_hw.C != 'C']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "              C          B      name                   G  \\\n2531   748323.0  2679043.0  00001619   8141295.936344964   \n2532  6129302.0  7236639.0  00001619  1698060.5572549982   \n2533  6015364.0  7236639.0  00001619  1757963.4398911092   \n\n                          J mac_num max_filter_size mac_array_num  \\\n2531  9.865678969799997e-05    65.0          4098.0           7.0   \n2532  8.896639770600013e-05    28.0           512.0           2.0   \n2533  8.506332450000004e-05    41.0           512.0           2.0   \n\n             total_power   bw_power          core_power data_bits sram_size  \n2531  14.662443587919999  10.716172  3.9462715879199988    2048.0  379904.0  \n2532   32.50521190824001  28.946556  3.5586559082400053     128.0   80000.0  \n2533  32.349088980000005  28.946556  3.4025329800000015     128.0   80000.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>C</th>\n      <th>B</th>\n      <th>name</th>\n      <th>G</th>\n      <th>J</th>\n      <th>mac_num</th>\n      <th>max_filter_size</th>\n      <th>mac_array_num</th>\n      <th>total_power</th>\n      <th>bw_power</th>\n      <th>core_power</th>\n      <th>data_bits</th>\n      <th>sram_size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2531</th>\n      <td>748323.0</td>\n      <td>2679043.0</td>\n      <td>00001619</td>\n      <td>8141295.936344964</td>\n      <td>9.865678969799997e-05</td>\n      <td>65.0</td>\n      <td>4098.0</td>\n      <td>7.0</td>\n      <td>14.662443587919999</td>\n      <td>10.716172</td>\n      <td>3.9462715879199988</td>\n      <td>2048.0</td>\n      <td>379904.0</td>\n    </tr>\n    <tr>\n      <th>2532</th>\n      <td>6129302.0</td>\n      <td>7236639.0</td>\n      <td>00001619</td>\n      <td>1698060.5572549982</td>\n      <td>8.896639770600013e-05</td>\n      <td>28.0</td>\n      <td>512.0</td>\n      <td>2.0</td>\n      <td>32.50521190824001</td>\n      <td>28.946556</td>\n      <td>3.5586559082400053</td>\n      <td>128.0</td>\n      <td>80000.0</td>\n    </tr>\n    <tr>\n      <th>2533</th>\n      <td>6015364.0</td>\n      <td>7236639.0</td>\n      <td>00001619</td>\n      <td>1757963.4398911092</td>\n      <td>8.506332450000004e-05</td>\n      <td>41.0</td>\n      <td>512.0</td>\n      <td>2.0</td>\n      <td>32.349088980000005</td>\n      <td>28.946556</td>\n      <td>3.4025329800000015</td>\n      <td>128.0</td>\n      <td>80000.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "train_hw[2531:2534]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  (NOT USED) Filter 70% size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "UsageError: Line magic function `%pycache` not found.\n"
    }
   ],
   "source": [
    "%pycache\n",
    "val_hw[\"total_power\"]=pd.to_numeric(val_hw[\"total_power\"], errors='coerce')\n",
    "train_hw[\"total_power\"]=pd.to_numeric(train_hw[\"total_power\"], errors='coerce')\n",
    "\n",
    "\n",
    "train_hw = train_hw[(train_hw.total_power) < 200]\n",
    "val_hw = val_hw[(val_hw.total_power) < 200 ]\n",
    "\n",
    "\n",
    "train_hw.to_csv( \"parsed_nondups_train_lower_power.csv\", index=False, encoding='utf-8-sig')\n",
    "val_hw.to_csv( \"parsed_nondups_val_lower_power.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks Dictionnary - Old + New nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open(all_nets, 'r') as f:\n",
    "    nets_dict = json.load(f)\n",
    "\n",
    "\n",
    "os.chdir(more_nets)\n",
    "all_filenames = glob.glob(\"*.json\")\n",
    "for file in all_filenames:\n",
    "    with open(more_nets +'/'+ file, 'r') as f:\n",
    "        file_dict = json.load(f)\n",
    "        nets_dict.update(file_dict)\n",
    "len(nets_dict.keys())\n",
    "\n",
    "def number_zeros(k):\n",
    "    nb = len(k)\n",
    "    return \"0\"*(8-nb)\n",
    "\n",
    "\n",
    "def f(mydict):\n",
    "    return dict((number_zeros(k)+k,f(v) if hasattr(v,'keys') else v) for k,v in mydict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nets_dict = f(nets_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "'00002449' in nets_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['00000000', '00000001', '00000002', ..., '00002447', '00002448',\n       '00002449'], dtype='<U8')"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "np.sort(list(nets_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2449"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "len(nets_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max block size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_blocks = 0\n",
    "for k,nn in nets_dict.items():\n",
    "    if len(nn)>max_blocks:\n",
    "        max_blocks=len(nn)\n",
    "\n",
    "max_blocks = max_blocks +1 # add fc layer at the end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "37"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "max_blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General information \n",
    "\n",
    "nets_dict_keys :0000 to 00531 (532)\n",
    "\n",
    "Train : 453 different NN\n",
    "\n",
    "Val : 50 different NN\n",
    "\n",
    "\n",
    "# Size dataset\n",
    "\n",
    "#### Train 1: 137,090\n",
    "#### Val 1: 13,804\n",
    "#### Train 2: 14,532\n",
    "#### Val 2: 2,882"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_NN_name(x):\n",
    "    x=int(x)\n",
    "    x=str(x)\n",
    "    while len(str(x))<8 :\n",
    "        x = '0'+str(x)\n",
    "    return x\n",
    "\n",
    "train_hw['name']=train_hw['name'].apply(lambda x : convert_NN_name(x))\n",
    "val_hw['name']=val_hw['name'].apply(lambda x : convert_NN_name(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            C          B      name                   G  \\\n0  11944703.0  3771067.0  00001642   1658074.656352509   \n1   8433638.0  4002079.0  00001642  1570522.2101876577   \n2  10753855.0  4002079.0  00001642  1411966.0827421746   \n3   1110008.0  3708652.0  00001642  10185009.221130842   \n4  11869528.0  4002079.0  00001642  1374615.4980233472   \n\n                        J mac_num max_filter_size mac_array_num  \\\n0  0.00016476742908900027    20.0           512.0           2.0   \n1  0.00015681514086299977    21.0           512.0           3.0   \n2  0.00014640667743900034    30.0           512.0           2.0   \n3  0.00010648946978700016   189.0          1536.0          14.0   \n4  0.00017413813578299998    20.0          1024.0           2.0   \n\n          total_power   bw_power          core_power data_bits sram_size  \n0   21.67496516356001  15.084268  6.5906971635600105     128.0   80000.0  \n1   22.28092163451999  16.008316   6.272605634519991     128.0   60000.0  \n2  21.864583097560015  16.008316   5.856267097560014     128.0   60000.0  \n3  19.094186791480006  14.834608   4.259578791480006     512.0   99968.0  \n4      22.97384143132  16.008316   6.965525431319999     128.0   60000.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>C</th>\n      <th>B</th>\n      <th>name</th>\n      <th>G</th>\n      <th>J</th>\n      <th>mac_num</th>\n      <th>max_filter_size</th>\n      <th>mac_array_num</th>\n      <th>total_power</th>\n      <th>bw_power</th>\n      <th>core_power</th>\n      <th>data_bits</th>\n      <th>sram_size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11944703.0</td>\n      <td>3771067.0</td>\n      <td>00001642</td>\n      <td>1658074.656352509</td>\n      <td>0.00016476742908900027</td>\n      <td>20.0</td>\n      <td>512.0</td>\n      <td>2.0</td>\n      <td>21.67496516356001</td>\n      <td>15.084268</td>\n      <td>6.5906971635600105</td>\n      <td>128.0</td>\n      <td>80000.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8433638.0</td>\n      <td>4002079.0</td>\n      <td>00001642</td>\n      <td>1570522.2101876577</td>\n      <td>0.00015681514086299977</td>\n      <td>21.0</td>\n      <td>512.0</td>\n      <td>3.0</td>\n      <td>22.28092163451999</td>\n      <td>16.008316</td>\n      <td>6.272605634519991</td>\n      <td>128.0</td>\n      <td>60000.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10753855.0</td>\n      <td>4002079.0</td>\n      <td>00001642</td>\n      <td>1411966.0827421746</td>\n      <td>0.00014640667743900034</td>\n      <td>30.0</td>\n      <td>512.0</td>\n      <td>2.0</td>\n      <td>21.864583097560015</td>\n      <td>16.008316</td>\n      <td>5.856267097560014</td>\n      <td>128.0</td>\n      <td>60000.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1110008.0</td>\n      <td>3708652.0</td>\n      <td>00001642</td>\n      <td>10185009.221130842</td>\n      <td>0.00010648946978700016</td>\n      <td>189.0</td>\n      <td>1536.0</td>\n      <td>14.0</td>\n      <td>19.094186791480006</td>\n      <td>14.834608</td>\n      <td>4.259578791480006</td>\n      <td>512.0</td>\n      <td>99968.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11869528.0</td>\n      <td>4002079.0</td>\n      <td>00001642</td>\n      <td>1374615.4980233472</td>\n      <td>0.00017413813578299998</td>\n      <td>20.0</td>\n      <td>1024.0</td>\n      <td>2.0</td>\n      <td>22.97384143132</td>\n      <td>16.008316</td>\n      <td>6.965525431319999</td>\n      <td>128.0</td>\n      <td>60000.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "train_hw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                C           B      name                   G  \\\n35423  51108099.0  39678749.0  00001695  2166257.3203038117   \n\n                          J mac_num max_filter_size mac_array_num  \\\n35423  0.002254929273794983    57.0          1536.0           2.0   \n\n              total_power    bw_power         core_power data_bits sram_size  \n35423  248.91216695179932  158.714996  90.19717095179931     512.0   99968.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>C</th>\n      <th>B</th>\n      <th>name</th>\n      <th>G</th>\n      <th>J</th>\n      <th>mac_num</th>\n      <th>max_filter_size</th>\n      <th>mac_array_num</th>\n      <th>total_power</th>\n      <th>bw_power</th>\n      <th>core_power</th>\n      <th>data_bits</th>\n      <th>sram_size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>35423</th>\n      <td>51108099.0</td>\n      <td>39678749.0</td>\n      <td>00001695</td>\n      <td>2166257.3203038117</td>\n      <td>0.002254929273794983</td>\n      <td>57.0</td>\n      <td>1536.0</td>\n      <td>2.0</td>\n      <td>248.91216695179932</td>\n      <td>158.714996</td>\n      <td>90.19717095179931</td>\n      <td>512.0</td>\n      <td>99968.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "train_hw[-2:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add neural network to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hw[\"NN\"]=train_hw['name'].map(nets_dict)\n",
    "val_hw[\"NN\"]=val_hw['name'].map(nets_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treat NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME DIDNT COUNT ACTIVATION\n",
    "\n",
    "def conv_flops(hout,cin,cout,k,tensor_in,skip=0):\n",
    "    flops = 2*k*k*cin*hout*hout*cout\n",
    "    if skip ==1:\n",
    "        flops += tensor_in\n",
    "    return flops\n",
    "\n",
    "def dw_flops(hout,c,k,tensor_in,skip=0, mult=1):\n",
    "    flops = 2*k*k*c*hout*hout\n",
    "    if skip == 1:\n",
    "        flops +=tensor_in\n",
    "    return flops\n",
    "\n",
    "def fcc_flops(i, j):\n",
    "    return (2*i-1)*j\n",
    "\n",
    "def calculate_flop(convtype,hin,hout,cin,cout,k,exp,tensor_in, skip=0, mult=1,skip_op=False):\n",
    "    if skip_op==True:\n",
    "        return 0\n",
    "    else:\n",
    "        if convtype=='conv':\n",
    "            return conv_flops(hout,cin,cout,k, tensor_in, skip)\n",
    "        elif convtype=='dw':\n",
    "            return dw_flops(hout,cin,k,tensor_in,skip)\n",
    "        elif convtype=='inv':\n",
    "            hout_pointwise = hin\n",
    "            return conv_flops(hout=hout_pointwise, cin=cin,cout=cin*exp,k=1, tensor_in=tensor_in, skip=skip) + \\\n",
    "        dw_flops(hout=hout,c=cin*exp,k=k,tensor_in=0,skip=0) + \\\n",
    "        conv_flops(hout=hout,cin=cin*exp,cout=cout,k=1, tensor_in=0, skip=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Calculate weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_weights(cin,cout,k):\n",
    "    return (k*k*cin+1)*cout\n",
    "\n",
    "def dw_weights(cin,k,mult=1):\n",
    "    #dw = equi cin=1 and multiply by cout\n",
    "    #return conv_flops(hout,1,cin,k)*mult\n",
    "    return (k*k+1)*cin\n",
    "\n",
    "def fcc_weight(i, j):\n",
    "    return\n",
    "    #return (2*i-1)*j\n",
    "\n",
    "def calculate_weights(convtype,cin,cout,k,exp,mult=1):\n",
    "    if convtype=='conv':\n",
    "        return conv_weights(cin,cout,k)\n",
    "    elif convtype=='dw':\n",
    "        return dw_weights(cin,k)\n",
    "    elif convtype=='inv':\n",
    "        return conv_weights(cin, cin*exp, 1)+ dw_weights(cin*exp,k,mult) + conv_weights(cin*exp,cout,1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distinguish columns between convtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def distinct_contypes(NN_frame, columns_names, conv_types):\n",
    "    columns_names_augmented = [ f'{name}_{conv_type}' for conv_type in conv_types for name in columns_names]\n",
    "    NN_frame_processed= pd.DataFrame(None, index=np.arange(len(NN)+1), columns=columns_names_augmented)\n",
    "\n",
    "    ### Len(NN)+1  beceause +1 FC layer at the end\n",
    "    for conv_type in conv_types:\n",
    "        columns_conv_type = [f'{columns_name}_{conv_type}' for columns_name in columns_names]\n",
    "        NN_frame_processed[columns_conv_type] = NN_frame.loc[NN_frame['convtype']==conv_type, columns_names]\n",
    "    return NN_frame_processed.fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treat the neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nb_classes= 1000\n",
    "separate_types = False\n",
    "\n",
    "# def no_relu(NN_frame):  \n",
    "#     NN_frame['convtype']= NN_frame['convtype'].apply(lambda x : 'conv' if x=='conv_norelu' else x)\n",
    "\n",
    "def treat_NN(NN_frame, values_to_keep, separate_types):\n",
    "    fc_block = {'exp':1, 'c_out':1000, 's':1, 'k':1, 'skip':0,'convtype':'conv'}\n",
    "    NN_frame=NN_frame.append(fc_block, ignore_index=True)\n",
    "    import pdb\n",
    "   # pdb.set_trace()\n",
    "\n",
    "    #no_relu\n",
    "    NN_frame['convtype']= NN_frame['convtype'].apply(lambda x : 'conv' if x=='conv_norelu' else x)\n",
    "\n",
    "    NN_frame['c_in'] = np.roll(NN_frame['c_out'], 1)\n",
    "    NN_frame['c_in'][0]=3 # RGB channels\n",
    "\n",
    "    NN_frame['k2']=NN_frame['k'].apply(lambda x : x*x)\n",
    "    NN_frame['hidden_dim']=NN_frame['exp']*NN_frame['c_in']\n",
    "\n",
    "    NN_frame['h_in'] = np.nan\n",
    "    NN_frame['h_in'][0]=224 # Size imagenet - hardcoded\n",
    "    for i in range(1, len(NN_frame)):\n",
    "        if NN_frame.loc[i-1, 's']==1:\n",
    "            NN_frame.loc[i, 'h_in']=NN_frame.loc[i-1, 'h_in']\n",
    "        elif NN_frame.loc[i-1, 's']==2:\n",
    "            NN_frame.loc[i, 'h_in']=NN_frame.loc[i-1, 'h_in']/2\n",
    "        else : \n",
    "            raise NameError('Dont know the paddind')\n",
    "\n",
    "\n",
    "    NN_frame['h_out'] = np.roll(NN_frame['h_in'], -1)\n",
    "    NN_frame['h_out'][NN_frame.last_valid_index()]=NN_frame['h_in'][NN_frame.last_valid_index()]/NN_frame.loc[NN_frame.last_valid_index(), 's']\n",
    "\n",
    "    NN_frame['tensor_in']=NN_frame['c_in']*NN_frame['h_in']*NN_frame['h_in']\n",
    "    NN_frame['tensor_out']=NN_frame['c_out']*NN_frame['h_out']*NN_frame['h_out']\n",
    "\n",
    "    NN_frame['weights']=NN_frame.apply(lambda x : calculate_weights(x.convtype,x.c_in,x.c_out,x.k,x.exp), axis=1)\n",
    "    NN_frame['FLOPS']= NN_frame.apply(lambda x : calculate_flop(x.convtype,x.h_in,x.h_out,x.c_in,x.c_out,x.k,x.exp, x.tensor_in,x.skip), axis=1)\n",
    "    #return  NN_frame\n",
    "    if separate_types:\n",
    "        NN_frame=NN_frame.loc[:, values_to_keep + ['convtype']]\n",
    "        NN_frame =distinct_contypes(NN_frame, values_to_keep, conv_types)\n",
    "        #values_to_keep = [f'{value}_{type}' for type in conv_types for value in values_to_keep]\n",
    "    else:\n",
    "        NN_frame =NN_frame.loc[:, values_to_keep]\n",
    "    return  NN_frame\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example NN_treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          FLOPS  weights  tensor_in  tensor_out  hidden_dim  k2  skip\n0    20321280.0      840   150528.0    376320.0           3   9     0\n1     6773760.0      300   376320.0    376320.0          30   9     0\n2    22579200.0      930   376320.0    376320.0          30   1     0\n3    37255680.0     5962   376320.0     68992.0          30   9     0\n4    29321600.0     4862    68992.0     68992.0          88   9     1\n5    27389824.0     4378    68992.0     68992.0          22   9     1\n6    27389824.0     4378    68992.0     68992.0          22   9     1\n7    58781184.0     9676    68992.0    125440.0         132   9     0\n8    90442240.0    14440   125440.0    125440.0          40   9     1\n9    28788480.0    18411   125440.0     39984.0          40   9     0\n10   51659328.0    70246    39984.0     13720.0         408  49     0\n11    5186160.0    53004    13720.0      4116.0          70   9     0\n12   12405624.0   128178     4116.0     69678.0          84   1     0\n13  139356000.0  1423000    69678.0     49000.0        1422   1     0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FLOPS</th>\n      <th>weights</th>\n      <th>tensor_in</th>\n      <th>tensor_out</th>\n      <th>hidden_dim</th>\n      <th>k2</th>\n      <th>skip</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20321280.0</td>\n      <td>840</td>\n      <td>150528.0</td>\n      <td>376320.0</td>\n      <td>3</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6773760.0</td>\n      <td>300</td>\n      <td>376320.0</td>\n      <td>376320.0</td>\n      <td>30</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22579200.0</td>\n      <td>930</td>\n      <td>376320.0</td>\n      <td>376320.0</td>\n      <td>30</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>37255680.0</td>\n      <td>5962</td>\n      <td>376320.0</td>\n      <td>68992.0</td>\n      <td>30</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>29321600.0</td>\n      <td>4862</td>\n      <td>68992.0</td>\n      <td>68992.0</td>\n      <td>88</td>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>27389824.0</td>\n      <td>4378</td>\n      <td>68992.0</td>\n      <td>68992.0</td>\n      <td>22</td>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>27389824.0</td>\n      <td>4378</td>\n      <td>68992.0</td>\n      <td>68992.0</td>\n      <td>22</td>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>58781184.0</td>\n      <td>9676</td>\n      <td>68992.0</td>\n      <td>125440.0</td>\n      <td>132</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>90442240.0</td>\n      <td>14440</td>\n      <td>125440.0</td>\n      <td>125440.0</td>\n      <td>40</td>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>28788480.0</td>\n      <td>18411</td>\n      <td>125440.0</td>\n      <td>39984.0</td>\n      <td>40</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>51659328.0</td>\n      <td>70246</td>\n      <td>39984.0</td>\n      <td>13720.0</td>\n      <td>408</td>\n      <td>49</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>5186160.0</td>\n      <td>53004</td>\n      <td>13720.0</td>\n      <td>4116.0</td>\n      <td>70</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12405624.0</td>\n      <td>128178</td>\n      <td>4116.0</td>\n      <td>69678.0</td>\n      <td>84</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>139356000.0</td>\n      <td>1423000</td>\n      <td>69678.0</td>\n      <td>49000.0</td>\n      <td>1422</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "conv_types = ['conv', 'dw', 'inv']\n",
    "columns_names = ['exp','c_out','s','k','skip']\n",
    "values_to_keep = ['FLOPS','weights','tensor_in','tensor_out','hidden_dim','k2', 'skip']\n",
    "#values_to_keep_plus_type = ['FLOPS','weights','tensor_in','tensor_out','hidden_dim','k2', 'skip', 'convtype']\n",
    "\n",
    "\n",
    "\n",
    "NN = nets_dict['00001754']\n",
    "NN_frame = pd.DataFrame(NN, columns = columns_names+ ['convtype',])\n",
    "\n",
    "#distinct =distinct_contypes(NN_frame, columns_names, conv_types)\n",
    "NN_00001 = treat_NN(NN_frame, values_to_keep, False)\n",
    "NN_00001\n",
    "#distinct.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify properperly calculate number of weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Initialize one NN : nets_dict[00001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\nModel: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 224, 224, 3)       0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 112, 112, 35)      980       \n_________________________________________________________________\ndepthwise_conv2d_1 (Depthwis (None, 112, 112, 35)      350       \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 112, 112, 34)      1224      \n_________________________________________________________________\nactivation_1 (Activation)    (None, 112, 112, 34)      0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 112, 112, 170)     5950      \n_________________________________________________________________\ndepthwise_conv2d_2 (Depthwis (None, 56, 56, 170)       4420      \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 56, 56, 9)         1539      \n_________________________________________________________________\nactivation_2 (Activation)    (None, 56, 56, 9)         0         \n_________________________________________________________________\nactivation_3 (Activation)    (None, 56, 56, 9)         0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 56, 56, 45)        450       \n_________________________________________________________________\ndepthwise_conv2d_3 (Depthwis (None, 56, 56, 45)        450       \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 56, 56, 9)         414       \n_________________________________________________________________\nactivation_4 (Activation)    (None, 56, 56, 9)         0         \n_________________________________________________________________\nactivation_5 (Activation)    (None, 56, 56, 9)         0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 56, 56, 45)        450       \n_________________________________________________________________\ndepthwise_conv2d_4 (Depthwis (None, 28, 28, 45)        450       \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 28, 28, 11)        506       \n_________________________________________________________________\nactivation_6 (Activation)    (None, 28, 28, 11)        0         \n_________________________________________________________________\nactivation_7 (Activation)    (None, 28, 28, 11)        0         \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 28, 28, 55)        660       \n_________________________________________________________________\ndepthwise_conv2d_5 (Depthwis (None, 28, 28, 55)        550       \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 28, 28, 11)        616       \n_________________________________________________________________\nactivation_8 (Activation)    (None, 28, 28, 11)        0         \n_________________________________________________________________\nactivation_9 (Activation)    (None, 28, 28, 11)        0         \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 28, 28, 66)        792       \n_________________________________________________________________\ndepthwise_conv2d_6 (Depthwis (None, 14, 14, 66)        1716      \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, 14, 14, 13)        871       \n_________________________________________________________________\nactivation_10 (Activation)   (None, 14, 14, 13)        0         \n_________________________________________________________________\nactivation_11 (Activation)   (None, 14, 14, 13)        0         \n_________________________________________________________________\nconv2d_13 (Conv2D)           (None, 14, 14, 78)        1092      \n_________________________________________________________________\ndepthwise_conv2d_7 (Depthwis (None, 14, 14, 78)        3900      \n_________________________________________________________________\nconv2d_14 (Conv2D)           (None, 14, 14, 13)        1027      \n_________________________________________________________________\nactivation_12 (Activation)   (None, 14, 14, 13)        0         \n_________________________________________________________________\nactivation_13 (Activation)   (None, 14, 14, 13)        0         \n_________________________________________________________________\nconv2d_15 (Conv2D)           (None, 14, 14, 78)        1092      \n_________________________________________________________________\ndepthwise_conv2d_8 (Depthwis (None, 14, 14, 78)        3900      \n_________________________________________________________________\nconv2d_16 (Conv2D)           (None, 14, 14, 13)        1027      \n_________________________________________________________________\nactivation_14 (Activation)   (None, 14, 14, 13)        0         \n_________________________________________________________________\nactivation_15 (Activation)   (None, 14, 14, 13)        0         \n_________________________________________________________________\nconv2d_17 (Conv2D)           (None, 14, 14, 78)        1092      \n_________________________________________________________________\ndepthwise_conv2d_9 (Depthwis (None, 14, 14, 78)        780       \n_________________________________________________________________\nconv2d_18 (Conv2D)           (None, 14, 14, 13)        1027      \n_________________________________________________________________\nactivation_16 (Activation)   (None, 14, 14, 13)        0         \n_________________________________________________________________\nactivation_17 (Activation)   (None, 14, 14, 13)        0         \n_________________________________________________________________\nconv2d_19 (Conv2D)           (None, 14, 14, 39)        546       \n_________________________________________________________________\ndepthwise_conv2d_10 (Depthwi (None, 7, 7, 39)          390       \n_________________________________________________________________\nconv2d_20 (Conv2D)           (None, 7, 7, 30)          1200      \n_________________________________________________________________\nactivation_18 (Activation)   (None, 7, 7, 30)          0         \n_________________________________________________________________\nactivation_19 (Activation)   (None, 7, 7, 30)          0         \n_________________________________________________________________\nconv2d_21 (Conv2D)           (None, 7, 7, 90)          2790      \n_________________________________________________________________\ndepthwise_conv2d_11 (Depthwi (None, 7, 7, 90)          900       \n_________________________________________________________________\nconv2d_22 (Conv2D)           (None, 7, 7, 30)          2730      \n_________________________________________________________________\nactivation_20 (Activation)   (None, 7, 7, 30)          0         \n_________________________________________________________________\nactivation_21 (Activation)   (None, 7, 7, 30)          0         \n_________________________________________________________________\nconv2d_23 (Conv2D)           (None, 7, 7, 90)          2790      \n_________________________________________________________________\ndepthwise_conv2d_12 (Depthwi (None, 7, 7, 90)          900       \n_________________________________________________________________\nconv2d_24 (Conv2D)           (None, 7, 7, 29)          2639      \n_________________________________________________________________\nactivation_22 (Activation)   (None, 7, 7, 29)          0         \n_________________________________________________________________\nconv2d_25 (Conv2D)           (None, 7, 7, 1079)        32370     \n_________________________________________________________________\nglobal_average_pooling2d_1 ( (None, 1079)              0         \n_________________________________________________________________\nreshape_1 (Reshape)          (None, 1, 1, 1079)        0         \n_________________________________________________________________\nDropout (Dropout)            (None, 1, 1, 1079)        0         \n_________________________________________________________________\nconv2d_26 (Conv2D)           (None, 1, 1, 1000)        1080000   \n_________________________________________________________________\nreshape_2 (Reshape)          (None, 1000)              0         \n=================================================================\nTotal params: 1,164,580\nTrainable params: 1,164,580\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dropout\n",
    "from keras.layers import Activation, BatchNormalization, Add, Reshape, DepthwiseConv2D\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from keras import backend as K\n",
    "def relu6(x):\n",
    "    return K.relu(x, max_value=6.0)\n",
    "\n",
    "def _conv_block(inputs, filters, kernel, strides):\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "    x = Conv2D(filters, kernel, padding='same', strides=strides)(inputs)\n",
    "    return x\n",
    "\n",
    "def _bottleneck(inputs, filters, kernel, t, alpha, s, r=False):\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "    tchannel = K.int_shape(inputs)[channel_axis] * t\n",
    "    cchannel = int(filters * alpha)\n",
    "    x = _conv_block(inputs, tchannel, (1, 1), (1, 1))\n",
    "    x = DepthwiseConv2D(kernel, strides=(s, s), depth_multiplier=1, padding='same')(x)\n",
    "    x = Conv2D(cchannel, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "    if r:\n",
    "        x = Add()([x, inputs])\n",
    "    return x\n",
    "\n",
    "def _inverted_residual_block(inputs, filters, kernel, t, alpha, strides, n):\n",
    "    x=Activation(relu6)(inputs)\n",
    "    x = _bottleneck(x, filters, kernel, t, alpha, strides)\n",
    "    for i in range(1, n):\n",
    "        x = _bottleneck(x, filters, kernel, t, alpha, 1, True)\n",
    "    x=Activation(relu6)(x)\n",
    "    return x\n",
    "\n",
    "def Net1(input_shape, k, alpha=1.0):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x= Conv2D(35, 3, padding='same', strides=(2,2))(inputs)\n",
    "    x = DepthwiseConv2D((3,3),  activation='relu', padding='same')(x)\n",
    "    x= Conv2D(34, 1, padding='same', strides=(1,1))(x)\n",
    "\n",
    "    x = _inverted_residual_block(x, 9, (5, 5), t=5, alpha=alpha, strides=2, n=1)\n",
    "    x = _inverted_residual_block(x, 9, (3, 3), t=5, alpha=alpha, strides=1, n=1)\n",
    "    x = _inverted_residual_block(x, 11, (3, 3), t=5, alpha=alpha, strides=2, n=1)\n",
    "    x = _inverted_residual_block(x, 11, (3, 3), t=5, alpha=alpha, strides=1, n=1)\n",
    "\n",
    "    x = _inverted_residual_block(x, 13, (5, 5), t=6, alpha=alpha, strides=2, n=1)\n",
    "    x = _inverted_residual_block(x, 13, (7, 7), t=6, alpha=alpha, strides=1, n=1)\n",
    "    x = _inverted_residual_block(x, 13, (7, 7), t=6, alpha=alpha, strides=1, n=1)\n",
    "    x = _inverted_residual_block(x, 13, (3, 3), t=6, alpha=alpha, strides=1, n=1)\n",
    "\n",
    "    x = _inverted_residual_block(x, 30, (3, 3), t=3, alpha=alpha, strides=2, n=1)\n",
    "    x = _inverted_residual_block(x, 30, (3, 3), t=3, alpha=alpha, strides=1, n=1)\n",
    "    x = _inverted_residual_block(x, 29, (3, 3), t=3, alpha=alpha, strides=1, n=1)\n",
    "    last_filters = 1079\n",
    "\n",
    "    x = _conv_block(x, last_filters, (1, 1), strides=(1, 1))\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    x = Reshape((1, 1, last_filters))(x)\n",
    "    x = Dropout(0.3, name='Dropout')(x)\n",
    "    #!!!!!!!!!\n",
    "    x = Conv2D(k, (1, 1), padding='same')(x)\n",
    "    #!!!!!!!!!\n",
    "    output = Reshape((k,))(x)\n",
    "    model = Model(inputs, output)\n",
    "    # plot_model(model, to_file='images/MobileNetv2.png', show_shapes=True)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model_1 = Net1((224, 224, 3), 1000, 1.0)\n",
    "    print(model_1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model total param = Total params: 1,164,580"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1164580"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "sum(NN_00001['weights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the final representation of the NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          FLOPS  weights  tensor_in  tensor_out  hidden_dim  k2  skip\n0    23708160.0      980   150528.0    439040.0           3   9     0\n1     7902720.0      350   439040.0    439040.0          35   9     0\n2    29854720.0     1224   439040.0    426496.0          35   1     0\n3   181260800.0    11909   426496.0     28224.0         170  25     0\n4     7620480.0     1314    28224.0     28224.0          45   9     0\n5     3951360.0     1406    28224.0      8624.0          45   9     0\n6     2673440.0     1826     8624.0      8624.0          55   9     0\n7     2121504.0     3379     8624.0      2548.0          66  25     0\n8     2293200.0     6019     2548.0      2548.0          78  49     0\n9     2293200.0     6019     2548.0      2548.0          78  49     0\n10    1070160.0     2899     2548.0      2548.0          78   9     0\n11     347802.0     2136     2548.0      1470.0          39   9     0\n12     610050.0     6420     1470.0      1470.0          90   9     1\n13     599760.0     6329     1470.0      1421.0          90   9     0\n14    3066518.0    32370     1421.0     52871.0          29   1     0\n15  105742000.0  1080000    52871.0     49000.0        1079   1     0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FLOPS</th>\n      <th>weights</th>\n      <th>tensor_in</th>\n      <th>tensor_out</th>\n      <th>hidden_dim</th>\n      <th>k2</th>\n      <th>skip</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>23708160.0</td>\n      <td>980</td>\n      <td>150528.0</td>\n      <td>439040.0</td>\n      <td>3</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7902720.0</td>\n      <td>350</td>\n      <td>439040.0</td>\n      <td>439040.0</td>\n      <td>35</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>29854720.0</td>\n      <td>1224</td>\n      <td>439040.0</td>\n      <td>426496.0</td>\n      <td>35</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>181260800.0</td>\n      <td>11909</td>\n      <td>426496.0</td>\n      <td>28224.0</td>\n      <td>170</td>\n      <td>25</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7620480.0</td>\n      <td>1314</td>\n      <td>28224.0</td>\n      <td>28224.0</td>\n      <td>45</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3951360.0</td>\n      <td>1406</td>\n      <td>28224.0</td>\n      <td>8624.0</td>\n      <td>45</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2673440.0</td>\n      <td>1826</td>\n      <td>8624.0</td>\n      <td>8624.0</td>\n      <td>55</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2121504.0</td>\n      <td>3379</td>\n      <td>8624.0</td>\n      <td>2548.0</td>\n      <td>66</td>\n      <td>25</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2293200.0</td>\n      <td>6019</td>\n      <td>2548.0</td>\n      <td>2548.0</td>\n      <td>78</td>\n      <td>49</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2293200.0</td>\n      <td>6019</td>\n      <td>2548.0</td>\n      <td>2548.0</td>\n      <td>78</td>\n      <td>49</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1070160.0</td>\n      <td>2899</td>\n      <td>2548.0</td>\n      <td>2548.0</td>\n      <td>78</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>347802.0</td>\n      <td>2136</td>\n      <td>2548.0</td>\n      <td>1470.0</td>\n      <td>39</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>610050.0</td>\n      <td>6420</td>\n      <td>1470.0</td>\n      <td>1470.0</td>\n      <td>90</td>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>599760.0</td>\n      <td>6329</td>\n      <td>1470.0</td>\n      <td>1421.0</td>\n      <td>90</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>3066518.0</td>\n      <td>32370</td>\n      <td>1421.0</td>\n      <td>52871.0</td>\n      <td>29</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>105742000.0</td>\n      <td>1080000</td>\n      <td>52871.0</td>\n      <td>49000.0</td>\n      <td>1079</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "\n",
    "def no_relu(NN_frame):  \n",
    "    NN_frame['convtype']= NN_frame['convtype'].apply(lambda x : 'conv' if x=='conv_norelu' else x)\n",
    "\n",
    "\n",
    "def NN_to_dataframe(NN_list, columns_names, conv_types, values_to_keep,separate_types):\n",
    "    NN_frame = pd.DataFrame(NN_list, columns = columns_names+ ['convtype',])\n",
    "    no_relu(NN_frame)\n",
    "    return treat_NN(NN_frame, values_to_keep,separate_types)\n",
    "\n",
    "    #NN_distinct_contypes = distinct_contypes(NN_frame, columns_names, conv_types)\n",
    "    #return NN_frame\n",
    "    #return NN_distinct_contypes\n",
    "\n",
    "\n",
    "NN_df = NN_to_dataframe(NN, columns_names, conv_types,values_to_keep,separate_types)\n",
    "NN_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[[1, 35, 2, 3, 0, 'conv'],\n [1, 35, 1, 3, 0, 'dw'],\n [1, 34, 1, 1, 0, 'conv_norelu'],\n [5, 9, 2, 5, 0, 'inv'],\n [5, 9, 1, 3, 0, 'inv'],\n [5, 11, 2, 3, 0, 'inv'],\n [5, 11, 1, 3, 0, 'inv'],\n [6, 13, 2, 5, 0, 'inv'],\n [6, 13, 1, 7, 0, 'inv'],\n [6, 13, 1, 7, 0, 'inv'],\n [6, 13, 1, 3, 0, 'inv'],\n [3, 30, 2, 3, 0, 'inv'],\n [3, 30, 1, 3, 1, 'inv'],\n [3, 29, 1, 3, 0, 'inv'],\n [1, 1079, 1, 1, 0, 'conv']]"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add HW params to NN_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ['mac_num','mac_array_num','data_bits','sram_size','max_filter_size']\n",
    "\n",
    "def add_HW_param_column(df,mac_num, mac_array_num, data_bits, sram_size, max_filter_size):\n",
    "    df['mac_num']=mac_num\n",
    "    df['mac_array_num']=mac_array_num\n",
    "    df['total_macs']=  mac_num * mac_array_num\n",
    "    df['data_bits']=data_bits\n",
    "    df['sram_size']=sram_size\n",
    "    df['max_filter_size']=max_filter_size\n",
    "\n",
    "\n",
    "def add_HW_param_line(NN_frame, mac_num, mac_array_num, data_bits, sram_size, max_filter_size):\n",
    "    HW_param_line =pd.DataFrame([[mac_num]*(NN_frame.shape[1])], columns=NN_frame.columns)\n",
    "    HW_param_line = HW_param_line.append(pd.DataFrame([[mac_array_num]*(NN_frame.shape[1])], columns=NN_frame.columns))\n",
    "    HW_param_line = HW_param_line.append(pd.DataFrame([[mac_num*mac_array_num]*(NN_frame.shape[1])], columns=NN_frame.columns))\n",
    "    HW_param_line =HW_param_line.append(pd.DataFrame([[data_bits]*(NN_frame.shape[1])], columns=NN_frame.columns))\n",
    "    HW_param_line =HW_param_line.append(pd.DataFrame([[sram_size]*(NN_frame.shape[1])], columns=NN_frame.columns))\n",
    "    HW_param_line =HW_param_line.append(pd.DataFrame([[max_filter_size]*(NN_frame.shape[1])], columns=NN_frame.columns))\n",
    "    return HW_param_line.append(NN_frame)\n",
    "\n",
    "\n",
    "#not_used\n",
    "def extend_to_max_blocks(NN_frame, value):\n",
    "    for i in range (max_blocks-len(NN_frame)):\n",
    "        NN_frame=NN_frame.append(pd.DataFrame([[0]*(NN_frame.shape[1])], index=[i+len(NN_frame),] ,columns=NN_frame.columns))\n",
    "    return NN_frame\n",
    "\n",
    "#not_used\n",
    "def add_zero_blocks(arr):\n",
    "    zero_blocks = np.zeros(( max_blocks-arr.shape[0],arr.shape[1]))\n",
    "    return np.append(arr, zero_blocks, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "UsageError: Line magic function `%pycache` not found.\n"
    }
   ],
   "source": [
    "%pycache\n",
    "train_hw= train_hw[:3]\n",
    "val_hw = val_hw[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 35410/35410 [18:39<00:00, 31.62it/s]\n100%|██████████| 35410/35410 [00:02<00:00, 14176.43it/s]\n100%|██████████| 4451/4451 [02:21<00:00, 31.47it/s]\n100%|██████████| 4451/4451 [00:00<00:00, 14492.38it/s]\n"
    }
   ],
   "source": [
    "#%pycache\n",
    "values_to_keep = ['FLOPS','weights','tensor_in','tensor_out','hidden_dim','k2', 'skip']\n",
    "separate_types = False\n",
    "# if separate_types:\n",
    "#     values_to_keep = [f'{value}_{type}' for type in conv_types for value in values_to_keep]\n",
    "\n",
    "name = 'from_1600'\n",
    "\n",
    "\n",
    "# Convert NN to dataframe with values of interest\n",
    "train_hw[\"NN_dataframe\"] = train_hw[\"NN\"].progress_apply(lambda x : NN_to_dataframe(x,columns_names, conv_types, values_to_keep,separate_types))\n",
    "#train_hw.progress_apply(lambda x : add_HW_param_column(x.NN_dataframe,x.mac_num,x.mac_array_num, x.data_bits, x.sram_size, x.max_filter_size), axis=1)\n",
    "train_hw['NN_dataframe']=train_hw['NN_dataframe'].progress_apply(lambda x : np.array(x))\n",
    "#complete to zero#complete to zero\n",
    "#train_hw['NN_dataframe']= train['NN_dataframe'].progress_apply(lambda x : add_zero_blocks(x))#complete to zero#complete to zero\n",
    "train_hw['NN_dataframe'].to_csv(f'train_{name}.csv')\n",
    "\n",
    "\n",
    "#####################################\n",
    "\n",
    "val_hw[\"NN_dataframe\"] = val_hw[\"NN\"].progress_apply(lambda x : NN_to_dataframe(x,columns_names, conv_types, values_to_keep,separate_types))\n",
    "#val_hw.progress_apply(lambda x : add_HW_param_column(x.NN_dataframe,x.mac_num,x.mac_array_num, x.data_bits, x.sram_size, x.max_filter_size), axis=1)\n",
    "val_hw['NN_dataframe']=val_hw['NN_dataframe'].progress_apply(lambda x : np.array(x))\n",
    "\n",
    "#complete to zero#complete to zero\n",
    "#val['NN_dataframe']= val['NN_dataframe'].progress_apply(lambda x : add_zero_blocks(x))#complete to zero#complete to zero\n",
    "val_hw.to_csv(f'val_{name}.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Load to verify everythinng is fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "UsageError: Line magic function `%pycache` not found.\n"
    }
   ],
   "source": [
    "%pycache\n",
    "import ast\n",
    "\n",
    "\n",
    "path_processed_val_nn=\"/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/DataForHASpredictor/val_low_power.csv\"\n",
    "\n",
    "def from_np_array(array_string):\n",
    "    array_string = ','.join(array_string.replace('[ ', '[').split())\n",
    "    return np.asarray(ast.literal_eval(array_string))\n",
    "\n",
    "val = pd.read_csv(path_processed_val_nn,converters={'NN_dataframe': from_np_array})\n",
    "\n",
    "X_train_nn =np.array(val['NN_dataframe'].tolist())\n",
    "#train = pd.read_csv(path_processed_train_nn,converters={'NN_dataframe': from_np_array})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "              0         1         2         3      4     5    6\n0    16257024.0     672.0  150528.0  301056.0    3.0   9.0  0.0\n1     5419008.0     240.0  301056.0  301056.0   24.0   9.0  0.0\n2    21676032.0     900.0  301056.0  451584.0   24.0   1.0  0.0\n3   158054400.0    9958.0  451584.0   68992.0  144.0   9.0  0.0\n4    29252608.0    4862.0   68992.0   68992.0   88.0   9.0  0.0\n5    94657024.0   15427.0   68992.0   84672.0  154.0  49.0  0.0\n6    80269056.0   13149.0   84672.0   84672.0  162.0  25.0  0.0\n7    42674688.0    7047.0   84672.0   84672.0  108.0   9.0  0.0\n8    53597376.0    8775.0   84672.0   84672.0  108.0  25.0  1.0\n9   104654592.0   17037.0   84672.0   84672.0  162.0  49.0  0.0\n10   21422016.0    3537.0   84672.0   84672.0   54.0   9.0  1.0\n11   40007520.0   14882.0   84672.0   25088.0  135.0  49.0  0.0\n12   25037824.0   16467.0   25088.0  391216.0   32.0   1.0  0.0\n13  782432000.0  500000.0  391216.0  784000.0  499.0   1.0  0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>16257024.0</td>\n      <td>672.0</td>\n      <td>150528.0</td>\n      <td>301056.0</td>\n      <td>3.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5419008.0</td>\n      <td>240.0</td>\n      <td>301056.0</td>\n      <td>301056.0</td>\n      <td>24.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21676032.0</td>\n      <td>900.0</td>\n      <td>301056.0</td>\n      <td>451584.0</td>\n      <td>24.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>158054400.0</td>\n      <td>9958.0</td>\n      <td>451584.0</td>\n      <td>68992.0</td>\n      <td>144.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>29252608.0</td>\n      <td>4862.0</td>\n      <td>68992.0</td>\n      <td>68992.0</td>\n      <td>88.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>94657024.0</td>\n      <td>15427.0</td>\n      <td>68992.0</td>\n      <td>84672.0</td>\n      <td>154.0</td>\n      <td>49.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>80269056.0</td>\n      <td>13149.0</td>\n      <td>84672.0</td>\n      <td>84672.0</td>\n      <td>162.0</td>\n      <td>25.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>42674688.0</td>\n      <td>7047.0</td>\n      <td>84672.0</td>\n      <td>84672.0</td>\n      <td>108.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>53597376.0</td>\n      <td>8775.0</td>\n      <td>84672.0</td>\n      <td>84672.0</td>\n      <td>108.0</td>\n      <td>25.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>104654592.0</td>\n      <td>17037.0</td>\n      <td>84672.0</td>\n      <td>84672.0</td>\n      <td>162.0</td>\n      <td>49.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>21422016.0</td>\n      <td>3537.0</td>\n      <td>84672.0</td>\n      <td>84672.0</td>\n      <td>54.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>40007520.0</td>\n      <td>14882.0</td>\n      <td>84672.0</td>\n      <td>25088.0</td>\n      <td>135.0</td>\n      <td>49.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>25037824.0</td>\n      <td>16467.0</td>\n      <td>25088.0</td>\n      <td>391216.0</td>\n      <td>32.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>782432000.0</td>\n      <td>500000.0</td>\n      <td>391216.0</td>\n      <td>784000.0</td>\n      <td>499.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "pd.DataFrame(val['NN_dataframe'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas\n",
    "import pandas as pd\n",
    "os.chdir(\"/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data\")\n",
    "extension = 'csv'\n",
    "\n",
    "trains = [\"/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/data_180035train/parsed_nondups_train_2.csv\", \"/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/DataForHASpredictor2/new_parsed_train.csv\"]\n",
    "\n",
    "vals = [\"/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/data_180035train/parsed_nondups_val_2.csv\", \"/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/DataForHASpredictor2/new_parsed_val.csv\"]\n",
    "#all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "\n",
    "\n",
    "#combine all files in the list\n",
    "#train_csv = pd.concat([pd.read_csv(f) for f in trains])\n",
    "#val_csv = pd.concat([pd.read_csv(f) for f in vals])\n",
    "\n",
    "train_l = []\n",
    "for f in trains:\n",
    "    panda = pd.read_csv(f)\n",
    "    panda = panda[panda.C != 'C']\n",
    "    panda = panda.astype(float)\n",
    "    train_l.append(panda)\n",
    "train_csv = pd.concat(train_l)\n",
    "\n",
    "\n",
    "\n",
    "val_l = []\n",
    "for f in vals:\n",
    "    panda = pd.read_csv(f)\n",
    "    panda = panda[panda.C != 'C']\n",
    "    panda = panda.astype(float)\n",
    "    val_l.append(panda)\n",
    "val_csv = pd.concat(val_l)\n",
    "\n",
    "\n",
    "\n",
    "#train_hw = train_hw[train_hw.C != 'C']\n",
    "#export to csv\n",
    "train_csv.to_csv( \"parsed_nondups_train_3.csv\", index=False, encoding='utf-8-sig')\n",
    "val_csv.to_csv( \"parsed_nondups_val_3.csv\", index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Éditer les Méta-Données",
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('has': conda)",
   "language": "python",
   "name": "python361064bithascondabd8f1537e5d34ba799ef15b8707e6526"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}