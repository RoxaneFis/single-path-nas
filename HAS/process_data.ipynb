{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nets = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/all_nets.json'\n",
    "\n",
    "parsed_nondups_val1 = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_val1_fix.txt'\n",
    "parsed_nondups_train1 = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_train1_fix.txt'\n",
    "\n",
    "parsed_nondups_val1_csv = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_val1.csv'\n",
    "parsed_nondups_train1_csv = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_train1.csv'\n",
    "\n",
    "# parsed_nondups_val2 = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_val2.txt'\n",
    "# parsed_nondups_train2 = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_train2.txt'\n",
    "\n",
    "# parsed_nondups_val2_csv = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_val2.csv'\n",
    "# parsed_nondups_train2_csv = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_train2.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "UsageError: Line magic function `%pycache` not found.\n"
    }
   ],
   "source": [
    "%pycache\n",
    "number = 2\n",
    "\n",
    "with open(parsed_nondups_val2, 'r') as in_file:\n",
    "    stripped = (line.strip() for line in in_file)\n",
    "    lines = (line.split(\",\") for line in stripped if line)\n",
    "    with open(f'parsed_nondups_val{number}.csv', 'w') as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        writer.writerows(lines)\n",
    "\n",
    "with open(parsed_nondups_train2, 'r') as in_file:\n",
    "    stripped = (line.strip() for line in in_file)\n",
    "    lines = (line.split(\",\") for line in stripped if line)\n",
    "    with open(f'parsed_nondups_train{number}.csv', 'w') as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        writer.writerows(lines)\n",
    "\n",
    "# train_hw = pd.read_csv(parsed_nondups_train1_csv)\n",
    "# val_hw = pd.read_csv(parsed_nondups_val1_csv)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hw = pd.read_csv(parsed_nondups_train1_csv)\n",
    "val_hw = pd.read_csv(parsed_nondups_val1_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks Dictionnary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(all_nets, 'r') as f:\n",
    "    nets_dict = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max block size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_blocks = 0\n",
    "for k,nn in nets_dict.items():\n",
    "    if len(nn)>max_blocks:\n",
    "        max_blocks=len(nn)\n",
    "\n",
    "max_blocks = max_blocks +1 # add fc layer at the end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "37"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "max_blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General information \n",
    "\n",
    "nets_dict_keys :0000 to 00531 (532)\n",
    "\n",
    "Train : 453 different NN\n",
    "\n",
    "Val : 50 different NN\n",
    "\n",
    "\n",
    "# Size dataset\n",
    "\n",
    "#### Train 1: 137,090\n",
    "#### Val 1: 13,804\n",
    "#### Train 2: 14,532\n",
    "#### Val 2: 2,882"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_NN_name(x):\n",
    "    x=str(x)\n",
    "    while len(str(x))<5 :\n",
    "        x = '0'+str(x)\n",
    "    return x\n",
    "\n",
    "train_hw['name']=train_hw['name'].apply(lambda x : convert_NN_name(x))\n",
    "val_hw['name']=val_hw['name'].apply(lambda x : convert_NN_name(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   mac_num  mac_array_num  data_bits  sram_size  max_filter_size  \\\n0    118.0            2.0      256.0   179968.0           2048.0   \n1     87.0            2.0      512.0    99968.0           2048.0   \n2    124.0            2.0      512.0    99968.0           3072.0   \n3     80.0            2.0     1024.0    99968.0           1024.0   \n4     86.0            2.0      512.0    60000.0           1536.0   \n\n              G           C           B         J   name    bw_power  \\\n0  3.636011e+06  18770712.0  19987780.0  0.000533  00000   79.951120   \n1  2.325259e+06  14362735.0  21849702.0  0.000570  00000   87.398808   \n2  2.533459e+06  12739050.0  21849702.0  0.000543  00000   87.398808   \n3  2.327509e+06  12155422.0  21849702.0  0.000684  00000   87.398808   \n4  1.728057e+06  16407889.0  28402776.0  0.000604  00000  113.611104   \n\n   core_power  total_power  \n0   21.330414   101.281534  \n1   22.816285   110.215093  \n2   21.716202   109.115010  \n3   27.343500   114.742308  \n4   24.174307   137.785411  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mac_num</th>\n      <th>mac_array_num</th>\n      <th>data_bits</th>\n      <th>sram_size</th>\n      <th>max_filter_size</th>\n      <th>G</th>\n      <th>C</th>\n      <th>B</th>\n      <th>J</th>\n      <th>name</th>\n      <th>bw_power</th>\n      <th>core_power</th>\n      <th>total_power</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>118.0</td>\n      <td>2.0</td>\n      <td>256.0</td>\n      <td>179968.0</td>\n      <td>2048.0</td>\n      <td>3.636011e+06</td>\n      <td>18770712.0</td>\n      <td>19987780.0</td>\n      <td>0.000533</td>\n      <td>00000</td>\n      <td>79.951120</td>\n      <td>21.330414</td>\n      <td>101.281534</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>87.0</td>\n      <td>2.0</td>\n      <td>512.0</td>\n      <td>99968.0</td>\n      <td>2048.0</td>\n      <td>2.325259e+06</td>\n      <td>14362735.0</td>\n      <td>21849702.0</td>\n      <td>0.000570</td>\n      <td>00000</td>\n      <td>87.398808</td>\n      <td>22.816285</td>\n      <td>110.215093</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>124.0</td>\n      <td>2.0</td>\n      <td>512.0</td>\n      <td>99968.0</td>\n      <td>3072.0</td>\n      <td>2.533459e+06</td>\n      <td>12739050.0</td>\n      <td>21849702.0</td>\n      <td>0.000543</td>\n      <td>00000</td>\n      <td>87.398808</td>\n      <td>21.716202</td>\n      <td>109.115010</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>80.0</td>\n      <td>2.0</td>\n      <td>1024.0</td>\n      <td>99968.0</td>\n      <td>1024.0</td>\n      <td>2.327509e+06</td>\n      <td>12155422.0</td>\n      <td>21849702.0</td>\n      <td>0.000684</td>\n      <td>00000</td>\n      <td>87.398808</td>\n      <td>27.343500</td>\n      <td>114.742308</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>86.0</td>\n      <td>2.0</td>\n      <td>512.0</td>\n      <td>60000.0</td>\n      <td>1536.0</td>\n      <td>1.728057e+06</td>\n      <td>16407889.0</td>\n      <td>28402776.0</td>\n      <td>0.000604</td>\n      <td>00000</td>\n      <td>113.611104</td>\n      <td>24.174307</td>\n      <td>137.785411</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "train_hw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add neural network to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hw[\"NN\"]=train_hw['name'].map(nets_dict)\n",
    "val_hw[\"NN\"]=val_hw['name'].map(nets_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   mac_num  mac_array_num  data_bits  sram_size  max_filter_size  \\\n0    118.0            2.0      256.0   179968.0           2048.0   \n1     87.0            2.0      512.0    99968.0           2048.0   \n2    124.0            2.0      512.0    99968.0           3072.0   \n3     80.0            2.0     1024.0    99968.0           1024.0   \n4     86.0            2.0      512.0    60000.0           1536.0   \n\n              G           C           B         J   name    bw_power  \\\n0  3.636011e+06  18770712.0  19987780.0  0.000533  00000   79.951120   \n1  2.325259e+06  14362735.0  21849702.0  0.000570  00000   87.398808   \n2  2.533459e+06  12739050.0  21849702.0  0.000543  00000   87.398808   \n3  2.327509e+06  12155422.0  21849702.0  0.000684  00000   87.398808   \n4  1.728057e+06  16407889.0  28402776.0  0.000604  00000  113.611104   \n\n   core_power  total_power                                                 NN  \n0   21.330414   101.281534  [[1, 9, 2, 3, 0, conv], [1, 9, 1, 3, 0, dw], [...  \n1   22.816285   110.215093  [[1, 9, 2, 3, 0, conv], [1, 9, 1, 3, 0, dw], [...  \n2   21.716202   109.115010  [[1, 9, 2, 3, 0, conv], [1, 9, 1, 3, 0, dw], [...  \n3   27.343500   114.742308  [[1, 9, 2, 3, 0, conv], [1, 9, 1, 3, 0, dw], [...  \n4   24.174307   137.785411  [[1, 9, 2, 3, 0, conv], [1, 9, 1, 3, 0, dw], [...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mac_num</th>\n      <th>mac_array_num</th>\n      <th>data_bits</th>\n      <th>sram_size</th>\n      <th>max_filter_size</th>\n      <th>G</th>\n      <th>C</th>\n      <th>B</th>\n      <th>J</th>\n      <th>name</th>\n      <th>bw_power</th>\n      <th>core_power</th>\n      <th>total_power</th>\n      <th>NN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>118.0</td>\n      <td>2.0</td>\n      <td>256.0</td>\n      <td>179968.0</td>\n      <td>2048.0</td>\n      <td>3.636011e+06</td>\n      <td>18770712.0</td>\n      <td>19987780.0</td>\n      <td>0.000533</td>\n      <td>00000</td>\n      <td>79.951120</td>\n      <td>21.330414</td>\n      <td>101.281534</td>\n      <td>[[1, 9, 2, 3, 0, conv], [1, 9, 1, 3, 0, dw], [...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>87.0</td>\n      <td>2.0</td>\n      <td>512.0</td>\n      <td>99968.0</td>\n      <td>2048.0</td>\n      <td>2.325259e+06</td>\n      <td>14362735.0</td>\n      <td>21849702.0</td>\n      <td>0.000570</td>\n      <td>00000</td>\n      <td>87.398808</td>\n      <td>22.816285</td>\n      <td>110.215093</td>\n      <td>[[1, 9, 2, 3, 0, conv], [1, 9, 1, 3, 0, dw], [...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>124.0</td>\n      <td>2.0</td>\n      <td>512.0</td>\n      <td>99968.0</td>\n      <td>3072.0</td>\n      <td>2.533459e+06</td>\n      <td>12739050.0</td>\n      <td>21849702.0</td>\n      <td>0.000543</td>\n      <td>00000</td>\n      <td>87.398808</td>\n      <td>21.716202</td>\n      <td>109.115010</td>\n      <td>[[1, 9, 2, 3, 0, conv], [1, 9, 1, 3, 0, dw], [...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>80.0</td>\n      <td>2.0</td>\n      <td>1024.0</td>\n      <td>99968.0</td>\n      <td>1024.0</td>\n      <td>2.327509e+06</td>\n      <td>12155422.0</td>\n      <td>21849702.0</td>\n      <td>0.000684</td>\n      <td>00000</td>\n      <td>87.398808</td>\n      <td>27.343500</td>\n      <td>114.742308</td>\n      <td>[[1, 9, 2, 3, 0, conv], [1, 9, 1, 3, 0, dw], [...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>86.0</td>\n      <td>2.0</td>\n      <td>512.0</td>\n      <td>60000.0</td>\n      <td>1536.0</td>\n      <td>1.728057e+06</td>\n      <td>16407889.0</td>\n      <td>28402776.0</td>\n      <td>0.000604</td>\n      <td>00000</td>\n      <td>113.611104</td>\n      <td>24.174307</td>\n      <td>137.785411</td>\n      <td>[[1, 9, 2, 3, 0, conv], [1, 9, 1, 3, 0, dw], [...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "train_hw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treat NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME DIDNT COUNT ACTIVATION\n",
    "\n",
    "def conv_flops(hout,cin,cout,k,tensor_in,skip=0):\n",
    "    flops = 2*k*k*cin*hout*hout*cout\n",
    "    if skip ==1:\n",
    "        flops += tensor_in\n",
    "    return flops\n",
    "\n",
    "def dw_flops(hout,c,k,tensor_in,skip=0, mult=1):\n",
    "    flops = 2*k*k*c*hout*hout\n",
    "    if skip == 1:\n",
    "        flops +=tensor_in\n",
    "    return flops\n",
    "\n",
    "def fcc_flops(i, j):\n",
    "    return (2*i-1)*j\n",
    "\n",
    "def calculate_flop(convtype,hin,hout,cin,cout,k,exp,tensor_in, skip=0, mult=1):\n",
    "    if convtype=='conv':\n",
    "        return conv_flops(hout,cin,cout,k, tensor_in, skip)\n",
    "    elif convtype=='dw':\n",
    "        return dw_flops(hout,cin,k,tensor_in,skip)\n",
    "    elif convtype=='inv':\n",
    "        hout_pointwise = hin\n",
    "        return conv_flops(hout=hout_pointwise, cin=cin,cout=cin*exp,k=1, tensor_in=tensor_in, skip=skip) + \\\n",
    "        dw_flops(hout=hout,c=cin*exp,k=k,tensor_in=0,skip=0) + \\\n",
    "        conv_flops(hout=hout,cin=cin*exp,cout=cout,k=1, tensor_in=0, skip=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Calculate weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_weights(cin,cout,k):\n",
    "    return (k*k*cin+1)*cout\n",
    "\n",
    "def dw_weights(cin,k,mult=1):\n",
    "    #dw = equi cin=1 and multiply by cout\n",
    "    #return conv_flops(hout,1,cin,k)*mult\n",
    "    return (k*k+1)*cin\n",
    "\n",
    "def fcc_weight(i, j):\n",
    "    return\n",
    "    #return (2*i-1)*j\n",
    "\n",
    "def calculate_weights(convtype,cin,cout,k,exp,mult=1):\n",
    "    if convtype=='conv':\n",
    "        return conv_weights(cin,cout,k)\n",
    "    elif convtype=='dw':\n",
    "        return dw_weights(cin,k)\n",
    "    elif convtype=='inv':\n",
    "        return conv_weights(cin, cin*exp, 1)+ dw_weights(cin*exp,k,mult) + conv_weights(cin*exp,cout,1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distinguish columns between convtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def distinct_contypes(NN_frame, columns_names, conv_types):\n",
    "    columns_names_augmented = [ f'{name}_{conv_type}' for conv_type in conv_types for name in columns_names]\n",
    "    NN_frame_processed= pd.DataFrame(None, index=np.arange(len(NN)+1), columns=columns_names_augmented)\n",
    "\n",
    "    ### Len(NN)+1  beceause +1 FC layer at the end\n",
    "    for conv_type in conv_types:\n",
    "        columns_conv_type = [f'{columns_name}_{conv_type}' for columns_name in columns_names]\n",
    "        NN_frame_processed[columns_conv_type] = NN_frame.loc[NN_frame['convtype']==conv_type, columns_names]\n",
    "    return NN_frame_processed.fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treat the neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nb_classes= 1000\n",
    "\n",
    "\n",
    "# def no_relu(NN_frame):  \n",
    "#     NN_frame['convtype']= NN_frame['convtype'].apply(lambda x : 'conv' if x=='conv_norelu' else x)\n",
    "\n",
    "def treat_NN(NN_frame, values_to_keep, separate_types):\n",
    "    fc_block = {'exp':1, 'c_out':1000, 's':1, 'k':1, 'skip':0,'convtype':'conv'}\n",
    "    NN_frame=NN_frame.append(fc_block, ignore_index=True)\n",
    "\n",
    "    #no_relu\n",
    "    NN_frame['convtype']= NN_frame['convtype'].apply(lambda x : 'conv' if x=='conv_norelu' else x)\n",
    "\n",
    "    NN_frame['c_in'] = np.roll(NN_frame['c_out'], 1)\n",
    "    NN_frame['c_in'][0]=3 # RGB channels\n",
    "\n",
    "    NN_frame['k2']=NN_frame['k'].apply(lambda x : x*x)\n",
    "    NN_frame['hidden_dim']=NN_frame['exp']*NN_frame['c_in']\n",
    "\n",
    "    NN_frame['h_in'] = np.nan\n",
    "    NN_frame['h_in'][0]=224 # Size imagenet - hardcoded\n",
    "    for i in range(1, len(NN_frame)):\n",
    "        if NN_frame.loc[i-1, 's']==1:\n",
    "            NN_frame.loc[i, 'h_in']=NN_frame.loc[i-1, 'h_in']\n",
    "        elif NN_frame.loc[i-1, 's']==2:\n",
    "            NN_frame.loc[i, 'h_in']=NN_frame.loc[i-1, 'h_in']/2\n",
    "        else : \n",
    "            raise NameError('Dont know the paddind')\n",
    "\n",
    "\n",
    "    NN_frame['h_out'] = np.roll(NN_frame['h_in'], -1)\n",
    "    NN_frame['h_out'][NN_frame.last_valid_index()]=NN_frame['h_in'][NN_frame.last_valid_index()]/NN_frame.loc[NN_frame.last_valid_index(), 's']\n",
    "\n",
    "    NN_frame['tensor_in']=NN_frame['c_in']*NN_frame['h_in']*NN_frame['h_in']\n",
    "    NN_frame['tensor_out']=NN_frame['c_out']*NN_frame['h_out']*NN_frame['h_out']\n",
    "\n",
    "    NN_frame['weights']=NN_frame.apply(lambda x : calculate_weights(x.convtype,x.c_in,x.c_out,x.k,x.exp), axis=1)\n",
    "    NN_frame['FLOPS']= NN_frame.apply(lambda x : calculate_flop(x.convtype,x.h_in,x.h_out,x.c_in,x.c_out,x.k,x.exp, x.tensor_in,x.skip), axis=1)\n",
    "    #return  NN_frame\n",
    "    if separate_types:\n",
    "        NN_frame=NN_frame.loc[:, values_to_keep + ['convtype']]\n",
    "        NN_frame =distinct_contypes(NN_frame, values_to_keep, conv_types)\n",
    "        #values_to_keep = [f'{value}_{type}' for type in conv_types for value in values_to_keep]\n",
    "    else:\n",
    "        NN_frame =NN_frame.loc[:, values_to_keep]\n",
    "    return  NN_frame\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example NN_treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     FLOPS_conv  weights_conv  tensor_in_conv  tensor_out_conv  \\\n0    23708160.0         980.0        150528.0         439040.0   \n1           0.0           0.0             0.0              0.0   \n2    29854720.0        1224.0        439040.0         426496.0   \n3           0.0           0.0             0.0              0.0   \n4           0.0           0.0             0.0              0.0   \n5           0.0           0.0             0.0              0.0   \n6           0.0           0.0             0.0              0.0   \n7           0.0           0.0             0.0              0.0   \n8           0.0           0.0             0.0              0.0   \n9           0.0           0.0             0.0              0.0   \n10          0.0           0.0             0.0              0.0   \n11          0.0           0.0             0.0              0.0   \n12          0.0           0.0             0.0              0.0   \n13          0.0           0.0             0.0              0.0   \n14    3066518.0       32370.0          1421.0          52871.0   \n15  105742000.0     1080000.0         52871.0          49000.0   \n\n    hidden_dim_conv  k2_conv  skip_conv   FLOPS_dw  weights_dw  tensor_in_dw  \\\n0               3.0      9.0        0.0        0.0         0.0           0.0   \n1               0.0      0.0        0.0  7902720.0       350.0      439040.0   \n2              35.0      1.0        0.0        0.0         0.0           0.0   \n3               0.0      0.0        0.0        0.0         0.0           0.0   \n4               0.0      0.0        0.0        0.0         0.0           0.0   \n5               0.0      0.0        0.0        0.0         0.0           0.0   \n6               0.0      0.0        0.0        0.0         0.0           0.0   \n7               0.0      0.0        0.0        0.0         0.0           0.0   \n8               0.0      0.0        0.0        0.0         0.0           0.0   \n9               0.0      0.0        0.0        0.0         0.0           0.0   \n10              0.0      0.0        0.0        0.0         0.0           0.0   \n11              0.0      0.0        0.0        0.0         0.0           0.0   \n12              0.0      0.0        0.0        0.0         0.0           0.0   \n13              0.0      0.0        0.0        0.0         0.0           0.0   \n14             29.0      1.0        0.0        0.0         0.0           0.0   \n15           1079.0      1.0        0.0        0.0         0.0           0.0   \n\n    ...  hidden_dim_dw  k2_dw  skip_dw    FLOPS_inv  weights_inv  \\\n0   ...            0.0    0.0      0.0          0.0          0.0   \n1   ...           35.0    9.0      0.0          0.0          0.0   \n2   ...            0.0    0.0      0.0          0.0          0.0   \n3   ...            0.0    0.0      0.0  181260800.0      11909.0   \n4   ...            0.0    0.0      0.0    7620480.0       1314.0   \n5   ...            0.0    0.0      0.0    3951360.0       1406.0   \n6   ...            0.0    0.0      0.0    2673440.0       1826.0   \n7   ...            0.0    0.0      0.0    2121504.0       3379.0   \n8   ...            0.0    0.0      0.0    2293200.0       6019.0   \n9   ...            0.0    0.0      0.0    2293200.0       6019.0   \n10  ...            0.0    0.0      0.0    1070160.0       2899.0   \n11  ...            0.0    0.0      0.0     347802.0       2136.0   \n12  ...            0.0    0.0      0.0     610050.0       6420.0   \n13  ...            0.0    0.0      0.0     599760.0       6329.0   \n14  ...            0.0    0.0      0.0          0.0          0.0   \n15  ...            0.0    0.0      0.0          0.0          0.0   \n\n    tensor_in_inv  tensor_out_inv  hidden_dim_inv  k2_inv  skip_inv  \n0             0.0             0.0             0.0     0.0       0.0  \n1             0.0             0.0             0.0     0.0       0.0  \n2             0.0             0.0             0.0     0.0       0.0  \n3        426496.0         28224.0           170.0    25.0       0.0  \n4         28224.0         28224.0            45.0     9.0       0.0  \n5         28224.0          8624.0            45.0     9.0       0.0  \n6          8624.0          8624.0            55.0     9.0       0.0  \n7          8624.0          2548.0            66.0    25.0       0.0  \n8          2548.0          2548.0            78.0    49.0       0.0  \n9          2548.0          2548.0            78.0    49.0       0.0  \n10         2548.0          2548.0            78.0     9.0       0.0  \n11         2548.0          1470.0            39.0     9.0       0.0  \n12         1470.0          1470.0            90.0     9.0       1.0  \n13         1470.0          1421.0            90.0     9.0       0.0  \n14            0.0             0.0             0.0     0.0       0.0  \n15            0.0             0.0             0.0     0.0       0.0  \n\n[16 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FLOPS_conv</th>\n      <th>weights_conv</th>\n      <th>tensor_in_conv</th>\n      <th>tensor_out_conv</th>\n      <th>hidden_dim_conv</th>\n      <th>k2_conv</th>\n      <th>skip_conv</th>\n      <th>FLOPS_dw</th>\n      <th>weights_dw</th>\n      <th>tensor_in_dw</th>\n      <th>...</th>\n      <th>hidden_dim_dw</th>\n      <th>k2_dw</th>\n      <th>skip_dw</th>\n      <th>FLOPS_inv</th>\n      <th>weights_inv</th>\n      <th>tensor_in_inv</th>\n      <th>tensor_out_inv</th>\n      <th>hidden_dim_inv</th>\n      <th>k2_inv</th>\n      <th>skip_inv</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>23708160.0</td>\n      <td>980.0</td>\n      <td>150528.0</td>\n      <td>439040.0</td>\n      <td>3.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>7902720.0</td>\n      <td>350.0</td>\n      <td>439040.0</td>\n      <td>...</td>\n      <td>35.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>29854720.0</td>\n      <td>1224.0</td>\n      <td>439040.0</td>\n      <td>426496.0</td>\n      <td>35.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>181260800.0</td>\n      <td>11909.0</td>\n      <td>426496.0</td>\n      <td>28224.0</td>\n      <td>170.0</td>\n      <td>25.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>7620480.0</td>\n      <td>1314.0</td>\n      <td>28224.0</td>\n      <td>28224.0</td>\n      <td>45.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3951360.0</td>\n      <td>1406.0</td>\n      <td>28224.0</td>\n      <td>8624.0</td>\n      <td>45.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2673440.0</td>\n      <td>1826.0</td>\n      <td>8624.0</td>\n      <td>8624.0</td>\n      <td>55.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2121504.0</td>\n      <td>3379.0</td>\n      <td>8624.0</td>\n      <td>2548.0</td>\n      <td>66.0</td>\n      <td>25.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2293200.0</td>\n      <td>6019.0</td>\n      <td>2548.0</td>\n      <td>2548.0</td>\n      <td>78.0</td>\n      <td>49.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2293200.0</td>\n      <td>6019.0</td>\n      <td>2548.0</td>\n      <td>2548.0</td>\n      <td>78.0</td>\n      <td>49.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1070160.0</td>\n      <td>2899.0</td>\n      <td>2548.0</td>\n      <td>2548.0</td>\n      <td>78.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>347802.0</td>\n      <td>2136.0</td>\n      <td>2548.0</td>\n      <td>1470.0</td>\n      <td>39.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>610050.0</td>\n      <td>6420.0</td>\n      <td>1470.0</td>\n      <td>1470.0</td>\n      <td>90.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>599760.0</td>\n      <td>6329.0</td>\n      <td>1470.0</td>\n      <td>1421.0</td>\n      <td>90.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>3066518.0</td>\n      <td>32370.0</td>\n      <td>1421.0</td>\n      <td>52871.0</td>\n      <td>29.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>105742000.0</td>\n      <td>1080000.0</td>\n      <td>52871.0</td>\n      <td>49000.0</td>\n      <td>1079.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>16 rows × 21 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "conv_types = ['conv', 'dw', 'inv']\n",
    "columns_names = ['exp','c_out','s','k','skip']\n",
    "values_to_keep = ['FLOPS','weights','tensor_in','tensor_out','hidden_dim','k2', 'skip']\n",
    "#values_to_keep_plus_type = ['FLOPS','weights','tensor_in','tensor_out','hidden_dim','k2', 'skip', 'convtype']\n",
    "\n",
    "\n",
    "\n",
    "NN = nets_dict['00001']\n",
    "NN_frame = pd.DataFrame(NN, columns = columns_names+ ['convtype',])\n",
    "\n",
    "#distinct =distinct_contypes(NN_frame, columns_names, conv_types)\n",
    "NN_00001 = treat_NN(NN_frame, values_to_keep, True)\n",
    "NN_00001\n",
    "#distinct.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify properperly calculate number of weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Initialize one NN : nets_dict[00001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\nModel: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 224, 224, 3)       0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 112, 112, 35)      980       \n_________________________________________________________________\ndepthwise_conv2d_1 (Depthwis (None, 112, 112, 35)      350       \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 112, 112, 34)      1224      \n_________________________________________________________________\nactivation_1 (Activation)    (None, 112, 112, 34)      0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 112, 112, 170)     5950      \n_________________________________________________________________\ndepthwise_conv2d_2 (Depthwis (None, 56, 56, 170)       4420      \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 56, 56, 9)         1539      \n_________________________________________________________________\nactivation_2 (Activation)    (None, 56, 56, 9)         0         \n_________________________________________________________________\nactivation_3 (Activation)    (None, 56, 56, 9)         0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 56, 56, 45)        450       \n_________________________________________________________________\ndepthwise_conv2d_3 (Depthwis (None, 56, 56, 45)        450       \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 56, 56, 9)         414       \n_________________________________________________________________\nactivation_4 (Activation)    (None, 56, 56, 9)         0         \n_________________________________________________________________\nactivation_5 (Activation)    (None, 56, 56, 9)         0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 56, 56, 45)        450       \n_________________________________________________________________\ndepthwise_conv2d_4 (Depthwis (None, 28, 28, 45)        450       \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 28, 28, 11)        506       \n_________________________________________________________________\nactivation_6 (Activation)    (None, 28, 28, 11)        0         \n_________________________________________________________________\nactivation_7 (Activation)    (None, 28, 28, 11)        0         \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 28, 28, 55)        660       \n_________________________________________________________________\ndepthwise_conv2d_5 (Depthwis (None, 28, 28, 55)        550       \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 28, 28, 11)        616       \n_________________________________________________________________\nactivation_8 (Activation)    (None, 28, 28, 11)        0         \n_________________________________________________________________\nactivation_9 (Activation)    (None, 28, 28, 11)        0         \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 28, 28, 66)        792       \n_________________________________________________________________\ndepthwise_conv2d_6 (Depthwis (None, 14, 14, 66)        1716      \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, 14, 14, 13)        871       \n_________________________________________________________________\nactivation_10 (Activation)   (None, 14, 14, 13)        0         \n_________________________________________________________________\nactivation_11 (Activation)   (None, 14, 14, 13)        0         \n_________________________________________________________________\nconv2d_13 (Conv2D)           (None, 14, 14, 78)        1092      \n_________________________________________________________________\ndepthwise_conv2d_7 (Depthwis (None, 14, 14, 78)        3900      \n_________________________________________________________________\nconv2d_14 (Conv2D)           (None, 14, 14, 13)        1027      \n_________________________________________________________________\nactivation_12 (Activation)   (None, 14, 14, 13)        0         \n_________________________________________________________________\nactivation_13 (Activation)   (None, 14, 14, 13)        0         \n_________________________________________________________________\nconv2d_15 (Conv2D)           (None, 14, 14, 78)        1092      \n_________________________________________________________________\ndepthwise_conv2d_8 (Depthwis (None, 14, 14, 78)        3900      \n_________________________________________________________________\nconv2d_16 (Conv2D)           (None, 14, 14, 13)        1027      \n_________________________________________________________________\nactivation_14 (Activation)   (None, 14, 14, 13)        0         \n_________________________________________________________________\nactivation_15 (Activation)   (None, 14, 14, 13)        0         \n_________________________________________________________________\nconv2d_17 (Conv2D)           (None, 14, 14, 78)        1092      \n_________________________________________________________________\ndepthwise_conv2d_9 (Depthwis (None, 14, 14, 78)        780       \n_________________________________________________________________\nconv2d_18 (Conv2D)           (None, 14, 14, 13)        1027      \n_________________________________________________________________\nactivation_16 (Activation)   (None, 14, 14, 13)        0         \n_________________________________________________________________\nactivation_17 (Activation)   (None, 14, 14, 13)        0         \n_________________________________________________________________\nconv2d_19 (Conv2D)           (None, 14, 14, 39)        546       \n_________________________________________________________________\ndepthwise_conv2d_10 (Depthwi (None, 7, 7, 39)          390       \n_________________________________________________________________\nconv2d_20 (Conv2D)           (None, 7, 7, 30)          1200      \n_________________________________________________________________\nactivation_18 (Activation)   (None, 7, 7, 30)          0         \n_________________________________________________________________\nactivation_19 (Activation)   (None, 7, 7, 30)          0         \n_________________________________________________________________\nconv2d_21 (Conv2D)           (None, 7, 7, 90)          2790      \n_________________________________________________________________\ndepthwise_conv2d_11 (Depthwi (None, 7, 7, 90)          900       \n_________________________________________________________________\nconv2d_22 (Conv2D)           (None, 7, 7, 30)          2730      \n_________________________________________________________________\nactivation_20 (Activation)   (None, 7, 7, 30)          0         \n_________________________________________________________________\nactivation_21 (Activation)   (None, 7, 7, 30)          0         \n_________________________________________________________________\nconv2d_23 (Conv2D)           (None, 7, 7, 90)          2790      \n_________________________________________________________________\ndepthwise_conv2d_12 (Depthwi (None, 7, 7, 90)          900       \n_________________________________________________________________\nconv2d_24 (Conv2D)           (None, 7, 7, 29)          2639      \n_________________________________________________________________\nactivation_22 (Activation)   (None, 7, 7, 29)          0         \n_________________________________________________________________\nconv2d_25 (Conv2D)           (None, 7, 7, 1079)        32370     \n_________________________________________________________________\nglobal_average_pooling2d_1 ( (None, 1079)              0         \n_________________________________________________________________\nreshape_1 (Reshape)          (None, 1, 1, 1079)        0         \n_________________________________________________________________\nDropout (Dropout)            (None, 1, 1, 1079)        0         \n_________________________________________________________________\nconv2d_26 (Conv2D)           (None, 1, 1, 1000)        1080000   \n_________________________________________________________________\nreshape_2 (Reshape)          (None, 1000)              0         \n=================================================================\nTotal params: 1,164,580\nTrainable params: 1,164,580\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dropout\n",
    "from keras.layers import Activation, BatchNormalization, Add, Reshape, DepthwiseConv2D\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from keras import backend as K\n",
    "def relu6(x):\n",
    "    return K.relu(x, max_value=6.0)\n",
    "\n",
    "def _conv_block(inputs, filters, kernel, strides):\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "    x = Conv2D(filters, kernel, padding='same', strides=strides)(inputs)\n",
    "    return x\n",
    "\n",
    "def _bottleneck(inputs, filters, kernel, t, alpha, s, r=False):\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "    tchannel = K.int_shape(inputs)[channel_axis] * t\n",
    "    cchannel = int(filters * alpha)\n",
    "    x = _conv_block(inputs, tchannel, (1, 1), (1, 1))\n",
    "    x = DepthwiseConv2D(kernel, strides=(s, s), depth_multiplier=1, padding='same')(x)\n",
    "    x = Conv2D(cchannel, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "    if r:\n",
    "        x = Add()([x, inputs])\n",
    "    return x\n",
    "\n",
    "def _inverted_residual_block(inputs, filters, kernel, t, alpha, strides, n):\n",
    "    x=Activation(relu6)(inputs)\n",
    "    x = _bottleneck(x, filters, kernel, t, alpha, strides)\n",
    "    for i in range(1, n):\n",
    "        x = _bottleneck(x, filters, kernel, t, alpha, 1, True)\n",
    "    x=Activation(relu6)(x)\n",
    "    return x\n",
    "\n",
    "def Net1(input_shape, k, alpha=1.0):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x= Conv2D(35, 3, padding='same', strides=(2,2))(inputs)\n",
    "    x = DepthwiseConv2D((3,3),  activation='relu', padding='same')(x)\n",
    "    x= Conv2D(34, 1, padding='same', strides=(1,1))(x)\n",
    "\n",
    "    x = _inverted_residual_block(x, 9, (5, 5), t=5, alpha=alpha, strides=2, n=1)\n",
    "    x = _inverted_residual_block(x, 9, (3, 3), t=5, alpha=alpha, strides=1, n=1)\n",
    "    x = _inverted_residual_block(x, 11, (3, 3), t=5, alpha=alpha, strides=2, n=1)\n",
    "    x = _inverted_residual_block(x, 11, (3, 3), t=5, alpha=alpha, strides=1, n=1)\n",
    "\n",
    "    x = _inverted_residual_block(x, 13, (5, 5), t=6, alpha=alpha, strides=2, n=1)\n",
    "    x = _inverted_residual_block(x, 13, (7, 7), t=6, alpha=alpha, strides=1, n=1)\n",
    "    x = _inverted_residual_block(x, 13, (7, 7), t=6, alpha=alpha, strides=1, n=1)\n",
    "    x = _inverted_residual_block(x, 13, (3, 3), t=6, alpha=alpha, strides=1, n=1)\n",
    "\n",
    "    x = _inverted_residual_block(x, 30, (3, 3), t=3, alpha=alpha, strides=2, n=1)\n",
    "    x = _inverted_residual_block(x, 30, (3, 3), t=3, alpha=alpha, strides=1, n=1)\n",
    "    x = _inverted_residual_block(x, 29, (3, 3), t=3, alpha=alpha, strides=1, n=1)\n",
    "    last_filters = 1079\n",
    "\n",
    "    x = _conv_block(x, last_filters, (1, 1), strides=(1, 1))\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    x = Reshape((1, 1, last_filters))(x)\n",
    "    x = Dropout(0.3, name='Dropout')(x)\n",
    "    #!!!!!!!!!\n",
    "    x = Conv2D(k, (1, 1), padding='same')(x)\n",
    "    #!!!!!!!!!\n",
    "    output = Reshape((k,))(x)\n",
    "    model = Model(inputs, output)\n",
    "    # plot_model(model, to_file='images/MobileNetv2.png', show_shapes=True)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model_1 = Net1((224, 224, 3), 1000, 1.0)\n",
    "    print(model_1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model total param = Total params: 1,164,580"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1164580.0\n"
    }
   ],
   "source": [
    "\n",
    "print(sum(NN_00001['weights_conv'])+sum(NN_00001['weights_dw'])+sum(NN_00001['weights_inv']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'weights'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'weights'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-8195442b3168>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNN_00001\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'weights'"
     ]
    }
   ],
   "source": [
    "sum(NN_00001['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /Users/roxanefischer/miniconda3/envs/has/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nWARNING:tensorflow:From /Users/roxanefischer/miniconda3/envs/has/lib/python3.6/site-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2321134"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    " \n",
    "##### FIXME!!!!!!!!!!!\n",
    "def get_flops():\n",
    "    session = tf.compat.v1.Session()\n",
    "    graph = tf.compat.v1.get_default_graph()\n",
    "\n",
    "    with graph.as_default():\n",
    "        with session.as_default():\n",
    "            model_2 = Net1((224, 224, 3), 1000, 1.0)\n",
    "            run_meta = tf.compat.v1.RunMetadata()\n",
    "            opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "            # Optional: save printed results to file\n",
    "            # flops_log_path = os.path.join(tempfile.gettempdir(), 'tf_flops_log.txt')\n",
    "            # opts['output'] = 'file:outfile={}'.format(flops_log_path)\n",
    "\n",
    "            # We use the Keras session graph in the call to the profiler.\n",
    "            flops = tf.compat.v1.profiler.profile(graph=graph,\n",
    "                                                  run_meta=run_meta, cmd='op', options=opts)\n",
    "\n",
    "            return flops.total_float_ops\n",
    "get_flops()\n",
    "\n",
    "#print(sum(NN_00001['FLOPS']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the final representation of the NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'separate_types' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-21e3360da8e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mNN_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN_to_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalues_to_keep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseparate_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'separate_types' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def no_relu(NN_frame):  \n",
    "    NN_frame['convtype']= NN_frame['convtype'].apply(lambda x : 'conv' if x=='conv_norelu' else x)\n",
    "\n",
    "\n",
    "def NN_to_dataframe(NN_list, columns_names, conv_types, values_to_keep,separate_types):\n",
    "    NN_frame = pd.DataFrame(NN_list, columns = columns_names+ ['convtype',])\n",
    "    no_relu(NN_frame)\n",
    "    return treat_NN(NN_frame, values_to_keep,separate_types)\n",
    "\n",
    "    #NN_distinct_contypes = distinct_contypes(NN_frame, columns_names, conv_types)\n",
    "    #return NN_frame\n",
    "    #return NN_distinct_contypes\n",
    "\n",
    "\n",
    "NN_df = NN_to_dataframe(NN, columns_names, conv_types,values_to_keep,separate_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add HW params to NN_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ['mac_num','mac_array_num','data_bits','sram_size','max_filter_size']\n",
    "\n",
    "def add_HW_param_column(df,mac_num, mac_array_num, data_bits, sram_size, max_filter_size):\n",
    "    df['mac_num']=mac_num\n",
    "    df['mac_array_num']=mac_array_num\n",
    "    df['total_macs']=  mac_num * mac_array_num\n",
    "    df['data_bits']=data_bits\n",
    "    df['sram_size']=sram_size\n",
    "    df['max_filter_size']=max_filter_size\n",
    "\n",
    "\n",
    "def add_HW_param_line(NN_frame, mac_num, mac_array_num, data_bits, sram_size, max_filter_size):\n",
    "    HW_param_line =pd.DataFrame([[mac_num]*(NN_frame.shape[1])], columns=NN_frame.columns)\n",
    "    HW_param_line = HW_param_line.append(pd.DataFrame([[mac_array_num]*(NN_frame.shape[1])], columns=NN_frame.columns))\n",
    "    HW_param_line = HW_param_line.append(pd.DataFrame([[mac_num*mac_array_num]*(NN_frame.shape[1])], columns=NN_frame.columns))\n",
    "    HW_param_line =HW_param_line.append(pd.DataFrame([[data_bits]*(NN_frame.shape[1])], columns=NN_frame.columns))\n",
    "    HW_param_line =HW_param_line.append(pd.DataFrame([[sram_size]*(NN_frame.shape[1])], columns=NN_frame.columns))\n",
    "    HW_param_line =HW_param_line.append(pd.DataFrame([[max_filter_size]*(NN_frame.shape[1])], columns=NN_frame.columns))\n",
    "    return HW_param_line.append(NN_frame)\n",
    "\n",
    "\n",
    "#not_used\n",
    "def extend_to_max_blocks(NN_frame, value):\n",
    "    for i in range (max_blocks-len(NN_frame)):\n",
    "        NN_frame=NN_frame.append(pd.DataFrame([[0]*(NN_frame.shape[1])], index=[i+len(NN_frame),] ,columns=NN_frame.columns))\n",
    "    return NN_frame\n",
    "\n",
    "#not_used\n",
    "def add_zero_blocks(arr):\n",
    "    zero_blocks = np.zeros(( max_blocks-arr.shape[0],arr.shape[1]))\n",
    "    return np.append(arr, zero_blocks, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "UsageError: Line magic function `%pycache` not found.\n"
    }
   ],
   "source": [
    "%pycache\n",
    "train_hw= train_hw[:3]\n",
    "val_hw = val_hw[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "  0%|          | 414/137090 [00:22<5:57:33,  6.37it/s]"
    }
   ],
   "source": [
    "#%pycache\n",
    "values_to_keep = ['FLOPS','weights','tensor_in','tensor_out','hidden_dim','k2', 'skip']\n",
    "separate_types = True\n",
    "# if separate_types:\n",
    "#     values_to_keep = [f'{value}_{type}' for type in conv_types for value in values_to_keep]\n",
    "\n",
    "name = '21'\n",
    "\n",
    "\n",
    "# Convert NN to dataframe with values of interest\n",
    "train_hw[\"NN_dataframe\"] = train_hw[\"NN\"].progress_apply(lambda x : NN_to_dataframe(x,columns_names, conv_types, values_to_keep,separate_types))\n",
    "#train_hw.progress_apply(lambda x : add_HW_param_column(x.NN_dataframe,x.mac_num,x.mac_array_num, x.data_bits, x.sram_size, x.max_filter_size), axis=1)\n",
    "train_hw['NN_dataframe']=train_hw['NN_dataframe'].progress_apply(lambda x : np.array(x))\n",
    "#complete to zero#complete to zero\n",
    "#train_hw['NN_dataframe']= train['NN_dataframe'].progress_apply(lambda x : add_zero_blocks(x))#complete to zero#complete to zero\n",
    "train_hw['NN_dataframe'].to_csv(f'train_{name}.csv')\n",
    "\n",
    "\n",
    "#####################################\n",
    "\n",
    "val_hw[\"NN_dataframe\"] = val_hw[\"NN\"].progress_apply(lambda x : NN_to_dataframe(x,columns_names, conv_types, values_to_keep,separate_types))\n",
    "#val_hw.progress_apply(lambda x : add_HW_param_column(x.NN_dataframe,x.mac_num,x.mac_array_num, x.data_bits, x.sram_size, x.max_filter_size), axis=1)\n",
    "val_hw['NN_dataframe']=val_hw['NN_dataframe'].progress_apply(lambda x : np.array(x))\n",
    "\n",
    "#complete to zero#complete to zero\n",
    "#val['NN_dataframe']= val['NN_dataframe'].progress_apply(lambda x : add_zero_blocks(x))#complete to zero#complete to zero\n",
    "val_hw.to_csv(f'val_{name}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pycache\n",
    "import ast\n",
    "\n",
    "\n",
    "path_processed_val_nn=\"/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/val_21.csv\"\n",
    "\n",
    "def from_np_array(array_string):\n",
    "    array_string = ','.join(array_string.replace('[ ', '[').split())\n",
    "    return np.asarray(ast.literal_eval(array_string))\n",
    "\n",
    "val = pd.read_csv(path_processed_val_nn,converters={'NN_dataframe': from_np_array})\n",
    "#train = pd.read_csv(path_processed_train_nn,converters={'NN_dataframe': from_np_array})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            0      1         2         3     4    5    6          7      8   \\\n0   21676032.0  896.0  150528.0  401408.0   3.0  9.0  0.0        0.0    0.0   \n1          0.0    0.0       0.0       0.0   0.0  0.0  0.0  7225344.0  320.0   \n2   20070400.0  825.0  401408.0  313600.0  32.0  1.0  0.0        0.0    0.0   \n3          0.0    0.0       0.0       0.0   0.0  0.0  0.0        0.0    0.0   \n4          0.0    0.0       0.0       0.0   0.0  0.0  0.0        0.0    0.0   \n5          0.0    0.0       0.0       0.0   0.0  0.0  0.0        0.0    0.0   \n6          0.0    0.0       0.0       0.0   0.0  0.0  0.0        0.0    0.0   \n7          0.0    0.0       0.0       0.0   0.0  0.0  0.0        0.0    0.0   \n8          0.0    0.0       0.0       0.0   0.0  0.0  0.0        0.0    0.0   \n9          0.0    0.0       0.0       0.0   0.0  0.0  0.0        0.0    0.0   \n10         0.0    0.0       0.0       0.0   0.0  0.0  0.0        0.0    0.0   \n11         0.0    0.0       0.0       0.0   0.0  0.0  0.0        0.0    0.0   \n12         0.0    0.0       0.0       0.0   0.0  0.0  0.0        0.0    0.0   \n13         0.0    0.0       0.0       0.0   0.0  0.0  0.0        0.0    0.0   \n14         0.0    0.0       0.0       0.0   0.0  0.0  0.0        0.0    0.0   \n15         0.0    0.0       0.0       0.0   0.0  0.0  0.0        0.0    0.0   \n\n          9   ...    11   12   13           14       15        16        17  \\\n0        0.0  ...   0.0  0.0  0.0          0.0      0.0       0.0       0.0   \n1   401408.0  ...  32.0  9.0  0.0          0.0      0.0       0.0       0.0   \n2        0.0  ...   0.0  0.0  0.0          0.0      0.0       0.0       0.0   \n3        0.0  ...   0.0  0.0  0.0  346214400.0  14118.0  313600.0  225792.0   \n4        0.0  ...   0.0  0.0  0.0  122153472.0   5094.0  225792.0  225792.0   \n5        0.0  ...   0.0  0.0  0.0   63221760.0   5431.0  225792.0   97216.0   \n6        0.0  ...   0.0  0.0  0.0   93327360.0  15230.0   97216.0  125440.0   \n7        0.0  ...   0.0  0.0  0.0  100352000.0  16431.0  125440.0   97216.0   \n8        0.0  ...   0.0  0.0  0.0   85550080.0  13998.0   97216.0  150528.0   \n9        0.0  ...   0.0  0.0  0.0  141496320.0  23077.0  150528.0  116032.0   \n10       0.0  ...   0.0  0.0  0.0  135757440.0  22046.0  116032.0   97216.0   \n11       0.0  ...   0.0  0.0  0.0   66106880.0  10878.0   97216.0   87808.0   \n12       0.0  ...   0.0  0.0  0.0   51806720.0   8562.0   87808.0   68992.0   \n13       0.0  ...   0.0  0.0  0.0  117976320.0  19270.0   68992.0  200704.0   \n14       0.0  ...   0.0  0.0  0.0  473260032.0  76666.0  200704.0  181888.0   \n15       0.0  ...   0.0  0.0  0.0  100947840.0  34541.0  181888.0   69776.0   \n\n       18    19   20  \n0     0.0   0.0  0.0  \n1     0.0   0.0  0.0  \n2     0.0   0.0  0.0  \n3   150.0  49.0  0.0  \n4   108.0   9.0  1.0  \n5    90.0   9.0  0.0  \n6   155.0  25.0  0.0  \n7   200.0   9.0  0.0  \n8   155.0   9.0  0.0  \n9   240.0   9.0  0.0  \n10  185.0  49.0  0.0  \n11  155.0   9.0  0.0  \n12  140.0   9.0  0.0  \n13  198.0   9.0  0.0  \n14  576.0   9.0  0.0  \n15  174.0  49.0  0.0  \n\n[16 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>21676032.0</td>\n      <td>896.0</td>\n      <td>150528.0</td>\n      <td>401408.0</td>\n      <td>3.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>7225344.0</td>\n      <td>320.0</td>\n      <td>401408.0</td>\n      <td>...</td>\n      <td>32.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20070400.0</td>\n      <td>825.0</td>\n      <td>401408.0</td>\n      <td>313600.0</td>\n      <td>32.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>346214400.0</td>\n      <td>14118.0</td>\n      <td>313600.0</td>\n      <td>225792.0</td>\n      <td>150.0</td>\n      <td>49.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>122153472.0</td>\n      <td>5094.0</td>\n      <td>225792.0</td>\n      <td>225792.0</td>\n      <td>108.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>63221760.0</td>\n      <td>5431.0</td>\n      <td>225792.0</td>\n      <td>97216.0</td>\n      <td>90.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>93327360.0</td>\n      <td>15230.0</td>\n      <td>97216.0</td>\n      <td>125440.0</td>\n      <td>155.0</td>\n      <td>25.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>100352000.0</td>\n      <td>16431.0</td>\n      <td>125440.0</td>\n      <td>97216.0</td>\n      <td>200.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>85550080.0</td>\n      <td>13998.0</td>\n      <td>97216.0</td>\n      <td>150528.0</td>\n      <td>155.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>141496320.0</td>\n      <td>23077.0</td>\n      <td>150528.0</td>\n      <td>116032.0</td>\n      <td>240.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>135757440.0</td>\n      <td>22046.0</td>\n      <td>116032.0</td>\n      <td>97216.0</td>\n      <td>185.0</td>\n      <td>49.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>66106880.0</td>\n      <td>10878.0</td>\n      <td>97216.0</td>\n      <td>87808.0</td>\n      <td>155.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>51806720.0</td>\n      <td>8562.0</td>\n      <td>87808.0</td>\n      <td>68992.0</td>\n      <td>140.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>117976320.0</td>\n      <td>19270.0</td>\n      <td>68992.0</td>\n      <td>200704.0</td>\n      <td>198.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>473260032.0</td>\n      <td>76666.0</td>\n      <td>200704.0</td>\n      <td>181888.0</td>\n      <td>576.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>100947840.0</td>\n      <td>34541.0</td>\n      <td>181888.0</td>\n      <td>69776.0</td>\n      <td>174.0</td>\n      <td>49.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>16 rows × 21 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 125
    }
   ],
   "source": [
    "pd.DataFrame((val['NN_dataframe'][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File /Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/csv/train_hw_13_old.csv does not exist: '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/csv/train_hw_13_old.csv'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-4cdd883989d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#combine all files in the list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrain_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrains\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mval_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#export to csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-118-4cdd883989d1>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#combine all files in the list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrain_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrains\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mval_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#export to csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/has/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File /Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/csv/train_hw_13_old.csv does not exist: '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/csv/train_hw_13_old.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas\n",
    "import pandas as pd\n",
    "os.chdir(\"/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data\")\n",
    "extension = 'csv'\n",
    "\n",
    "trains = [\"/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/csv/train_hw_13_old.csv\", \"/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/csv/train_13_new.csv\"]\n",
    "\n",
    "vals = [\"/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/csv/val_hw_13_old.csv\", \"/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/csv/val_13_new.csv\"]\n",
    "#all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "\n",
    "\n",
    "#combine all files in the list\n",
    "train_csv = pd.concat([pd.read_csv(f) for f in trains])\n",
    "val_csv = pd.concat([pd.read_csv(f) for f in vals])\n",
    "#export to csv\n",
    "train_csv.to_csv( \"train_13.csv\", index=False, encoding='utf-8-sig')\n",
    "val_csv.to_csv( \"val_13\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "all_nets.json                 parsed_nondups_val1_fix.txt\nparsed_nondups_train1.csv     parsed_nondups_val2.csv\nparsed_nondups_train1_fix.txt parsed_nondups_val2.txt\nparsed_nondups_train2.csv     parsed_nondups_val_all.csv\nparsed_nondups_train2.txt     train_21.csv\nparsed_nondups_train_all.csv  val_21.csv\nparsed_nondups_val1.csv\n"
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Éditer les Méta-Données",
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('has': conda)",
   "language": "python",
   "name": "python361064bithascondabd8f1537e5d34ba799ef15b8707e6526"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}