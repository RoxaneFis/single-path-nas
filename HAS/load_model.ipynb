{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import ast\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import seaborn as sns\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from progressbar import ProgressBar\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import Sequential, Model\n",
    "from random import randrange\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import time\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "\n",
    "pbar = ProgressBar()\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_processed_val_nn = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/val_7.csv'\n",
    "path_raw_val = '/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/data/parsed_nondups_val_all.csv'\n",
    "val = pd.read_csv(path_processed_val_nn,converters={'NN_dataframe': from_np_array})\n",
    "def add_zero_blocks(arr):\n",
    "    zero_blocks = np.zeros((max_blocks-arr.shape[0],arr.shape[1]))\n",
    "    return np.append(arr, zero_blocks, axis=0)\n",
    "\n",
    "val['NN_dataframe']= val['NN_dataframe'].apply(lambda x : add_zero_blocks(x))\n",
    "val_hw = pd.read_csv(path_raw_val)\n",
    "y_val = np.array(val_hw[\"total_power\"].tolist())\n",
    "y_val=y_val.reshape(y_val.shape[0],-1)\n",
    "X_val_hw_param  = val_hw[['mac_num', 'mac_array_num', 'data_bits', 'sram_size', 'max_filter_size']]\n",
    "X_val_hw_param['tot_mac'] = X_val_hw_param['mac_num']*X_val_hw_param['mac_array_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_blocks = 37\n",
    "nb_param =7\n",
    "nb_hw_param = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " model_nn= tf.keras.Sequential([\n",
    "       layers.Conv1D(128, (3), activation='relu', padding=\"same\",input_shape=(max_blocks, nb_param)),\n",
    "       layers.Conv1D(64, (3), activation='relu', padding=\"same\"),\n",
    "       layers.Lambda( lambda x: K.sum(x, axis=1)),\n",
    "      #layers.Flatten()\n",
    " ])\n",
    "\n",
    "\n",
    "model_hw = tf.keras.Sequential([\n",
    "     layers.Dense(128, activation='relu', input_shape=(nb_hw_param,)),\n",
    "     #layers.Dense(64, activation='relu'),\n",
    "     layers.Dense(64, activation='linear')\n",
    " ])\n",
    "\n",
    "\n",
    "concat = tf.keras.layers.multiply([model_nn.output, model_hw.output])\n",
    "output = tf.keras.layers.Dense(units=16, activation='relu')(concat)\n",
    "output = tf.keras.layers.Dense(units=1, activation='relu')(output)\n",
    "\n",
    "\n",
    "full_model = tf.keras.Model(inputs=[model_nn.input, model_hw.input], outputs=[output])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1a4ae330b8>"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "full_model.load_weights(\"/Users/roxanefischer/Desktop/single_path_nas/single-path-nas/HAS/results_best_models/multiply/model_7_37665_param_0.213_error/model_7_37665_param\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(X_list,y):\n",
    "    losses=[]\n",
    "    inputs =[]\n",
    "    for i in range(len(X_list[0])):\n",
    "        for x in range(len(X_list)): # whether one or multiple inputs\n",
    "            input_x=np.array(X_list[x])[i]\n",
    "            input_x=input_x.reshape((1,*input_x.shape))\n",
    "            inputs.append(tf.convert_to_tensor(input_x))\n",
    "        pred = model.predict(inputs)\n",
    "        losses.append(loss(y[i],pred))\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'X_val_list' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-b41e3052b940>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_val_list' is not defined"
     ]
    }
   ],
   "source": [
    "score(X_val_list[:10],y_val[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_score, score_decreases = get_score_importances(score, X_val_list, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter('tmp.tfrecord') as writer:\n",
    "    def create_float_feature(values):\n",
    "        return tf.train.Feature(float_list=tf.train.FloatList(value=values))\n",
    "\n",
    "    def _bytes_feature(value):\n",
    "        \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "        if isinstance(value, type(tf.constant(0))): # if value ist tensor\n",
    "            value = value.numpy() # get value of tensor\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "    def serialize_array(array):\n",
    "        array = tf.io.serialize_tensor(array)\n",
    "        return array\n",
    "\n",
    "\n",
    "    def create_int_feature(values):\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=list(values)))\n",
    "\n",
    "    for X_nn, X_hw,y in zip(X_val_nn_norm, X_val_hw_param_norm, y_val):\n",
    "        serialized_array = serialize_array(X_nn)\n",
    "        features = {'b_features':  _bytes_feature(serialized_array) , 'labels': create_float_feature([y])}\n",
    "        tf_example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "\n",
    "def _parse_tfr_element(element):\n",
    "  parse_dic = {\n",
    "     'b_feature': tf.io.FixedLenFeature([], tf.string), # Note that it is tf.string, not tf.float32\n",
    "     'labels': tf.FixedLenFeature([], tf.float64),\n",
    "    }\n",
    "  example_message = tf.io.parse_single_example(element, parse_dic)\n",
    "\n",
    "  b_feature = example_message['b_feature'] # get byte string\n",
    "  label = example_message['labels']\n",
    "  feature = tf.io.parse_tensor(b_feature, out_type=tf.float64) # restore 2D array from byte string\n",
    "  return feature, label\n",
    "\n",
    "\n",
    "tfr_dataset = tf.data.TFRecordDataset('tmp.tfrecord') \n",
    "for serialized_instance in tfr_dataset:\n",
    "  print(serialized_instance) # print serialized example messages\n",
    "\n",
    "dataset = tfr_dataset.map(_parse_tfr_element)\n",
    "for instance in dataset:\n",
    "  print()\n",
    "  print(instance) # print parsed example messages with restored arrays\n",
    "  breakwith tf.io.TFRecordWriter('tmp.tfrecord') as writer:\n",
    "    def create_float_feature(values):\n",
    "        return tf.train.Feature(float_list=tf.train.FloatList(value=values))\n",
    "\n",
    "    def _bytes_feature(value):\n",
    "        \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "        if isinstance(value, type(tf.constant(0))): # if value ist tensor\n",
    "            value = value.numpy() # get value of tensor\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "    def serialize_array(array):\n",
    "        array = tf.io.serialize_tensor(array)\n",
    "        return array\n",
    "\n",
    "\n",
    "    def create_int_feature(values):\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=list(values)))\n",
    "\n",
    "    for X_nn, X_hw,y in zip(X_val_nn_norm, X_val_hw_param_norm, y_val):\n",
    "        serialized_array = serialize_array(X_nn)\n",
    "        features = {'b_features':  _bytes_feature(serialized_array) , 'labels': create_float_feature([y])}\n",
    "        tf_example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "\n",
    "def _parse_tfr_element(element):\n",
    "  parse_dic = {\n",
    "     'b_feature': tf.io.FixedLenFeature([], tf.string), # Note that it is tf.string, not tf.float32\n",
    "     'labels': tf.FixedLenFeature([], tf.float64),\n",
    "    }\n",
    "  example_message = tf.io.parse_single_example(element, parse_dic)\n",
    "\n",
    "  b_feature = example_message['b_feature'] # get byte string\n",
    "  label = example_message['labels']\n",
    "  feature = tf.io.parse_tensor(b_feature, out_type=tf.float64) # restore 2D array from byte string\n",
    "  return feature, label\n",
    "\n",
    "\n",
    "tfr_dataset = tf.data.TFRecordDataset('tmp.tfrecord') \n",
    "for serialized_instance in tfr_dataset:\n",
    "  print(serialized_instance) # print serialized example messages\n",
    "\n",
    "dataset = tfr_dataset.map(_parse_tfr_element)\n",
    "for instance in dataset:\n",
    "  print()\n",
    "  print(instance) # print parsed example messages with restored arrays\n",
    "  break"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bithascondabd8f1537e5d34ba799ef15b8707e6526",
   "display_name": "Python 3.6.10 64-bit ('has': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}